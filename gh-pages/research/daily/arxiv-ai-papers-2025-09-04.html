<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Papers - 2025-09-05 - AICOE</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <div class="container">
        <nav class="breadcrumb">
            <a href="../../index.html">Home</a> / 
            <a href="../index.html">Research</a> / 
            <span>Daily AI Papers</span>
        </nav>
        
        <div class="research-hero">
            <h1>arXiv AI Papers - 2025-09-05</h1>
            <p>Daily collection of AI-related papers from arXiv. Total papers: 63</p>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-number">63</div>
                <div class="stat-label">Total Papers</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">19</div>
                <div class="stat-label">High Relevance</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">31</div>
                <div class="stat-label">Categories</div>
            </div>
        </div>
        
        <div class="research-content">

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>1. Res-MoCoDiff: Residual-guided diffusion models for motion artifact   correction in brain MRI</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Mojtaba Safari, Shansong Wang, Qiang Li et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, physics.med-ph</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2505.03498v2" target="_blank">arXiv:2505.03498v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.03498v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Objective. Motion artifacts in brain MRI, mainly from rigid head motion,
degrade image quality and hinder downstream applications. Conventional methods
to mitigate these artifacts, including repeated acquisitions or motion
tracking, impose workflow burdens. This study introduces Res-MoCoDiff, an
efficient denoising diffusion probabilistic model specifically designed for MRI
motion artifact correction.Approach.Res-MoCoDiff exploits a novel residual
error shifting mechanism during the forward diff...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>2. ACING: Actor-Critic for Instruction Learning in Black-Box LLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Salma Kharrat, Fares Fourati, Marco Canini</span><br>
                    <span class="meta-item">üìÅ cs.AI, cs.LG, eess.SY, cs.CL, cs.SY, math.OC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2411.12736v2" target="_blank">arXiv:2411.12736v2</a> | 
                    <a href="http://arxiv.org/pdf/2411.12736v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The effectiveness of Large Language Models (LLMs) in solving tasks depends
significantly on the quality of their instructions, which often require
substantial human effort to craft. This underscores the need for automated
instruction optimization. However, optimizing instructions is particularly
challenging when working with black-box LLMs, where model parameters and
gradients are inaccessible. We introduce ACING, an actor-critic reinforcement
learning framework that formulates instruction optim...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>3. AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Guibin Zhang, Junhao Wang, Junjie Chen et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.MA</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.03312v2" target="_blank">arXiv:2509.03312v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03312v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly in...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>4. Self-adaptive Dataset Construction for Real-World Multimodal Safety   Scenarios</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Jingen Qu, Lijun Li, Bo Zhang et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, cs.CL, cs.CR</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04403v1" target="_blank">arXiv:2509.04403v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04403v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end c...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at EMNLP 2025 Findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>5. OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent   Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Chen Hu, Shan Luo, Letizia Gionfrida</span><br>
                    <span class="meta-item">üìÅ cs.RO, cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04324v1" target="_blank">arXiv:2509.04324v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04324v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a visio...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>6. Spatially-Enhanced Recurrent Memory for Long-Range Mapless Navigation   via End-to-End Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Fan Yang, Per Frivik, David Hoeller et al.</span><br>
                    <span class="meta-item">üìÅ cs.RO</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2506.05997v2" target="_blank">arXiv:2506.05997v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.05997v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in robot navigation, particularly with end-to-end
learning approaches such as reinforcement learning (RL), have demonstrated
strong performance. However, successful navigation still depends on two key
capabilities: mapping and planning (explicitly or implicitly). Classical
approaches rely on explicit mapping pipelines to register egocentric
observations into a coherent map. In contrast, end-to-end learning often
achieves this implicitly -- through recurrent neural networks (R...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 22 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>7. Enhancing Technical Documents Retrieval for RAG</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Songjiang Lai, Tsun-Hin Cheung, Ka-Chun Fung et al.</span><br>
                    <span class="meta-item">üìÅ cs.IR, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04139v1" target="_blank">arXiv:2509.04139v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04139v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this paper, we introduce Technical-Embeddings, a novel framework designed
to optimize semantic retrieval in technical documentation, with applications in
both hardware and software development. Our approach addresses the challenges
of understanding and retrieving complex technical content by leveraging the
capabilities of Large Language Models (LLMs). First, we enhance user queries by
generating expanded representations that better capture user intent and improve
dataset diversity, thereby en...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>8. Delta Activations: A Representation for Finetuned Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Zhiqiu Xu, Amish Sethi, Mayur Naik et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.LG, cs.IR, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04442v1" target="_blank">arXiv:2509.04442v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04442v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured repositories.
We introduce Delta Activations, a method to represent finetuned models as
vector embeddings by measuring shifts in their internal activations relative to
a base model. This representation ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>9. ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Matthew Ho, Chen Si, Zhaoxiang Feng et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.LG, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04439v1" target="_blank">arXiv:2509.04439v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04439v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>10. Towards a Unified View of Large Language Model Post-Training</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Xingtai Lv, Yuxin Zuo, Youbang Sun et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.LG, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04419v1" target="_blank">arXiv:2509.04419v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04419v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Two major sources of training data exist for post-training modern language
models: online (model-generated rollouts) data, and offline (human or
other-model demonstrations) data. These two types of data are typically used by
approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT),
respectively. In this paper, we show that these approaches are not in
contradiction, but are instances of a single optimization process. We derive a
Unified Policy Gradient Estimator, and present t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>11. Modular Techniques for Synthetic Long-Context Data Generation in   Language Model Training and Evaluation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Seganrasan Subramanian, Abhigya Verma</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.01185v2" target="_blank">arXiv:2509.01185v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.01185v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple tra...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 26 pages, 4 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>12. TRUST-VL: An Explainable News Assistant for General Multimodal   Misinformation Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Zehong Yan, Peng Qi, Wynne Hsu et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, cs.MM</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04448v1" target="_blank">arXiv:2509.04448v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04448v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and e...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025; Project Homepage: https://yanzehong.github.io/trust-vl/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>13. Plot&#x27;n Polish: Zero-shot Story Visualization and Disentangled Editing   with Text-to-Image Diffusion Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Kiymet Akdemir, Jing Shi, Kushal Kafle et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04446v1" target="_blank">arXiv:2509.04446v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04446v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>14. Connections between reinforcement learning with feedback,test-time   scaling, and diffusion guidance: An anthology</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Yuchen Jiao, Yuxin Chen, Gen Li</span><br>
                    <span class="meta-item">üìÅ stat.ML, cs.GL, cs.LG, math.ST, stat.TH</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04372v1" target="_blank">arXiv:2509.04372v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04372v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this note, we reflect on several fundamental connections among widely used
post-training techniques. We clarify some intimate connections and equivalences
between reinforcement learning with human feedback, reinforcement learning with
internal feedback, and test-time scaling (particularly soft best-of-$N$
sampling), while also illuminating intrinsic links between diffusion guidance
and test-time scaling. Additionally, we introduce a resampling approach for
alignment and reward-directed diffus...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>15. Psychologically Enhanced AI Agents</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Maciej Besta, Shriram Chandran, Robert Gerstenberger et al.</span><br>
                    <span class="meta-item">üìÅ cs.AI, cs.CL, cs.CY, cs.HC, cs.MA</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04343v1" target="_blank">arXiv:2509.04343v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04343v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>16. Write on Paper, Wrong in Practice: Why LLMs Still Struggle with Writing   Clinical Notes</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Kristina L. Kupferschmidt, Kieran O&#x27;Doherty, Joshua A. Skorburg</span><br>
                    <span class="meta-item">üìÅ cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04340v1" target="_blank">arXiv:2509.04340v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04340v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) are often proposed as tools to streamline
clinical documentation, a task viewed as both high-volume and low-risk.
However, even seemingly straightforward applications of LLMs raise complex
sociotechnical considerations to translate into practice. This case study,
conducted at KidsAbility, a pediatric rehabilitation facility in Ontario,
Canada examined the use of LLMs to support occupational therapists in reducing
documentation burden.We conducted a qualitative study ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>17. No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in   Resume Screening</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva et al.</span><br>
                    <span class="meta-item">üìÅ cs.AI, cs.CY, cs.HC, K.4.2, cs.CL</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04404v1" target="_blank">arXiv:2509.04404v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04404v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this study, we conduct a resume-screening experiment (N=528) where people
collaborate with simulated AI models exhibiting race-based preferences (bias)
to evaluate candidates for 16 high and low status occupations. Simulated AI
bias approximates factual and counterfactual estimates of racial bias in
real-world AI systems. We investigate people&#x27;s preferences for White, Black,
Hispanic, and Asian candidates (represented through names and affinity groups
on quality-controlled resumes) across 1,5...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published in Proceedings of the 2025 AAAI/ACM Conference on AI,
  Ethics, and Society; code available at
  https://github.com/kyrawilson/No-Thoughts-Just-AI</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>18. IPA: An Information-Preserving Input Projection Framework for Efficient   Foundation Model Adaptation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Yuan Yin, Shashanka Venkataramanan, Tuan-Hung Vu et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04398v1" target="_blank">arXiv:2509.04398v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04398v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, reduce
adaptation cost by injecting low-rank updates into pretrained weights. However,
LoRA&#x27;s down-projection is randomly initialized and data-agnostic, discarding
potentially useful information. Prior analyses show that this projection
changes little during training, while the up-projection carries most of the
adaptation, making the random input compression a performance bottleneck. We
propose IPA, a feature-aware projection framewor...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>19. Enhancing Text2Cypher with Schema Filtering</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Makbule Gulcin Ozsoy</span><br>
                    <span class="meta-item">üìÅ cs.DB, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2505.05118v2" target="_blank">arXiv:2505.05118v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.05118v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Knowledge graphs represent complex data using nodes, relationships, and
properties. Cypher, a powerful query language for graph databases, enables
efficient modeling and querying. Recent advancements in large language models
allow translation of natural language questions into Cypher queries -
Text2Cypher. A common approach is incorporating database schema into prompts.
However, complex schemas can introduce noise, increase hallucinations, and
raise computational costs. Schema filtering addresse...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>20. Parking Availability Prediction via Fusing Multi-Source Data with A   Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Yin Huang, Yongqi Dong, Youhua Tang et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.AI, stat.ML</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04362v1" target="_blank">arXiv:2509.04362v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04362v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The rapid growth of private car ownership has worsened the urban parking
predicament, underscoring the need for accurate and effective parking
availability prediction to support urban planning and management. To address
key limitations in modeling spatio-temporal dependencies and exploiting
multi-source data for parking availability prediction, this study proposes a
novel approach with SST-iTransformer. The methodology leverages K-means
clustering to establish parking cluster zones (PCZs), extra...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 25 pages, 5 figures, under review for journal publication</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>21. Imputation-free Learning of Tabular Data with Missing Values using   Incremental Feature Partitions in Transformer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Manar D. Samad, Kazi Fuad B. Akhter, Shourav B. Rabbani et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG, stat.ML</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2504.14610v4" target="_blank">arXiv:2504.14610v4</a> | 
                    <a href="http://arxiv.org/pdf/2504.14610v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Tabular data sets with varying missing values are prepared for machine
learning using an arbitrary imputation strategy. Synthetic values generated by
imputation models often raise concerns about data quality and the reliability
of data-driven outcomes. To address these concerns, this article proposes an
imputation-free incremental attention learning (IFIAL) method for tabular data.
A pair of attention masks is derived and retrofitted to a transformer to
directly streamline tabular data without i...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>22. Robust training of implicit generative models for multivariate and   heavy-tailed distributions with an invariant statistical loss</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Jos√© Manuel de Frutos, Manuel A. V√°zquez, Pablo Olmos et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.AI, stat.CO, stat.ML</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2410.22381v2" target="_blank">arXiv:2410.22381v2</a> | 
                    <a href="http://arxiv.org/pdf/2410.22381v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Traditional implicit generative models are capable of learning highly complex
data distributions. However, their training involves distinguishing real data
from synthetically generated data using adversarial discriminators, which can
lead to unstable training dynamics and mode dropping issues. In this work, we
build on the \textit{invariant statistical loss} (ISL) method introduced in
\cite{de2024training}, and extend it to handle heavy-tailed and multivariate
data distributions.
  The data gene...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>23. SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic   Avatars</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Atikkhan Faridkhan Nilgar, Kristof Van Laerhoven, Ayub Kinoti</span><br>
                    <span class="meta-item">üìÅ cs.RO, cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04356v1" target="_blank">arXiv:2509.04356v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04356v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present SRWToolkit, an open-source Wizard of Oz toolkit designed to
facilitate the rapid prototyping of social robotic avatars powered by local
large language models (LLMs). Our web-based toolkit enables multimodal
interaction through text input, button-activated speech, and wake-word command.
The toolkit offers real-time configuration of avatar appearance, behavior,
language, and voice via an intuitive control panel. In contrast to prior works
that rely on cloud-based LLM services, SRWToolki...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>24. HumAIne-Chatbot: Real-Time Personalized Conversational AI via   Reinforcement Learning</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira et al.</span><br>
                    <span class="meta-item">üìÅ cs.HC, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04303v1" target="_blank">arXiv:2509.04303v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04303v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Current conversational AI systems often provide generic, one-size-fits-all
interactions that overlook individual user characteristics and lack adaptive
dialogue management. To address this gap, we introduce
\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes
responses through a novel user profiling framework. The system is pre-trained
on a diverse set of GPT-generated virtual personas to establish a broad prior
over user types. During live interactions, an online reinfo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 11 pages, 4 figures, IEEE conference format</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>25. OneSearch: A Preliminary Exploration of the Unified End-to-End   Generative Framework for E-commerce Search</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Ben Chen, Xian Guo, Siyuan Wang et al.</span><br>
                    <span class="meta-item">üìÅ cs.IR</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.03236v2" target="_blank">arXiv:2509.03236v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03236v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Traditional e-commerce search systems employ multi-stage cascading
architectures (MCA) that progressively filter items through recall,
pre-ranking, and ranking stages. While effective at balancing computational
efficiency with business conversion, these systems suffer from fragmented
computation and optimization objective collisions across stages, which
ultimately limit their performance ceiling. To address these, we propose
\textbf{OneSearch}, the first industrial-deployed end-to-end generative...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>26. Demographic-aware fine-grained classification of pediatric wrist   fractures</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, cs.AI, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2507.12964v5" target="_blank">arXiv:2507.12964v5</a> | 
                    <a href="http://arxiv.org/pdf/2507.12964v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Wrist pathologies are frequently observed, particularly among children who
constitute the majority of fracture cases. Computer vision presents a promising
avenue, contingent upon the availability of extensive datasets, a notable
challenge in medical imaging. Therefore, reliance solely on one modality, such
as images, proves inadequate, especially in an era of diverse and plentiful
data types. This study addresses the problem using a multifaceted approach:
framing it as a fine-grained recognition...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>27. Unveiling the Role of Data Uncertainty in Tabular Deep Learning</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Nikolay Kartashev, Ivan Rubachev, Artem Babenko</span><br>
                    <span class="meta-item">üìÅ cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04430v1" target="_blank">arXiv:2509.04430v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04430v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in tabular deep learning have demonstrated exceptional
practical performance, yet the field often lacks a clear understanding of why
these techniques actually succeed. To address this gap, our paper highlights
the importance of the concept of data uncertainty for explaining the
effectiveness of the recent tabular DL methods. In particular, we reveal that
the success of many beneficial design choices in tabular DL, such as numerical
feature embeddings, retrieval-augmented mode...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>28. One Flight Over the Gap: A Survey from Perspective to Panoramic Vision</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Xin Lin, Xian Ge, Dizhe Zhang et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04444v1" target="_blank">arXiv:2509.04444v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04444v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct doma...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>29. Durian: Dual Reference-guided Portrait Animation with Attribute Transfer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Hyunsoo Cha, Byungjun Kim, Hanbyul Joo</span><br>
                    <span class="meta-item">üìÅ cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04434v1" target="_blank">arXiv:2509.04434v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04434v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project Page: https://hyunsoocha.github.io/durian</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>30. Few-step Flow for 3D Generation via Marginal-Data Transport Distillation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Zanwei Zhou, Taoran Yi, Jiemin Fang et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04406v1" target="_blank">arXiv:2509.04406v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04406v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Margin...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project page: https://github.com/Zanue/MDT-dist</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>31. Integrating Pruning with Quantization for Efficient Deep Neural Networks   Compression</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Sara Makenali, Babak Rokh, Ali Azarpeyvand</span><br>
                    <span class="meta-item">üìÅ cs.NE</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04244v1" target="_blank">arXiv:2509.04244v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04244v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Deep Neural Networks (DNNs) have achieved significant advances in a wide
range of applications. However, their deployment on resource-constrained
devices remains a challenge due to the large number of layers and parameters,
which result in considerable computational and memory demands. To address this
issue, pruning and quantization are two widely used compression techniques,
commonly applied individually in most studies to reduce model size and enhance
processing speed. Nevertheless, combining ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>32. Pilot Study on Generative AI and Critical Thinking in Higher Education   Classrooms</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• W. F. Lamberti, S. R. Lawrence, D. White et al.</span><br>
                    <span class="meta-item">üìÅ cs.CY, cs.AI, cs.HC, stat.AP</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.00167v2" target="_blank">arXiv:2509.00167v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.00167v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Generative AI (GAI) tools have seen rapid adoption in educational settings,
yet their role in fostering critical thinking remains underexplored. While
previous studies have examined GAI as a tutor for specific lessons or as a tool
for completing assignments, few have addressed how students critically evaluate
the accuracy and appropriateness of GAI-generated responses. This pilot study
investigates students&#x27; ability to apply structured critical thinking when
assessing Generative AI outputs in in...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>33. Temporal Interest-Driven Multimodal Personalized Content Generation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Tian Miao</span><br>
                    <span class="meta-item">üìÅ cs.IR</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04330v1" target="_blank">arXiv:2509.04330v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04330v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With the dynamic evolution of user interests and the increasing multimodal
demands in internet applications, personalized content generation strategies
based on static interest preferences struggle to meet practical application
requirements. The proposed TIMGen (Temporal Interest-driven Multimodal
Generation) model addresses this challenge by modeling the long-term temporal
evolution of users&#x27; interests and capturing dynamic interest representations
with strong temporal dependencies. This model ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>34. A Survey of Graph Retrieval-Augmented Generation for Customized Large   Language Models</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Qinggang Zhang, Shengyuan Chen, Yuanchen Bei et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.AI, cs.IR</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2501.13958v2" target="_blank">arXiv:2501.13958v2</a> | 
                    <a href="http://arxiv.org/pdf/2501.13958v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-Augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>35. How many patients could we save with LLM priors?</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Shota Arai, David Selby, Andrew Vargo et al.</span><br>
                    <span class="meta-item">üìÅ stat.ME, cs.AI, cs.ET, cs.IR, stat.AP</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04250v1" target="_blank">arXiv:2509.04250v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04250v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Imagine a world where clinical trials need far fewer patients to achieve the
same statistical power, thanks to the knowledge encoded in large language
models (LLMs). We present a novel framework for hierarchical Bayesian modeling
of adverse events in multi-center clinical trials, leveraging LLM-informed
prior distributions. Unlike data augmentation approaches that generate
synthetic data points, our methodology directly obtains parametric priors from
the model. Our approach systematically elicit...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 4 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>36. PianoBind: A Multimodal Joint Embedding Model for Pop-piano Music</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Hayeon Bang, Eunjin Choi, Seungheon Doh et al.</span><br>
                    <span class="meta-item">üìÅ cs.SD, cs.IR, cs.MM</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04215v1" target="_blank">arXiv:2509.04215v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04215v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Solo piano music, despite being a single-instrument medium, possesses
significant expressive capabilities, conveying rich semantic information across
genres, moods, and styles. However, current general-purpose music
representation models, predominantly trained on large-scale datasets, often
struggle to captures subtle semantic distinctions within homogeneous solo piano
music. Furthermore, existing piano-specific representation models are typically
unimodal, failing to capture the inherently mult...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for publication at the 26th International Society for Music
  Information Retrieval Conference (ISMIR 2025)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>37. ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Adrian Catalin Lutu, Ioana Pintilie, Elena Burceanu et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04449v1" target="_blank">arXiv:2509.04449v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04449v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present ChronoGraph, a graph-structured multivariate time series
forecasting dataset built from real-world production microservices. Each node
is a service that emits a multivariate stream of system-level performance
metrics, capturing CPU, memory, and network usage patterns, while directed
edges encode dependencies between services. The primary task is forecasting
future values of these signals at the service level. In addition, ChronoGraph
provides expert-annotated incident windows as anoma...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>38. Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual   Try-On from a Single Image -- Technical Preview</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04450v1" target="_blank">arXiv:2509.04450v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04450v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining g...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project Page: https://immortalco.github.io/VirtualFittingRoom/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>39. Understanding sparse autoencoder scaling in the presence of feature   manifolds</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Eric J. Michaud, Liv Gorton, Tom McGrath</span><br>
                    <span class="meta-item">üìÅ cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.02565v2" target="_blank">arXiv:2509.02565v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02565v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Sparse autoencoders (SAEs) model the activations of a neural network as
linear combinations of sparsely occurring directions of variation (latents).
The ability of SAEs to reconstruct activations follows scaling laws w.r.t. the
number of latents. In this work, we adapt a capacity-allocation model from the
neural scaling literature (Brill, 2024) to understand SAE scaling, and in
particular, to understand how &quot;feature manifolds&quot; (multi-dimensional features)
influence scaling behavior. Consistent w...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 13 pages, 8 figures, short workshop submission</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>40. Bayesian Additive Regression Trees for functional ANOVA model</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Seokhun Park, Insung Kong, Yongdai Kim</span><br>
                    <span class="meta-item">üìÅ stat.ML, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.03317v2" target="_blank">arXiv:2509.03317v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03317v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Bayesian Additive Regression Trees (BART) is a powerful statistical model
that leverages the strengths of Bayesian inference and regression trees. It has
received significant attention for capturing complex non-linear relationships
and interactions among predictors. However, the accuracy of BART often comes at
the cost of interpretability. To address this limitation, we propose ANOVA
Bayesian Additive Regression Trees (ANOVA-BART), a novel extension of BART
based on the functional ANOVA decompos...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>41. Emancipatory Information Retrieval</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Bhaskar Mitra</span><br>
                    <span class="meta-item">üìÅ cs.IR, cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2501.19241v5" target="_blank">arXiv:2501.19241v5</a> | 
                    <a href="http://arxiv.org/pdf/2501.19241v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Our world today is facing a confluence of several mutually reinforcing crises
each of which intersects with concerns of social justice and emancipation. This
paper is a provocation for the role of computer-mediated information access in
our emancipatory struggles. We define emancipatory information retrieval as the
study and development of information access methods that challenge various
forms of human oppression, and situates its activities within broader
collective emancipatory praxis. The te...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>42. DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Hao-Shu Fang, Branden Romero, Yichen Xie et al.</span><br>
                    <span class="meta-item">üìÅ cs.RO, cs.HC, cs.CV, cs.AI</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04441v1" target="_blank">arXiv:2509.04441v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04441v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (vi...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: project page: https://dex-op.github.io</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>43. Towards Cognitively-Faithful Decision-Making Models to Improve AI   Alignment</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Cyrus Cousins, Vijay Keswani, Vincent Conitzer et al.</span><br>
                    <span class="meta-item">üìÅ cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04445v1" target="_blank">arXiv:2509.04445v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04445v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent AI work trends towards incorporating human-centric objectives, with
the explicit goal of aligning AI models to personal preferences and societal
values. Using standard preference elicitation methods, researchers and
practitioners build models of human decisions and judgments, which are then
used to align AI behavior with that of humans. However, models commonly used in
such elicitation processes often do not capture the true cognitive processes of
human decision making, such as when peopl...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>44. Echo State Networks as State-Space Models: A Systems Perspective</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Pradeep Singh, Balasubramanian Raman</span><br>
                    <span class="meta-item">üìÅ cs.LG, 93C10, 68T07, 93C05, 93E11, 93B30, 93B05, 93B07, 62M10, I.2.6; I.5.1; I.6.5; I.6.4; G.3</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04422v1" target="_blank">arXiv:2509.04422v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04422v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Echo State Networks (ESNs) are typically presented as efficient,
readout-trained recurrent models, yet their dynamics and design are often
guided by heuristics rather than first principles. We recast ESNs explicitly as
state-space models (SSMs), providing a unified systems-theoretic account that
links reservoir computing with classical identification and modern kernelized
SSMs. First, we show that the echo-state property is an instance of
input-to-state stability for a contractive nonlinear SSM ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 27 pages, 1 figure</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>45. The Telephone Game: Evaluating Semantic Drift in Unified Models</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Sabbir Mollah, Rohit Gupta, Sirnam Swetha et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL, cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04438v1" target="_blank">arXiv:2509.04438v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04438v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and G...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>46. From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray   Collimators via Hough Transform</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Benjamin El-Zein, Dominik Eckert, Andreas Fieselmann et al.</span><br>
                    <span class="meta-item">üìÅ cs.CV, physics.med-ph</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04437v1" target="_blank">arXiv:2509.04437v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04437v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrai...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>47. Can Language Models Handle a Non-Gregorian Calendar?</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Mutsumi Sasaki, Go Kamoda, Ryosuke Takahashi et al.</span><br>
                    <span class="meta-item">üìÅ cs.CL</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04432v1" target="_blank">arXiv:2509.04432v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04432v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>48. Pulling Back the Curtain on ReLU Networks</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Maciej Satkiewicz</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.CV, cs.NE, I.2.6; I.4.10</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2507.22832v3" target="_blank">arXiv:2507.22832v3</a> | 
                    <a href="http://arxiv.org/pdf/2507.22832v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Since any ReLU network is piecewise affine, its hidden units can be
characterized by their pullbacks through the active subnetwork, i.e., by their
gradients (up to bias terms). However, gradients of deeper neurons are
notoriously misaligned, which obscures the network&#x27;s internal representations.
We posit that models do align gradients with data, yet this is concealed by the
intrinsic noise of the ReLU hard gating. We validate this intuition by applying
soft gating in the backward pass only, redu...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages, 3-page appendix, 4 figures, preprint; v3 changes: changed
  title, improved abstract, expanded introduction, added section on
  implications of the path stability</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>49. We Have It Covered: A Resampling-based Method for Uplift Model   Comparison</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Yang Liu, Chaoyu Yuan</span><br>
                    <span class="meta-item">üìÅ stat.ME, stat.ML</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04315v1" target="_blank">arXiv:2509.04315v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04315v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Uplift models play a critical role in modern marketing applications to help
understand the incremental benefits of interventions and identify optimal
targeting strategies. A variety of techniques exist for building uplift models,
and it is essential to understand the model differences in the context of
intended applications. The uplift curve is a widely adopted tool for assessing
uplift model performance on the selection universe when observations are
available for the entire population. However...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>50. The Strong, Weak and Benign Goodhart&#x27;s law. An independence-free and   paradigm-agnostic formalisation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Adrien Majka, El-Mahdi El-Mhamdi</span><br>
                    <span class="meta-item">üìÅ stat.ML, cs.LG, math.ST, stat.TH</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2505.23445v2" target="_blank">arXiv:2505.23445v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.23445v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Goodhart&#x27;s law is a famous adage in policy-making that states that ``When a
measure becomes a target, it ceases to be a good measure&#x27;&#x27;. As machine learning
models and the optimisation capacity to train them grow, growing empirical
evidence reinforced the belief in the validity of this law without however
being formalised. Recently, a few attempts were made to formalise Goodhart&#x27;s
law, either by categorising variants of it, or by looking at how optimising a
proxy metric affects the optimisation o...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 32 pages, 1 figure</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>51. A Primer on Causal and Statistical Dataset Biases for Fair and Robust   Image Analysis</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Charles Jones, Ben Glocker</span><br>
                    <span class="meta-item">üìÅ cs.LG, cs.CY, stat.ML</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04295v1" target="_blank">arXiv:2509.04295v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04295v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Machine learning methods often fail when deployed in the real world. Worse
still, they fail in high-stakes situations and across socially sensitive lines.
These issues have a chilling effect on the adoption of machine learning methods
in settings such as medical diagnosis, where they are arguably best-placed to
provide benefits if safely deployed. In this primer, we introduce the causal
and statistical structures which induce failure in machine learning methods for
image analysis. We highlight t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Excerpt from C. Jones&#x27; PhD thesis. Winner of the G-Research PhD prize
  2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>52. Sharp Convergence Rates of Empirical Unbalanced Optimal Transport for   Spatio-Temporal Point Processes</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Marina Struleva, Shayan Hundrieser, Dominic Schuhmacher et al.</span><br>
                    <span class="meta-item">üìÅ math.ST, stat.ML, stat.TH, primary 62G05, 62G07, 62R20, secondary: 60D05, 60G60</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04225v1" target="_blank">arXiv:2509.04225v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04225v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We statistically analyze empirical plug-in estimators for unbalanced optimal
transport (UOT) formalisms, focusing on the Kantorovich-Rubinstein distance,
between general intensity measures based on observations from spatio-temporal
point processes. Specifically, we model the observations by two weakly
time-stationary point processes with spatial intensity measures $\mu$ and $\nu$
over the expanding window $(0,t]$ as $t$ increases to infinity, and establish
sharp convergence rates of the empirica...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The first two authors contributed equally, 76 pages, 7 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>53. Batched Stochastic Matching Bandits</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Jung-hun Kim, Min-hwan Oh</span><br>
                    <span class="meta-item">üìÅ stat.ML, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04194v1" target="_blank">arXiv:2509.04194v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04194v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this study, we introduce a novel bandit framework for stochastic matching
based on the Multi-nomial Logit (MNL) choice model. In our setting, $N$ agents
on one side are assigned to $K$ arms on the other side, where each arm
stochastically selects an agent from its assigned pool according to an unknown
preference and yields a corresponding reward. The objective is to minimize
regret by maximizing the cumulative revenue from successful matches across all
agents. This task requires solving a com...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>54. EMMA: Scaling Mobile Manipulation via Egocentric Human Data</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Lawrence Y. Zhu, Pranav Kuppili, Ryan Punamiya et al.</span><br>
                    <span class="meta-item">üìÅ cs.RO</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04443v1" target="_blank">arXiv:2509.04443v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04443v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>55. SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety   Certificates</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Babak Esmaeili, Hamidreza Modares</span><br>
                    <span class="meta-item">üìÅ eess.SY, cs.LG, cs.MA, cs.RO, cs.SY, math.OC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04413v1" target="_blank">arXiv:2509.04413v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04413v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper proposes a fully data-driven motion-planning framework for
homogeneous linear multi-agent systems that operate in shared, obstacle-filled
workspaces without access to explicit system models. Each agent independently
learns its closed-loop behavior from experimental data by solving convex
semidefinite programs that generate locally invariant ellipsoids and
corresponding state-feedback gains. These ellipsoids, centered along grid-based
waypoints, certify the dynamic feasibility of short...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Submitted to IEEE Transactions on Automation Science and Engineering</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>56. Taming High-Dimensional Dynamics: Learning Optimal Projections onto   Spectral Submanifolds</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Hugo Buurmeijer, Luis A. Pabon, John Irvin Alora et al.</span><br>
                    <span class="meta-item">üìÅ eess.SY, cs.RO, cs.SY</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2504.03157v2" target="_blank">arXiv:2504.03157v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.03157v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">High-dimensional nonlinear systems pose considerable challenges for modeling
and control across many domains, from fluid mechanics to advanced robotics.
Such systems are typically approximated with reduced-order models, which often
rely on orthogonal projections, a simplification that may lead to large
prediction errors. In this work, we derive optimality of fiber-aligned
projections onto spectral submanifolds, preserving the nonlinear geometric
structure and minimizing long-term prediction erro...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>57. Leveraging Equivariances and Symmetries in the Control Barrier Function   Synthesis</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Adrian Wiltz, Dimos V. Dimarogonas</span><br>
                    <span class="meta-item">üìÅ eess.SY, cs.RO, cs.SY</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04399v1" target="_blank">arXiv:2509.04399v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04399v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The synthesis of Control Barrier Functions (CBFs) often involves demanding
computations or a meticulous construction. However, structural properties of
the system dynamics and constraints have the potential to mitigate these
challenges. In this paper, we explore how equivariances in the dynamics,
loosely speaking a form of symmetry, can be leveraged in the CBF synthesis.
Although CBFs are generally not inherently symmetric, we show how equivariances
in the dynamics and symmetries in the constrai...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>58. Robotic Manipulation via Imitation Learning: Taxonomy, Evolution,   Benchmark, and Challenges</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Zezeng Li, Alexandre Chapin, Enda Xiang et al.</span><br>
                    <span class="meta-item">üìÅ cs.RO</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2508.17449v2" target="_blank">arXiv:2508.17449v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.17449v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Robotic Manipulation (RM) is central to the advancement of autonomous robots,
enabling them to interact with and manipulate objects in real-world
environments. This survey focuses on RM methodologies that leverage imitation
learning, a powerful technique that allows robots to learn complex manipulation
skills by mimicking human demonstrations. We identify and analyze the most
influential studies in this domain, selected based on community impact and
intrinsic quality. For each paper, we provide ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>59. Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the   Roles of Information Transparency, User Control, and Proactivity</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Atikkhan Faridkhan Nilgar, Manuel Dietrich, Kristof Van Laerhoven</span><br>
                    <span class="meta-item">üìÅ cs.RO, cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04358v1" target="_blank">arXiv:2509.04358v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04358v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Social robots are increasingly recognized as valuable supporters in the field
of well-being coaching. They can function as independent coaches or provide
support alongside human coaches, and healthcare professionals. In coaching
interactions, these robots often handle sensitive information shared by users,
making privacy a relevant issue. Despite this, little is known about the
factors that shape users&#x27; privacy perceptions. This research aims to examine
three key factors systematically: (1) the ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>60. Fuzzy to Clear: Elucidating the Threat Hunter Cognitive Process and   Cognitive Support Needs</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Alessandra Maciel Paz Milani, Arty Starr, Samantha Hill et al.</span><br>
                    <span class="meta-item">üìÅ cs.CR, cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2408.04348v3" target="_blank">arXiv:2408.04348v3</a> | 
                    <a href="http://arxiv.org/pdf/2408.04348v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With security threats increasing in frequency and severity, it is critical
that we consider the important role of threat hunters. These highly-trained
security professionals learn to see, identify, and intercept security threats.
Many recent works and existing tools in cybersecurity are focused on automating
the threat hunting process, often overlooking the critical human element. Our
study shifts this paradigm by emphasizing a human-centered approach to
understanding the lived experiences of th...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 22 Pages; 5 Figures; 8 Tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>61. Autonomation, Not Automation: Activities and Needs of European   Fact-checkers as a Basis for Designing Human-Centered AI Systems</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Andrea Hrckova, Robert Moro, Ivan Srba et al.</span><br>
                    <span class="meta-item">üìÅ cs.CY, cs.AI, cs.HC</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2211.12143v3" target="_blank">arXiv:2211.12143v3</a> | 
                    <a href="http://arxiv.org/pdf/2211.12143v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">To mitigate the negative effects of false information more effectively, the
development of Artificial Intelligence (AI) systems to assist fact-checkers is
needed. Nevertheless, the lack of focus on the needs of these stakeholders
results in their limited acceptance and skepticism toward automating the whole
fact-checking process. In this study, we conducted semi-structured in-depth
interviews with Central European fact-checkers. Their activities and problems
were analyzed using iterative content...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 44 pages, 13 figures, 2 annexes. Accepted to ACM Journal on
  Responsible Computing</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>62. Global-to-Local or Local-to-Global? Enhancing Image Retrieval with   Efficient Local Search and Effective Global Re-ranking</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Dror Aiger, Bingyi Cao, Kaifeng Chen et al.</span><br>
                    <span class="meta-item">üìÅ cs.IR, cs.CV</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04351v1" target="_blank">arXiv:2509.04351v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04351v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The dominant paradigm in image retrieval systems today is to search large
databases using global image features, and re-rank those initial results with
local image feature matching techniques. This design, dubbed global-to-local,
stems from the computational cost of local matching approaches, which can only
be afforded for a small number of retrieved images. However, emerging efficient
local feature search approaches have opened up new possibilities, in particular
enabling detailed retrieval at ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>63. Decoupled Entity Representation Learning for Pinterest Ads Ranking</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">üë• Jie Liu, Yinrui Li, Jiankai Sun et al.</span><br>
                    <span class="meta-item">üìÅ cs.IR, cs.AI, cs.LG</span><br>
                    <span class="meta-item">üîó <a href="http://arxiv.org/abs/2509.04337v1" target="_blank">arXiv:2509.04337v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04337v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this paper, we introduce a novel framework following an
upstream-downstream paradigm to construct user and item (Pin) embeddings from
diverse data sources, which are essential for Pinterest to deliver personalized
Pins and ads effectively. Our upstream models are trained on extensive data
sources featuring varied signals, utilizing complex architectures to capture
intricate relationships between users and Pins on Pinterest. To ensure
scalability of the upstream models, entity embeddings are l...</p>
                
            </div>

        </div>
        
        <footer class="card text-center" style="margin-top: 2rem;">
            <p class="text-muted mb-0">Generated on 2025-09-05 18:47:46</p>
        </footer>
    </div>
</body>
</html>