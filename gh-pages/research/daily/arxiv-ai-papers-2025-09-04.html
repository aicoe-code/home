<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Papers - 2025-09-05 - AICOE</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <div class="container">
        <nav class="breadcrumb">
            <a href="../../index.html">Home</a> / 
            <a href="../index.html">Research</a> / 
            <span>Daily AI Papers</span>
        </nav>
        
        <div class="research-hero">
            <h1>arXiv AI Papers - 2025-09-05</h1>
            <p>Daily collection of AI-related papers from arXiv. Total papers: 357</p>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-number">357</div>
                <div class="stat-label">Total Papers</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">141</div>
                <div class="stat-label">High Relevance</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">77</div>
                <div class="stat-label">Categories</div>
            </div>
        </div>
        
        <div class="research-content">

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>1. Foundations and Models in Modern Computer Vision: Key Building Blocks in   Landmark Architectures</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 8.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Radu-Andrei Bourceanu, Neil De La Fuente, Jan Grimm et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.23357v2" target="_blank">arXiv:2507.23357v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.23357v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This report analyzes the evolution of key design patterns in computer vision
by examining six influential papers. The analysis begins with foundational
architectures for image recognition. We review ResNet, which introduced
residual connections to overcome the vanishing gradient problem and enable
effective training of significantly deeper convolutional networks.
Subsequently, we examine the Vision Transformer (ViT), which established a new
paradigm by applying the Transformer architecture to se...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>2. Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of   Vision-Language Model</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 8.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Phuoc-Nguyen Bui, Khanh-Binh Nguyen, Hyunseung Choo</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03895v1" target="_blank">arXiv:2509.03895v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03895v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learning
framework that enhances CLIP&#x27;s adaptability via a dual attention mechanism. Our
design incorporates dataset-specific information through two components: the
Memory Attn-Adapter, which refines cate...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: ICCV 2025 - LIMIT Workshop</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>3. Arabic Chatbot Technologies in Education: An Overview</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 8.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hicham Bourhil, Yacine El Younoussi</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04066v1" target="_blank">arXiv:2509.04066v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04066v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-19
pandemic, there has been an increasing interest in these digital technologies
to allow and enhance remote access. In education, e-learning systems have been
massively adopted worldwide. The emergen...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published as a book chapter in: Transformaci\&#x27;on Digital en la
  Educaci\&#x27;on: Innovaciones y Desaf\&#x27;ios desde los Campus Virtuales (UA
  Journals, 2024), pp. 11-14</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>4. Plan Verification for LLM-Based Embodied Task Completion Agents</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 7.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ananth Hariharan, Vardhan Dongre, Dilek Hakkani-TÃ¼r et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02761v2" target="_blank">arXiv:2509.02761v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02761v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequences and a Planner LLM applies the revisions, yielding progressively
cleaner and more spatially coherent trajectories. Unlike rule-based approaches,
our method relies on natural language prompting, enab...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>5. PAK-UCB Contextual Bandit: An Online Learning Approach to Prompt-Aware   Selection of Generative Models and LLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 7.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiaoyan Hu, Ho-fung Leung, Farzan Farnia</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2410.13287v6" target="_blank">arXiv:2410.13287v6</a> | 
                    <a href="http://arxiv.org/pdf/2410.13287v6" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Selecting a sample generation scheme from multiple prompt-based generative
models, including large language models (LLMs) and prompt-guided image and
video generation models, is typically addressed by choosing the model that
maximizes an averaged evaluation score. However, this score-based selection
overlooks the possibility that different models achieve the best generation
performance for different types of text prompts. An online identification of
the best generation model for various input pr...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: accepted to ICML 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>6. SMooGPT: Stylized Motion Generation using Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 7.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lei Zhong, Yi Yang, Changjian Li</span><br>
                    <span class="meta-item">ğŸ“ cs.GR, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04058v1" target="_blank">arXiv:2509.04058v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04058v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey&#x27;&#x27;. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>7. CANDY: Benchmarking LLMs&#x27; Limitations and Assistive Potential in Chinese   Misinformation Fact-Checking</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 7.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ruiling Guo, Xinwei Yang, Chen Huang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03957v1" target="_blank">arXiv:2509.03957v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03957v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
we curate a carefully annotated dataset of ~20k instances. Our analysis shows
that current LLMs exhibit limitations in generating accurate fact-checking
conclusions, even when enhanced with chain-of-t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Findings of EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>8. MiniCPM4: Ultra-Efficient LLMs on End Devices</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥  MiniCPM Team, Chaojun Xiao, Yuxuan Li et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.07900v2" target="_blank">arXiv:2506.07900v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.07900v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper introduces MiniCPM4, a highly efficient large language model (LLM)
designed explicitly for end-side devices. We achieve this efficiency through
systematic innovation in four key dimensions: model architecture, training
data, training algorithms, and inference systems. Specifically, in terms of
model architecture, we propose InfLLM v2, a trainable sparse attention
mechanism that accelerates both prefilling and decoding phases for long-context
processing. Regarding training data, we pro...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: MiniCPM4 Technical Report</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>9. From Editor to Dense Geometry Estimator</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ JiYuan Wang, Chunyu Lin, Lei Sun et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04338v1" target="_blank">arXiv:2509.04338v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04338v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-tuning.
  Motivated by this, we conduct a systematic analysis of the fine-tuning
behaviors of both editors and generators for dense geometry estimation. Our
findings show that editing models possess in...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 20pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>10. Rapid Word Learning Through Meta In-Context Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wentao Wang, Guangyuan Jiang, Tal Linzen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.14791v4" target="_blank">arXiv:2502.14791v4</a> | 
                    <a href="http://arxiv.org/pdf/2502.14791v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Humans can quickly learn a new word from a few illustrative examples, and
then systematically and flexibly use it in novel contexts. Yet the abilities of
current language models for few-shot word learning, and methods for improving
these abilities, are underexplored. In this study, we introduce a novel method,
Meta-training for IN-context learNing Of Words (Minnow). This method trains
language models to generate new examples of a word&#x27;s usage given a few
in-context examples, using a special plac...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>11. DMN-Guided Prompting: A Framework for Controlling LLM Behavior</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shaghayegh Abedi, Amin Jalali</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.11701v2" target="_blank">arXiv:2505.11701v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.11701v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) have shown considerable potential in automating
decision logic within knowledge-intensive processes. However, their
effectiveness largely depends on the strategy and quality of prompting. Since
decision logic is typically embedded in prompts, it becomes challenging for end
users to modify or refine it. Decision Model and Notation (DMN) offers a
standardized graphical approach for defining decision logic in a structured,
user-friendly manner. This paper introduces a D...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Large Language Models, Decision Model and Notation, Automated
  Feedback, Prompt Engineering</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>12. Detecting Regional Spurious Correlations in Vision Transformers via   Token Discarding</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Solha Kang, Esla Timothy Anzaku, Wesley De Neve et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04009v1" target="_blank">arXiv:2509.04009v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04009v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues may
vary from simple color aberrations to small texts within the image. In
situations where these unintended signals align with the predictive task,
models can mistakenly link these features with the ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>13. EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Huanyu Liu, Jia Li, Chang Yu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.07809v2" target="_blank">arXiv:2508.07809v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.07809v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through explorat...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>14. Res-MoCoDiff: Residual-guided diffusion models for motion artifact   correction in brain MRI</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mojtaba Safari, Shansong Wang, Qiang Li et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, physics.med-ph</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.03498v2" target="_blank">arXiv:2505.03498v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.03498v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Objective. Motion artifacts in brain MRI, mainly from rigid head motion,
degrade image quality and hinder downstream applications. Conventional methods
to mitigate these artifacts, including repeated acquisitions or motion
tracking, impose workflow burdens. This study introduces Res-MoCoDiff, an
efficient denoising diffusion probabilistic model specifically designed for MRI
motion artifact correction.Approach.Res-MoCoDiff exploits a novel residual
error shifting mechanism during the forward diff...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>15. Aesthetic Image Captioning with Saliency Enhanced MLLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yilin Tao, Jiashui Huang, Huaze Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04378v1" target="_blank">arXiv:2509.04378v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04378v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
image aesthetics research that integrates both visual and textual modalities.
However, most existing studies on image aesthetics primarily focus on
predicting aesthetic ratings and have shown limited app...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>16. Imitating Radiological Scrolling: A Global-Local Attention Model for 3D   Chest CT Volumes Multi-Label Anomaly Classification</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Theo Di Piazza, Carole Lazarus, Olivier Nempont et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.20652v5" target="_blank">arXiv:2503.20652v5</a> | 
                    <a href="http://arxiv.org/pdf/2503.20652v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The rapid increase in the number of Computed Tomography (CT) scan
examinations has created an urgent need for automated tools, such as organ
segmentation, anomaly classification, and report generation, to assist
radiologists with their growing workload. Multi-label classification of
Three-Dimensional (3D) CT scans is a challenging task due to the volumetric
nature of the data and the variety of anomalies to be detected. Existing deep
learning methods based on Convolutional Neural Networks (CNNs)...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 13 pages, 4 figures. Accepted for publication at MIDL 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>17. TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ayan Banerjee, Josep LladÃ³s, Umapada Pal et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04123v1" target="_blank">arXiv:2509.04123v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04123v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response, we
introduce TaleDiffusion, a novel framework for generating multi-character
stories with an iterative process, maintaining character consistency, and
accurate dialogue assignment via postprocessing...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>18. ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD   Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhu Wenjie, Zhang Yabin, Xin Jin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03951v1" target="_blank">arXiv:2509.03951v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03951v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
significantly degrades their near-OOD performance. To address these issues, we
propose shaping an Adaptive Negative Textual Space (ANTS) by leveraging the
understanding and reasoning capabilities of multimo...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>19. A Generative Foundation Model for Chest Radiography</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuanfeng Ji, Dan Lin, Xiyue Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03903v1" target="_blank">arXiv:2509.03903v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03903v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen&#x27;, a generative vision-language foundation model that
introduces a unified framework for text-, mask-, and bounding box-guided
synthesis of chest radiographs. Built upon the latent diffusion transformer
architecture, ChexGen was pretrained on the largest cu...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>20. Synthesizing Sheet Music Problems for Evaluation and Reinforcement   Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 6.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhilin Wang, Zhe Yang, Yun Luo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04059v1" target="_blank">arXiv:2509.04059v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04059v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
propose the idea of synthesizing sheet music problems grounded in music theory,
which can serve both as evaluation benchmarks and as training data for
reinforcement learning with verifiable rewards (RLVR)...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 11 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>21. ACING: Actor-Critic for Instruction Learning in Black-Box LLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Salma Kharrat, Fares Fourati, Marco Canini</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.SY, math.OC, eess.SY, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.12736v2" target="_blank">arXiv:2411.12736v2</a> | 
                    <a href="http://arxiv.org/pdf/2411.12736v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The effectiveness of Large Language Models (LLMs) in solving tasks depends
significantly on the quality of their instructions, which often require
substantial human effort to craft. This underscores the need for automated
instruction optimization. However, optimizing instructions is particularly
challenging when working with black-box LLMs, where model parameters and
gradients are inaccessible. We introduce ACING, an actor-critic reinforcement
learning framework that formulates instruction optim...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>22. EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn   Negotiation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yunbo Long, Liming Xu, Lukas Beckenbauer et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04310v1" target="_blank">arXiv:2509.04310v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04310v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>23. Style Transfer to Calvin and Hobbes comics using Stable Diffusion</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Asvin Kumar Venkataramanan, Sloke Shrestha, Sundar Sripada Venugopalaswamy Sriraman</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2312.03993v2" target="_blank">arXiv:2312.03993v2</a> | 
                    <a href="http://arxiv.org/pdf/2312.03993v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This project report summarizes our journey to perform stable diffusion
fine-tuning on a dataset containing Calvin and Hobbes comics. The purpose is to
convert any given input image into the comic style of Calvin and Hobbes,
essentially performing style transfer. We train stable-diffusion-v1.5 using Low
Rank Adaptation (LoRA) to efficiently speed up the fine-tuning process. The
diffusion itself is handled by a Variational Autoencoder (VAE), which is a
U-net. Our results were visually appealing fo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Updated authorship</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>24. Enhancing Technical Documents Retrieval for RAG</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Songjiang Lai, Tsun-Hin Cheung, Ka-Chun Fung et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04139v1" target="_blank">arXiv:2509.04139v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04139v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this paper, we introduce Technical-Embeddings, a novel framework designed
to optimize semantic retrieval in technical documentation, with applications in
both hardware and software development. Our approach addresses the challenges
of understanding and retrieving complex technical content by leveraging the
capabilities of Large Language Models (LLMs). First, we enhance user queries by
generating expanded representations that better capture user intent and improve
dataset diversity, thereby en...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>25. MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image   Generation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuan Zhao, Liu Lin</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04126v1" target="_blank">arXiv:2509.04126v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04126v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Text-to-image diffusion models have achieved remarkable image quality, but
they still struggle with complex, multiele ment prompts, and limited stylistic
diversity. To address these limitations, we propose a Multi-Expert Planning and
Gen eration Framework (MEPG) that synergistically integrates position- and
style-aware large language models (LLMs) with spatial-semantic expert modules.
The framework comprises two core components: (1) a Position-Style-Aware (PSA)
module that utilizes a supervised ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>26. Transferable Mask Transformer: Cross-domain Semantic Segmentation with   Region-adaptive Transferability Estimation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jianhua Liu, Zhengyu Li, Yanru Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.05774v2" target="_blank">arXiv:2504.05774v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.05774v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advances in Vision Transformers (ViTs) have set new benchmarks in
semantic segmentation. However, when adapting pretrained ViTs to new target
domains, significant performance degradation often occurs due to distribution
shifts, resulting in suboptimal global attention. Since self-attention
mechanisms are inherently data-driven, they may fail to effectively attend to
key objects when source and target domains exhibit differences in texture,
scale, or object co-occurrence patterns. While gl...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>27. DaMoC: Efficiently Selecting the Optimal Large Language Model for   Fine-tuning Domain Tasks Based on Data and Model Compression</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wei Huang, Huang Wei, Yinggui Wang</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.01221v2" target="_blank">arXiv:2509.01221v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.01221v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first esta...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>28. CoT-Space: A Theoretical Framework for Internal Slow-Thinking via   Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zeyu Gan, Hao Yi, Yong Liu</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04027v1" target="_blank">arXiv:2509.04027v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04027v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimizati...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Preprint Edition</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>29. NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware   Embeddings</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Or Shachar, Uri Katz, Yoav Goldberg et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.IR, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04011v1" target="_blank">arXiv:2509.04011v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04011v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named
Entity Retrieval, a variant of Named Entity Recognition (NER), where the types
of interest are not provided in advance, and a user-defined type description is
used to retrieve documents mentioning entities of that type. Instead of relying
on fixed schemas or fine-tuned models, our method builds on internal
representations of large language models (LLMs) to embed both entity mentions
and user-provided open-ended type descr...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Findings of EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>30. Promptception: How Sensitive Are Large Multimodal Models to Prompts?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mohamed Insaf Ismithdeen, Muhammad Uzair Khattak, Salman Khan</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL, cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03986v1" target="_blank">arXiv:2509.03986v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03986v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduc...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>31. RL&#x27;s Razor: Why Online Reinforcement Learning Forgets Less</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Idan Shenfeld, Jyothish Pari, Pulkit Agrawal</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04259v1" target="_blank">arXiv:2509.04259v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04259v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Comparison of fine-tuning models with reinforcement learning (RL) and
supervised fine-tuning (SFT) reveals that, despite similar performance at a new
task, RL preserves prior knowledge and capabilities significantly better. We
find that the degree of forgetting is determined by the distributional shift,
measured as the KL-divergence between the fine-tuned and base policy evaluated
on the new task. Our analysis reveals that on-policy RL is implicitly biased
towards KL-minimal solutions among the ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>32. Synthetic Survival Data Generation for Heart Failure Prognosis Using   Deep Generative Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chanon Puttanawarut, Natcha Fongsrisin, Porntep Amornritvanich et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04245v1" target="_blank">arXiv:2509.04245v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04245v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Background: Heart failure (HF) research is constrained by limited access to
large, shareable datasets due to privacy regulations and institutional
barriers. Synthetic data generation offers a promising solution to overcome
these challenges while preserving patient confidentiality. Methods: We
generated synthetic HF datasets from institutional data comprising 12,552
unique patients using five deep learning models: tabular variational
autoencoder (TVAE), normalizing flow, ADSGAN, SurvivalGAN, and ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>33. Sailing Towards Zero-Shot State Estimation using Foundation Models   Combined with a UKF</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tobin Holtmann, David Stenger, Andres Posada-Moreno et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.LG, cs.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04213v1" target="_blank">arXiv:2509.04213v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04213v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">State estimation in control and systems engineering traditionally requires
extensive manual system identification or data-collection effort. However,
transformer-based foundation models in other domains have reduced data
requirements by leveraging pre-trained generalist models. Ultimately,
developing zero-shot foundation models of system dynamics could drastically
reduce manual deployment effort. While recent work shows that transformer-based
end-to-end approaches can achieve zero-shot performan...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for publication at CDC2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>34. COBRA: Multimodal Sensing Deep Learning Framework for Remote Chronic   Obesity Management via Wrist-Worn Activity Monitoring</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhengyang Shen, Bo Gao, Mayue Shi</span><br>
                    <span class="meta-item">ğŸ“ cs.CE, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04210v1" target="_blank">arXiv:2509.04210v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04210v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Chronic obesity management requires continuous monitoring of energy balance
behaviors, yet traditional self-reported methods suffer from significant
underreporting and recall bias, and difficulty in integration with modern
digital health systems. This study presents COBRA (Chronic Obesity Behavioral
Recognition Architecture), a novel deep learning framework for objective
behavioral monitoring using wrist-worn multimodal sensors. COBRA integrates a
hybrid D-Net architecture combining U-Net spatia...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 19 pages, 4 figures. *Correspondence: m.shi16@imperial.ac.uk.
  Accepted by the IUPESM World Congress on Medical Physics and Biomedical
  Engineering 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>35. Self-adaptive Dataset Construction for Real-World Multimodal Safety   Scenarios</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jingen Qu, Lijun Li, Bo Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CR, cs.CL, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04403v1" target="_blank">arXiv:2509.04403v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04403v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end c...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at EMNLP 2025 Findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>36. AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval   for Text-Based Person Anomaly Search</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hao Ju, Hu Zhang, Zhedong Zheng</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04376v1" target="_blank">arXiv:2509.04376v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04376v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
alignment between textual anomalies and visual behaviors, and (2) anomaly
recognition under sparse real-world samples. While Large Multi-modal Models
(LMMs) excel in multi-modal understanding, their pote...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>37. OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent   Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chen Hu, Shan Luo, Letizia Gionfrida</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04324v1" target="_blank">arXiv:2509.04324v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04324v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a visio...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>38. Enhanced Generative Data Augmentation for Semantic Segmentation via   Stronger Guidance</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Quang-Huy Che, Duc-Tri Le, Bich-Nga Pham et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2409.06002v5" target="_blank">arXiv:2409.06002v5</a> | 
                    <a href="http://arxiv.org/pdf/2409.06002v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Data augmentation is crucial for pixel-wise annotation tasks like semantic
segmentation, where labeling requires significant effort and intensive labor.
Traditional methods, involving simple transformations such as rotations and
flips, create new images but often lack diversity along key semantic dimensions
and fail to alter high-level semantic properties. To address this issue,
generative models have emerged as an effective solution for augmenting data by
generating synthetic images. Controllab...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published in ICPRAM 2025, ISBN 978-989-758-730-6, ISSN 2184-4313</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>39. SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiaofu Chen, Israfel Salazar, Yova Kementchedjhieva</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03897v1" target="_blank">arXiv:2509.03897v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03897v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show str...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>40. AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Guibin Zhang, Junhao Wang, Junjie Chen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.MA</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03312v2" target="_blank">arXiv:2509.03312v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03312v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly in...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>41. Measuring Bias or Measuring the Task: Understanding the Brittle Nature   of LLM Gender Biases</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Bufan Gao, Elisa Kreiss</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04373v1" target="_blank">arXiv:2509.04373v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04373v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully constructed
task prompts that overtly or covertly signal the presence of gender
bias-related content. In this paper, we examine how signaling the evaluative
purpose of a task impacts measured gender bias in L...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>42. Improving Narrative Classification and Explanation via Fine Tuned   Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Rishit Tyagi, Rahul Bouri, Mohit Gupta</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04077v1" target="_blank">arXiv:2509.04077v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04077v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Understanding covert narratives and implicit messaging is essential for
analyzing bias and sentiment. Traditional NLP methods struggle with detecting
subtle phrasing and hidden agendas. This study tackles two key challenges: (1)
multi-label classification of narratives and sub-narratives in news articles,
and (2) generating concise, evidence-based explanations for dominant
narratives. We fine-tune a BERT model with a recall-oriented approach for
comprehensive narrative detection, refining predic...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>43. Spotlight Attention: Towards Efficient LLM Generation via Non-linear   Hashing-based KV Cache Retrieval</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wenhao Li, Yuxin Zhang, Gen Luo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.19740v2" target="_blank">arXiv:2508.19740v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.19740v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embe...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>44. Exploring NLP Benchmarks in an Extremely Low-Resource Setting</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ulin Nuha, Adam Jatowt</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03962v1" target="_blank">arXiv:2509.03962v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03962v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remains limited,
making it difficult to develop robust language technologies. This paper
addresses such gap by focusing on Ladin, an endangered Romance language,
specifically targeting the Val Badia variant...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>45. SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by   Self-Play Fine-Tuning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuhao Zhang, Shaoming Duan, Jinhang Su et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03937v1" target="_blank">arXiv:2509.03937v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03937v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new information, and
the large number of correct SQL queries produced by the opponent model during
self-play reduces the main model&#x27;s ability to generate accurate SQL queries. To
address this challenge, we propo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025 Findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>46. Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yang Wang, Chenghao Xiao, Chia-Yi Hsiao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03867v1" target="_blank">arXiv:2509.03867v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03867v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce Drivelology, a unique linguistic phenomenon characterised as
&quot;nonsense with depth&quot;, utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit meaning requiring contextual inference, moral reasoning, or emotional
interpretation. We find that current large language models (LLMs), despite
excelling at many natural language processing (NLP) tas...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for oral presentation at the EMNLP 2025 Main Conference</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>47. Spatially-Enhanced Recurrent Memory for Long-Range Mapless Navigation   via End-to-End Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 5.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Fan Yang, Per Frivik, David Hoeller et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.05997v2" target="_blank">arXiv:2506.05997v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.05997v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in robot navigation, particularly with end-to-end
learning approaches such as reinforcement learning (RL), have demonstrated
strong performance. However, successful navigation still depends on two key
capabilities: mapping and planning (explicitly or implicitly). Classical
approaches rely on explicit mapping pipelines to register egocentric
observations into a coherent map. In contrast, end-to-end learning often
achieves this implicitly -- through recurrent neural networks (R...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 22 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>48. Delta Activations: A Representation for Finetuned Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhiqiu Xu, Amish Sethi, Mayur Naik et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.IR, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04442v1" target="_blank">arXiv:2509.04442v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04442v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured repositories.
We introduce Delta Activations, a method to represent finetuned models as
vector embeddings by measuring shifts in their internal activations relative to
a base model. This representation ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>49. ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Matthew Ho, Chen Si, Zhaoxiang Feng et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04439v1" target="_blank">arXiv:2509.04439v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04439v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>50. Towards a Unified View of Large Language Model Post-Training</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xingtai Lv, Yuxin Zuo, Youbang Sun et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04419v1" target="_blank">arXiv:2509.04419v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04419v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Two major sources of training data exist for post-training modern language
models: online (model-generated rollouts) data, and offline (human or
other-model demonstrations) data. These two types of data are typically used by
approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT),
respectively. In this paper, we show that these approaches are not in
contradiction, but are instances of a single optimization process. We derive a
Unified Policy Gradient Estimator, and present t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>51. Modular Techniques for Synthetic Long-Context Data Generation in   Language Model Training and Evaluation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Seganrasan Subramanian, Abhigya Verma</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.01185v2" target="_blank">arXiv:2509.01185v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.01185v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple tra...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 26 pages, 4 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>52. Psychologically Enhanced AI Agents</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Maciej Besta, Shriram Chandran, Robert Gerstenberger et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.MA, cs.CL, cs.CY, cs.AI, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04343v1" target="_blank">arXiv:2509.04343v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04343v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>53. AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lu Wang, Hao Chen, Siyu Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02349v2" target="_blank">arXiv:2509.02349v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02349v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multimodal Large Language Models (MLLMs) have been widely applied in speech
and music. This tendency has led to a focus on audio tokenization for Large
Models (LMs). Unlike semantic-only text tokens, audio tokens must both capture
global semantic content and preserve fine-grained acoustic details. Moreover,
they provide a discrete method for speech and music that can be effectively
integrated into MLLMs. However, existing research is unsuitable in the
definitions of semantic tokens and acoustic ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>54. DeepVIS: Bridging Natural Language and Data Visualization Through   Step-wise Reasoning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhihao Shuai, Boyan Li, Siyu Yan et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.01700v2" target="_blank">arXiv:2508.01700v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.01700v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Although data visualization is powerful for revealing patterns and
communicating insights, creating effective visualizations requires familiarity
with authoring tools and often disrupts the analysis flow. While large language
models show promise for automatically converting analysis intent into
visualizations, existing methods function as black boxes without transparent
reasoning processes, which prevents users from understanding design rationales
and refining suboptimal outputs. To bridge this ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: IEEE VIS 2025 full paper</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>55. CP-Bench: Evaluating Large Language Models for Constraint Modelling</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kostis Michailidis, Dimos Tsouros, Tias Guns</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.06052v2" target="_blank">arXiv:2506.06052v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.06052v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Constraint Programming (CP) is widely used to solve combinatorial problems,
but its core process, namely constraint modelling, requires significant
expertise and is considered to be a bottleneck for wider adoption. Aiming to
alleviate this bottleneck, recent studies have explored using Large Language
Models (LLMs) to transform combinatorial problem descriptions into executable
constraint models. However, the existing evaluation datasets for constraint
modelling are often limited to small, homoge...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: ECAI 25</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>56. Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility   for Resource-Efficient LLM Agent</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chunlong Wu, Zhibo Qu</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03990v1" target="_blank">arXiv:2509.03990v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03990v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we i...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>57. Expanding Foundational Language Capabilities in Open-Source LLMs through   a Korean Case Study</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junghwan Lim, Gangwon Jo, Sungmin Lee et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03972v1" target="_blank">arXiv:2509.03972v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03972v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce Llama-3-Motif, a language model consisting of 102 billion
parameters, specifically designed to enhance Korean capabilities while
retaining strong performance in English. Developed on the Llama 3 architecture,
Llama-3-Motif employs advanced training techniques, including LlamaPro and
Masked Structure Growth, to effectively scale the model without altering its
core Transformer architecture. Using the MoAI platform for efficient training
across hyperscale GPU clusters, we optimized Lla...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>58. PagedEviction: Structured Block-wise KV Cache Pruning for Efficient   Large Language Model Inference</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Krishna Teja Chitty-Venkata, Jie Ye, Xian-He Sun et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04377v1" target="_blank">arXiv:2509.04377v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04377v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">KV caching significantly improves the efficiency of Large Language Model
(LLM) inference by storing attention states from previously processed tokens,
enabling faster generation of subsequent tokens. However, as sequence length
increases, the KV cache quickly becomes a major memory bottleneck. To address
this, we propose PagedEviction, a novel fine-grained, structured KV cache
pruning strategy that enhances the memory efficiency of vLLM&#x27;s PagedAttention.
Unlike existing approaches that rely on a...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Preprint</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>59. Connections between reinforcement learning with feedback,test-time   scaling, and diffusion guidance: An anthology</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuchen Jiao, Yuxin Chen, Gen Li</span><br>
                    <span class="meta-item">ğŸ“ cs.GL, math.ST, stat.ML, stat.TH, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04372v1" target="_blank">arXiv:2509.04372v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04372v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this note, we reflect on several fundamental connections among widely used
post-training techniques. We clarify some intimate connections and equivalences
between reinforcement learning with human feedback, reinforcement learning with
internal feedback, and test-time scaling (particularly soft best-of-$N$
sampling), while also illuminating intrinsic links between diffusion guidance
and test-time scaling. Additionally, we introduce a resampling approach for
alignment and reward-directed diffus...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>60. Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven   Inference-Time-Scaling Algorithm</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Siddharth Mansingh, James Amarel, Ragib Arnab et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, physics.comp-ph</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02846v2" target="_blank">arXiv:2509.02846v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02846v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Partial Differential Equations (PDEs) are the bedrock for modern
computational sciences and engineering, and inherently computationally
expensive. While PDE foundation models have shown much promise for simulating
such complex spatio-temporal phenomena, existing models remain constrained by
the pretraining datasets and struggle with auto-regressive rollout performance,
especially in out-of-distribution (OOD) cases. Furthermore, they have
significant compute and training data requirements which h...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>61. An Unsupervised Natural Language Processing Pipeline for Assessing   Referral Appropriateness</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Vittorio Torri, Annamaria Bottelli, Michele Ercolanoni et al.</span><br>
                    <span class="meta-item">ğŸ“ I.2.7; J.1; J.3, 68T50, cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2501.14701v2" target="_blank">arXiv:2501.14701v2</a> | 
                    <a href="http://arxiv.org/pdf/2501.14701v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Objective: Assessing the appropriateness of diagnostic referrals is critical
for improving healthcare efficiency and reducing unnecessary procedures.
However, this task becomes challenging when referral reasons are recorded only
as free text rather than structured codes, like in the Italian NHS. To address
this gap, we propose a fully unsupervised Natural Language Processing (NLP)
pipeline capable of extracting and evaluating referral reasons without relying
on labelled datasets.
  Methods: Our ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 49 pages, 10 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>62. Straighter Flow Matching via a Diffusion-Based Coupling Prior</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Siyu Xing, Jie Cao, Huaibo Huang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2311.16507v2" target="_blank">arXiv:2311.16507v2</a> | 
                    <a href="http://arxiv.org/pdf/2311.16507v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Flow matching as a paradigm of generative model achieves notable success
across various domains. However, existing methods use either multi-round
training or knowledge within minibatches, posing challenges in finding a
favorable coupling strategy for straightening trajectories to few-step
generation. To address this issue, we propose a novel approach, Straighter
trajectories of Flow Matching (StraightFM). It straightens trajectories with
the coupling strategy from the entire distribution level. ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>63. One-Embedding-Fits-All: Efficient Zero-Shot Time Series Forecasting by a   Model Zoo</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hao-Nan Shi, Ting-Ji Huang, Lu Han et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04208v1" target="_blank">arXiv:2509.04208v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04208v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The proliferation of Time Series Foundation Models (TSFMs) has significantly
advanced zero-shot forecasting, enabling predictions for unseen time series
without task-specific fine-tuning. Extensive research has confirmed that no
single TSFM excels universally, as different models exhibit preferences for
distinct temporal patterns. This diversity suggests an opportunity: how to take
advantage of the complementary abilities of TSFMs. To this end, we propose
ZooCast, which characterizes each model&#x27;...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>64. KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and   Runtime Logs Analysis</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Omri Sgan Cohen, Ehud Malul, Yair Meidan et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CR, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04191v1" target="_blank">arXiv:2509.04191v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04191v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents Kub...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>65. TRUST-VL: An Explainable News Assistant for General Multimodal   Misinformation Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zehong Yan, Peng Qi, Wynne Hsu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.MM</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04448v1" target="_blank">arXiv:2509.04448v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04448v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and e...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025; Project Homepage: https://yanzehong.github.io/trust-vl/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>66. Plot&#x27;n Polish: Zero-shot Story Visualization and Disentangled Editing   with Text-to-Image Diffusion Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kiymet Akdemir, Jing Shi, Kushal Kafle et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04446v1" target="_blank">arXiv:2509.04446v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04446v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>67. TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D   Diffusion Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuxin Gong, Se-in Jang, Wei Shao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04269v1" target="_blank">arXiv:2509.04269v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04269v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Accurate quantification of tau pathology via tau positron emission tomography
(PET) scan is crucial for diagnosing and monitoring Alzheimer&#x27;s disease (AD).
However, the high cost and limited availability of tau PET restrict its
widespread use. In contrast, structural magnetic resonance imaging (MRI) and
plasma-based biomarkers provide non-invasive and widely available complementary
information related to brain anatomy and disease progression. In this work, we
propose a text-guided 3D diffusion m...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 4 figures, submitted to IEEE Transactions on Radiation and
  Plasma Medical Sciences</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>68. Spatial-aware Transformer-GRU Framework for Enhanced Glaucoma Diagnosis   from 3D OCT Imaging</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mona Ashtari-Majlan, David Masip</span><br>
                    <span class="meta-item">ğŸ“ eess.IV, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2403.05702v2" target="_blank">arXiv:2403.05702v2</a> | 
                    <a href="http://arxiv.org/pdf/2403.05702v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Glaucoma, a leading cause of irreversible blindness, necessitates early
detection for accurate and timely intervention to prevent irreversible vision
loss. In this study, we present a novel deep learning framework that leverages
the diagnostic value of 3D Optical Coherence Tomography (OCT) imaging for
automated glaucoma detection. In this framework, we integrate a pre-trained
Vision Transformer on retinal data for rich slice-wise feature extraction and a
bidirectional Gated Recurrent Unit for ca...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>69. Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures   for On-Device Image Generation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sanchar Palit, Sathya Veera Reddy Dendi, Mallikarjuna Talluri et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.06119v2" target="_blank">arXiv:2411.06119v2</a> | 
                    <a href="http://arxiv.org/pdf/2411.06119v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Vision Transformers and U-Net architectures have been widely adopted in the
implementation of Diffusion Models. However, each architecture presents
specific challenges while realizing them on-device. Vision Transformers require
positional embedding to maintain correspondence between the tokens processed by
the transformer, although they offer the advantage of using fixed-size,
reusable repetitive blocks following tokenization. The U-Net architecture lacks
these attributes, as it utilizes variabl...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: presented at IJCNN 2025 poster track</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>70. R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code   Completion Abilities of Code Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ken Deng, Jiaheng Liu, He Zhu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.SE</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2406.01359v3" target="_blank">arXiv:2406.01359v3</a> | 
                    <a href="http://arxiv.org/pdf/2406.01359v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Code completion models have made significant progress in recent years.
Recently, repository-level code completion has drawn more attention in modern
software development, and several baseline methods and benchmarks have been
proposed. However, existing repository-level code completion methods often fall
short of fully using the extensive context of a project repository, such as the
intricacies of relevant files and class hierarchies. Besides, the existing
benchmarks usually focus on limited code...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>71. Small Changes, Large Consequences: Analyzing the Allocational Fairness   of LLMs in Hiring Contexts</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Preethi Seshadri, Hongyu Chen, Sameer Singh et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2501.04316v2" target="_blank">arXiv:2501.04316v2</a> | 
                    <a href="http://arxiv.org/pdf/2501.04316v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) are increasingly being deployed in high-stakes
applications like hiring, yet their potential for unfair decision-making
remains understudied in generative and retrieval settings. In this work, we
examine the allocational fairness of LLM-based hiring systems through two tasks
that reflect actual HR usage: resume summarization and applicant ranking. By
constructing a synthetic resume dataset with controlled perturbations and
curating job postings, we investigate whethe...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>72. Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow   Real Instructions?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qinyan Zhang, Xinping Lei, Ruijie Miao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04292v1" target="_blank">arXiv:2509.04292v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04292v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) achieve strong performance on diverse tasks but
often exhibit cognitive inertia, struggling to follow instructions that
conflict with the standardized patterns learned during supervised fine-tuning
(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that
measures models Counter-intuitive Abilitytheir capacity to override
training-induced biases and comply with adversarial instructions. Inverse
IFEval introduces eight types of such challenges, i...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>73. Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large   Language Models via a Multi-Paradigm Perspective</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yiyao Yu, Yuxiang Zhang, Dongdong Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2501.11110v4" target="_blank">arXiv:2501.11110v4</a> | 
                    <a href="http://arxiv.org/pdf/2501.11110v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) have made notable progress in mathematical
reasoning, yet often rely on single-paradigm reasoning, limiting their
effectiveness across diverse tasks. We introduce Chain-of-Reasoning (CoR), a
novel unified framework integrating multiple reasoning paradigms--Natural
Language Reasoning (NLR), Algorithmic Reasoning (AR), and Symbolic Reasoning
(SR)--to enable synergistic collaboration. CoR generates multiple potential
answers via different reasoning paradigms and synthes...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to ACL 2025 (Main)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>74. Context Reasoner: Incentivizing Reasoning Capability for Contextualized   Privacy and Safety Compliance via Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wenbin Hu, Haoran Li, Huihao Jing et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.14585v2" target="_blank">arXiv:2505.14585v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.14585v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">While Large Language Models (LLMs) exhibit remarkable capabilities, they also
introduce significant safety and privacy risks. Current mitigation strategies
often fail to preserve contextual reasoning capabilities in risky scenarios.
Instead, they rely heavily on sensitive pattern matching to protect LLMs, which
limits the scope. Furthermore, they overlook established safety and privacy
standards, leading to systemic risks for legal compliance. To address these
gaps, we formulate safety and priva...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to EMNLP 2025 Main</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>75. A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Han Xiaohui, Zhang Yunlong, Guo Yuxi</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, I.2.7</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04046v1" target="_blank">arXiv:2509.04046v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04046v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Systemic Functional Grammar and its branch, Cardiff Grammar, have been widely
applied to discourse analysis, semantic function research, and other tasks
across various languages and texts. However, an automatic annotation system
based on this theory for Chinese texts has not yet been developed, which
significantly constrains the application and promotion of relevant theories. To
fill this gap, this research introduces a functional syntax annotation model
for Chinese based on RoBERTa (Robustly Op...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The paper includes 10 pages, 6 tables, and 4 figures. This project is
  completed with the assistance of National Center for Language Technology and
  Digital Economy Research (No. GJLX20250002), and is funded by Heilongjiang
  Language Research Committee Project Construction of an Adaptive Intelligent
  Chinese Learning Platform for International Students in China (No. G2025Y003)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>76. Training LLMs to be Better Text Embedders through Bidirectional   Reconstruction</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chang Su, Dengliang Shi, Siyuan Huang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03020v2" target="_blank">arXiv:2509.03020v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03020v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) have increasingly been explored as powerful text
embedders. Existing LLM-based text embedding approaches often leverage the
embedding of the final token, typically a reserved special token such as [EOS].
However, these tokens have not been intentionally trained to capture the
semantics of the whole context, limiting their capacity as text embeddings,
especially for retrieval and re-ranking tasks. We propose to add a new training
stage before contrastive learning to e...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: accepted by EMNLP 2025 Main Conference</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>77. SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented   Generation via Distribution Self-Alignment</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuqing Huang, Rongyang Zhang, Qimeng Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03934v1" target="_blank">arXiv:2509.03934v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03934v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in large language models (LLMs) have revolutionized
natural language processing through their remarkable capabilities in
understanding and executing diverse tasks. While supervised fine-tuning,
particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively
enhances task-specific performance, it often leads to catastrophic forgetting,
where models lose their previously acquired knowledge and general capabilities.
Existing solutions either require access to general...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>78. MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question   Answering</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Fengxiao Tang, Yufeng Li, Zongzong Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03918v1" target="_blank">arXiv:2509.03918v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03918v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Complex Question Answering (QA) is a fundamental and challenging task in NLP.
While large language models (LLMs) exhibit impressive performance in QA, they
suffer from significant performance degradation when facing complex and
abstract QA tasks due to insufficient reasoning capabilities. Works such as
Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs&#x27; reasoning
abilities, but they face issues such as in-layer redundancy in tree structures
and single paths in chain structures....</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>79. How Can I Publish My LLM Benchmark Without Giving the True Answers Away?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Takashi Ishida, Thanawat Lodkaew, Ikko Yamane</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.AI, cs.CL, stat.ME</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.18102v5" target="_blank">arXiv:2505.18102v5</a> | 
                    <a href="http://arxiv.org/pdf/2505.18102v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Publishing a large language model (LLM) benchmark on the Internet risks
contaminating future LLMs: the benchmark may be unintentionally (or
intentionally) used to train or select a model. A common mitigation is to keep
the benchmark private and let participants submit their models or predictions
to the organizers. However, this strategy will require trust in a single
organization and still permits test-set overfitting through repeated queries.
To overcome this issue, we propose a way to publish ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Extended version of the paper presented as an Oral at the ICML 2025
  Workshop on the Impact of Memorization on Trustworthy Foundation Models</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>80. Diffusion Generative Models Meet Compressed Sensing, with Applications   to Image Data and Financial Time Series</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhengyi Guo, Jiatu Li, Wenpin Tang et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03898v1" target="_blank">arXiv:2509.03898v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03898v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper develops dimension reduction techniques for accelerating diffusion
model inference in the context of synthetic data generation. The idea is to
integrate compressed sensing into diffusion models: (i) compress the data into
a latent space, (ii) train a diffusion model in the latent space, and (iii)
apply a compressed sensing algorithm to the samples generated in the latent
space, facilitating the efficiency of both model training and inference. Under
suitable sparsity assumptions on dat...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>81. INGRID: Intelligent Generative Robotic Design Using Large Language   Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Guanglu Jia, Ceng Zhang, Gregory S. Chirikjian</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03842v1" target="_blank">arXiv:2509.03842v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03842v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with recipro...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages, 6 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>82. Write on Paper, Wrong in Practice: Why LLMs Still Struggle with Writing   Clinical Notes</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kristina L. Kupferschmidt, Kieran O&#x27;Doherty, Joshua A. Skorburg</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04340v1" target="_blank">arXiv:2509.04340v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04340v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) are often proposed as tools to streamline
clinical documentation, a task viewed as both high-volume and low-risk.
However, even seemingly straightforward applications of LLMs raise complex
sociotechnical considerations to translate into practice. This case study,
conducted at KidsAbility, a pediatric rehabilitation facility in Ontario,
Canada examined the use of LLMs to support occupational therapists in reducing
documentation burden.We conducted a qualitative study ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>83. TimeCopilot</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Azul Garza, ReneÃ© Rosillo</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.AI, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.00616v2" target="_blank">arXiv:2509.00616v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.00616v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce TimeCopilot, the first open-source agentic framework for
forecasting that combines multiple Time Series Foundation Models (TSFMs) with
Large Language Models (LLMs) through a single unified API. TimeCopilot
automates the forecasting pipeline: feature analysis, model selection,
cross-validation, and forecast generation, while providing natural language
explanations and supporting direct queries about the future. The framework is
LLM-agnostic, compatible with both commercial and open-s...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>84. MultiConIR: Towards multi-condition Information Retrieval</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 4.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xuan Lu, Sifan Liu, Bochao Yin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.08046v3" target="_blank">arXiv:2503.08046v3</a> | 
                    <a href="http://arxiv.org/pdf/2503.08046v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multi-condition information retrieval (IR) presents a significant, yet
underexplored challenge for existing systems. This paper introduces MultiConIR,
a benchmark specifically designed to evaluate retrieval and reranking models
under nuanced multi-condition query scenarios across five diverse domains. We
systematically assess model capabilities through three critical tasks:
complexity robustness, relevance monotonicity, and query format sensitivity.
Our extensive experiments on 15 models reveal ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025 Findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>85. No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in   Resume Screening</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CY, K.4.2, cs.AI, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04404v1" target="_blank">arXiv:2509.04404v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04404v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this study, we conduct a resume-screening experiment (N=528) where people
collaborate with simulated AI models exhibiting race-based preferences (bias)
to evaluate candidates for 16 high and low status occupations. Simulated AI
bias approximates factual and counterfactual estimates of racial bias in
real-world AI systems. We investigate people&#x27;s preferences for White, Black,
Hispanic, and Asian candidates (represented through names and affinity groups
on quality-controlled resumes) across 1,5...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published in Proceedings of the 2025 AAAI/ACM Conference on AI,
  Ethics, and Society; code available at
  https://github.com/kyrawilson/No-Thoughts-Just-AI</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>86. IPA: An Information-Preserving Input Projection Framework for Efficient   Foundation Model Adaptation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuan Yin, Shashanka Venkataramanan, Tuan-Hung Vu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04398v1" target="_blank">arXiv:2509.04398v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04398v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, reduce
adaptation cost by injecting low-rank updates into pretrained weights. However,
LoRA&#x27;s down-projection is randomly initialized and data-agnostic, discarding
potentially useful information. Prior analyses show that this projection
changes little during training, while the up-projection carries most of the
adaptation, making the random input compression a performance bottleneck. We
propose IPA, a feature-aware projection framewor...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>87. Parking Availability Prediction via Fusing Multi-Source Data with A   Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yin Huang, Yongqi Dong, Youhua Tang et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04362v1" target="_blank">arXiv:2509.04362v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04362v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The rapid growth of private car ownership has worsened the urban parking
predicament, underscoring the need for accurate and effective parking
availability prediction to support urban planning and management. To address
key limitations in modeling spatio-temporal dependencies and exploiting
multi-source data for parking availability prediction, this study proposes a
novel approach with SST-iTransformer. The methodology leverages K-means
clustering to establish parking cluster zones (PCZs), extra...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 25 pages, 5 figures, under review for journal publication</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>88. Transplant Then Regenerate: A New Paradigm for Text Data Augmentation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Guangzhan Wang, Hongyu Zhang, Beijun Shen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.14723v2" target="_blank">arXiv:2508.14723v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.14723v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Data augmentation is a critical technique in deep learning. Traditional
methods like Back-translation typically focus on lexical-level rephrasing,
which primarily produces variations with the same semantics. While large
language models (LLMs) have enhanced text augmentation by their &quot;knowledge
emergence&quot; capability, controlling the style and structure of these outputs
remains challenging and requires meticulous prompt engineering. In this paper,
we propose LMTransplant, a novel text augmentation...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>89. Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with   Adaptive Exploration</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhicheng Yang, Zhijiang Guo, Yinya Huang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.13755v2" target="_blank">arXiv:2508.13755v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.13755v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reinforcement Learning with Verifiable Reward (RLVR) has emerged as a
powerful paradigm for unlocking reasoning capabilities in large language
models, yet its full potential is hindered by two under-explored dimensions:
Depth-the hardest problem a model can sample; Breadth-the number of instances
consumed in a single iteration. We dissect the popular GRPO algorithm and
reveal a systematic bias: the cumulative-advantage disproportionately weights
samples with medium accuracy, while down-weighting...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 16 pages, 14 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>90. Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge   in Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Juraj Vladika, Mahdi Dhaini, Florian Matthes</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04304v1" target="_blank">arXiv:2509.04304v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04304v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The growing capabilities of Large Language Models (LLMs) show significant
potential to enhance healthcare by assisting medical researchers and
physicians. However, their reliance on static training data is a major risk
when medical recommendations evolve with new research and developments. When
LLMs memorize outdated medical knowledge, they can provide harmful advice or
fail at clinical reasoning tasks. To investigate this problem, we introduce two
novel question-answering (QA) datasets derived ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to Findings of EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>91. HumAIne-Chatbot: Real-Time Personalized Conversational AI via   Reinforcement Learning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04303v1" target="_blank">arXiv:2509.04303v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04303v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Current conversational AI systems often provide generic, one-size-fits-all
interactions that overlook individual user characteristics and lack adaptive
dialogue management. To address this gap, we introduce
\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes
responses through a novel user profiling framework. The system is pre-trained
on a diverse set of GPT-generated virtual personas to establish a broad prior
over user types. During live interactions, an online reinfo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 11 pages, 4 figures, IEEE conference format</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>92. Street-Level AI: Are Large Language Models Ready for Real-World   Judgments?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Gaurab Pokharel, Shafkat Farabi, Patrick J. Fowler et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CY, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.08193v2" target="_blank">arXiv:2508.08193v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.08193v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A surge of recent work explores the ethical and societal implications of
large-scale AI models that make &quot;moral&quot; judgments. Much of this literature
focuses either on alignment with human judgments through various thought
experiments or on the group fairness implications of AI judgments. However, the
most immediate and likely use of AI is to help or fully replace the so-called
street-level bureaucrats, the individuals deciding to allocate scarce social
resources or approve benefits. There is a ri...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: This work has been accepted for publication as a full paper at the
  AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>93. TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D   Visual Grounding based on CLIP</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Fan Li, Zanyi Wang, Zeyi Huang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.14904v2" target="_blank">arXiv:2507.14904v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.14904v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">3D visual grounding allows an embodied agent to understand visual information
in real-world 3D environments based on human instructions, which is crucial for
embodied intelligence. Existing 3D visual grounding methods typically rely on
separate encoders for different modalities (e.g., RGB images, text, and 3D
point clouds), resulting in large and complex models that are inefficient to
train. While some approaches use pre-trained 2D multi-modal models like CLIP
for 3D tasks, they still struggle w...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>94. MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn   Mental Health Counseling Sessions</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04183v1" target="_blank">arXiv:2509.04183v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04183v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The growing demand for scalable psychological counseling highlights the need
for fine-tuning open-source Large Language Models (LLMs) with high-quality,
privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,
a novel multi-agent framework for synthetic psychological counseling session
generation that decomposes counselor response generation into coordinated
sub-tasks handled by specialized LLM agents, each modeling a key psychological
technique. Unlike prior single-agent ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 25 pages, 29 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>95. VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer   Vision</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Safouane El Ghazouali, Umberto Michelucci</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04180v1" target="_blank">arXiv:2509.04180v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04180v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">AI models rely on annotated data to learn pattern and perform prediction.
Annotation is usually a labor-intensive step that require associating labels
ranging from a simple classification label to more complex tasks such as object
detection, oriented bounding box estimation, and instance segmentation.
Traditional tools often require extensive manual input, limiting scalability
for large datasets. To address this, we introduce VisioFirm, an open-source web
application designed to streamline image...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>96. Robust training of implicit generative models for multivariate and   heavy-tailed distributions with an invariant statistical loss</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ JosÃ© Manuel de Frutos, Manuel A. VÃ¡zquez, Pablo Olmos et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.AI, stat.CO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2410.22381v2" target="_blank">arXiv:2410.22381v2</a> | 
                    <a href="http://arxiv.org/pdf/2410.22381v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Traditional implicit generative models are capable of learning highly complex
data distributions. However, their training involves distinguishing real data
from synthetically generated data using adversarial discriminators, which can
lead to unstable training dynamics and mode dropping issues. In this work, we
build on the \textit{invariant statistical loss} (ISL) method introduced in
\cite{de2024training}, and extend it to handle heavy-tailed and multivariate
data distributions.
  The data gene...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>97. Crossing the Species Divide: Transfer Learning from Speech to Animal   Sounds</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jules Cauzinille, Marius Miron, Olivier Pietquin et al.</span><br>
                    <span class="meta-item">ğŸ“ 68T07, cs.CL, cs.SD, cs.AI, I.5.4; I.2.6; H.5.5, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04166v1" target="_blank">arXiv:2509.04166v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04166v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Self-supervised speech models have demonstrated impressive performance in
speech processing, but their effectiveness on non-speech data remains
underexplored. We study the transfer learning capabilities of such models on
bioacoustic detection and classification tasks. We show that models such as
HuBERT, WavLM, and XEUS can generate rich latent representations of animal
sounds across taxa. We analyze the models properties with linear probing on
time-averaged representations. We then extend the ap...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 5 pages, 3 figures, uses dcase2025.sty, submitted to DCASE 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>98. TAGAL: Tabular Data Generation using Agentic LLM Methods</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ BenoÃ®t Ronval, Pierre Dupont, Siegfried Nijssen</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04152v1" target="_blank">arXiv:2509.04152v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04152v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The generation of data is a common approach to improve the performance of
machine learning tasks, among which is the training of models for
classification. In this paper, we present TAGAL, a collection of methods able
to generate synthetic tabular data using an agentic workflow. The methods
leverage Large Language Models (LLMs) for an automatic and iterative process
that uses feedback to improve the generated data without any further LLM
training. The use of LLMs also allows for the addition of ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>99. Oyster-I: Beyond Refusal -- Constructive Safety Alignment for   Responsible Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ranjie Duan, Jiexi Liu, Xiaojun Jia et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SC, cs.CL, cs.CY, cs.AI, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.01909v2" target="_blank">arXiv:2509.01909v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.01909v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model&#x27;s response can strongly
influence the user&#x27;s next actions. Simple re...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Technical Report Code &amp; Model weights available:
  https://github.com/Alibaba-AAIG/Oyster</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>100. Diffusion on language model encodings for protein sequence generation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov et al.</span><br>
                    <span class="meta-item">ğŸ“ q-bio.BM, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2403.03726v3" target="_blank">arXiv:2403.03726v3</a> | 
                    <a href="http://arxiv.org/pdf/2403.03726v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Protein sequence design has seen significant advances through discrete
diffusion and autoregressive approaches, yet the potential of continuous
diffusion remains underexplored. Here, we present DiMA, a latent diffusion
framework that operates on protein language model representations. Through
systematic exploration of architectural choices and diffusion components, we
develop a robust methodology that generalizes across multiple protein encoders
ranging from 8M to 3B parameters. We demonstrate t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>101. Intermediate Languages Matter: Formal Languages and LLMs affect   Neurosymbolic Reasoning</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Alexander Beiser, David Penz, Nysret Musliu</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04083v1" target="_blank">arXiv:2509.04083v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04083v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: To appear in the proceedings of The Second Workshop on Knowledge
  Graphs and Neurosymbolic AI (KG-NeSy) Co-located with SEMANTiCS 2025
  Conference, Vienna, Austria - September 3rd, 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>102. RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging   Evaluation of Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jingjing Liu, Zeming Liu, Zihao Cheng et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SE, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04078v1" target="_blank">arXiv:2509.04078v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04078v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM&#x27;s function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenar...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 30 pages, 12 figures, EMNLP 2025 Findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>103. Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lennart Clasmeier, Jan-Gerrit Habekost, Connor GÃ¤de et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04076v1" target="_blank">arXiv:2509.04076v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04076v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its ou...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Submitted to ICANN 20255 Special Session on Neural Robotics</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>104. On Robustness and Reliability of Benchmark-Based Evaluation of LLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Riccardo Lunardi, Vincenzo Della Mea, Stefano Mizzaro et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04013v1" target="_blank">arXiv:2509.04013v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04013v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) effectiveness is usually evaluated by means of
benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in
their original wording, thus in a fixed, standardized format. However,
real-world applications involve linguistic variability, requiring models to
maintain their effectiveness across diverse rewordings of the same question or
query. In this study, we systematically assess the robustness of LLMs to
paraphrased benchmark questions and investigat...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at ECAI 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>105. AutoPBO: LLM-powered Optimization for Local Search PBO Solvers</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jinyuan Li, Yi Chu, Yiwen Sun et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04007v1" target="_blank">arXiv:2509.04007v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04007v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their appli...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>106. RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question   Answering with Large Language Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhaoyan Gong, Juan Li, Zhiqiang Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03995v1" target="_blank">arXiv:2509.03995v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03995v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Current temporal knowledge graph question answering (TKGQA) methods primarily
focus on implicit temporal constraints, lacking the capability of handling more
complex temporal queries, and struggle with limited reasoning abilities and
error propagation in decomposition frameworks. We propose RTQA, a novel
framework to address these challenges by enhancing reasoning over TKGs without
requiring training. Following recursive thinking, RTQA recursively decomposes
questions into sub-problems, solves t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>107. NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language   Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chuhan Zhang, Ye Zhang, Bowen Shi et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CR, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03985v1" target="_blank">arXiv:2509.03985v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03985v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of pa...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages, 9 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>108. MultiGen: Child-Friendly Multilingual Speech Generator with LLMs</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiaoxue Gao, Huayun Zhang, Nancy F. Chen</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, eess.SP, eess.AS, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.08715v3" target="_blank">arXiv:2508.08715v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.08715v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Generative speech models have demonstrated significant potential in improving
human-machine interactions, offering valuable real-world applications such as
language learning for children. However, achieving high-quality, child-friendly
speech generation remains challenging, particularly for low-resource languages
across diverse languages and cultural contexts. In this paper, we propose
MultiGen, a multilingual speech generation model with child-friendly
interaction, leveraging LLM architecture f...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 5 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>109. Enhancing Text2Cypher with Schema Filtering</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Makbule Gulcin Ozsoy</span><br>
                    <span class="meta-item">ğŸ“ cs.DB, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.05118v2" target="_blank">arXiv:2505.05118v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.05118v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Knowledge graphs represent complex data using nodes, relationships, and
properties. Cypher, a powerful query language for graph databases, enables
efficient modeling and querying. Recent advancements in large language models
allow translation of natural language questions into Cypher queries -
Text2Cypher. A common approach is incorporating database schema into prompts.
However, complex schemas can introduce noise, increase hallucinations, and
raise computational costs. Schema filtering addresse...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>110. Text2Cypher: Data Pruning using Hard Example Selection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Makbule Gulcin Ozsoy</span><br>
                    <span class="meta-item">ğŸ“ cs.DB, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.05122v2" target="_blank">arXiv:2505.05122v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.05122v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Database query languages such as SQL for relational databases and Cypher for
graph databases have been widely adopted. Recent advancements in large language
models (LLMs) enable natural language interactions with databases through
models like Text2SQL and Text2Cypher. Fine-tuning these models typically
requires large, diverse datasets containing non-trivial examples. However, as
dataset size increases, the cost of fine-tuning also rises. This makes smaller,
high-quality datasets essential for re...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>111. Transition Models: Rethinking the Generative Learning Objective</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zidong Wang, Yiyuan Zhang, Xiaoyu Yue et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04394v1" target="_blank">arXiv:2509.04394v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04394v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A fundamental dilemma in generative modeling persists: iterative diffusion
models achieve outstanding fidelity, but at a significant computational cost,
while efficient few-step alternatives are constrained by a hard quality
ceiling. This conflict between generation steps and output quality arises from
restrictive training objectives that focus exclusively on either infinitesimal
dynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by
introducing an exact, continuous-time ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The code is released at https://github.com/WZDTHU/TiM</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>112. Imputation-free Learning of Tabular Data with Missing Values using   Incremental Feature Partitions in Transformer</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Manar D. Samad, Kazi Fuad B. Akhter, Shourav B. Rabbani et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.14610v4" target="_blank">arXiv:2504.14610v4</a> | 
                    <a href="http://arxiv.org/pdf/2504.14610v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Tabular data sets with varying missing values are prepared for machine
learning using an arbitrary imputation strategy. Synthetic values generated by
imputation models often raise concerns about data quality and the reliability
of data-driven outcomes. To address these concerns, this article proposes an
imputation-free incremental attention learning (IFIAL) method for tabular data.
A pair of attention masks is derived and retrofitted to a transformer to
directly streamline tabular data without i...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>113. Rethinking the long-range dependency in Mamba/SSM and transformer models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Cong Ma, Kayvan Najarian</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04226v1" target="_blank">arXiv:2509.04226v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04226v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Long-range dependency is one of the most desired properties of recent
sequence models such as state-space models (particularly Mamba) and transformer
models. New model architectures are being actively developed and benchmarked
for prediction tasks requiring long-range dependency. However, the capability
of modeling long-range dependencies of these models has not been investigated
from a theoretical perspective, which hinders a systematic improvement on this
aspect. In this work, we mathematicall...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>114. DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ruohong Yang, Peng Hu, Yunfan Li et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04193v1" target="_blank">arXiv:2509.04193v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04193v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of
the same category across diverse domains without relying on annotations.
Existing UCIR methods, which align cross-domain features for the entire image,
often struggle with the domain gap, as the object features critical for
retrieval are frequently entangled with domain-specific styles. To address this
challenge, we propose DUDE, a novel UCIR method building upon feature
disentanglement. In brief, DUDE leverages a text-t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>115. Plugging Attention into Power Grids: Towards Transparent Forecasting</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Eloi Campagne, Itai Zehavi, Yvenn Amara-Ouali et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.03690v2" target="_blank">arXiv:2507.03690v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.03690v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reliable prediction of electricity demand plays a key role in safeguarding
grid stability and guiding generation decisions, a need that grows with the
decentralization and complexity of modern systems. While classical approaches
such as Generalized Additive Models (GAMs) remain widely used, they often fail
to capture the spatial dependencies inherent in energy networks. Graph Neural
Networks (GNNs) offer a principled framework to incorporate this structure by
directly leveraging graph topologies...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 16 pages, ECML PKDD 2025 Workshop paper</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>116. UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hang Ni, Weijia Zhang, Hao Liu</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.01426v2" target="_blank">arXiv:2508.01426v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.01426v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in deep learning have led to the development of
Foundation Models (FMs) for weather forecasting, yet their ability to predict
extreme weather events remains limited. Existing approaches either focus on
general weather conditions or specialize in specific-type extremes, neglecting
the real-world atmospheric patterns of diversified extreme events. In this
work, we identify two key characteristics of extreme events: (1) the spectral
disparity against normal weather regimes, and ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 35 pages, 80 figures, submitted to ACM KDD 2026 conference</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>117. Zero-shot Generalization in Inventory Management: Train, then Estimate   and Decide</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tarkan TemizÃ¶z, Christina Imdahl, Remco Dijkman et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.00515v2" target="_blank">arXiv:2411.00515v2</a> | 
                    <a href="http://arxiv.org/pdf/2411.00515v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Deploying deep reinforcement learning (DRL) in real-world inventory
management presents challenges, including dynamic environments and uncertain
problem parameters, e.g. demand and lead time distributions. These challenges
highlight a research gap, suggesting a need for a unifying framework to model
and solve sequential decision-making under parameter uncertainty. We address
this by exploring an underexplored area of DRL for inventory management:
training generally capable agents (GCAs) under ze...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>118. Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA   Flow Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hongyin Zhang, Shiyuan Zhang, Junxi Jin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04063v1" target="_blank">arXiv:2509.04063v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04063v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Vision-Language-Action (VLA) models based on flow matching have shown
excellent performance in general-purpose robotic manipulation tasks. However,
the action accuracy of these models on complex downstream tasks is
unsatisfactory. One important reason is that these models rely solely on the
post-training paradigm of imitation learning, which makes it difficult to have
a deeper understanding of the distribution properties of data quality, which is
exactly what Reinforcement Learning (RL) excels a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>119. MARS: Unleashing the Power of Variance Reduction for Training Large   Models</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Huizhuo Yuan, Yifeng Liu, Shuang Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ math.OC, stat.ML, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.10438v4" target="_blank">arXiv:2411.10438v4</a> | 
                    <a href="http://arxiv.org/pdf/2411.10438v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Training deep neural networks--and more recently, large models demands
efficient and scalable optimizers. Adaptive gradient algorithms like Adam,
AdamW, and their variants have been central to this task. Despite the
development of numerous variance reduction algorithms in the past decade aimed
at accelerating stochastic optimization in both convex and nonconvex settings,
variance reduction has not found widespread success in training deep neural
networks or large language models. Consequently, i...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 35 pages, 19 figures, 12 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>120. EvolveSignal: A Large Language Model Powered Coding Agent for   Discovering Traffic Signal Control Algorithms</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Leizhen Wang, Peibo Duan, Hao Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03335v2" target="_blank">arXiv:2509.03335v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03335v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In traffic engineering, the fixed-time traffic signal control remains widely
used for its low cost, stability, and interpretability. However, its design
depends on hand-crafted formulas (e.g., Webster) and manual re-timing by
engineers to adapt to demand changes, which is labor-intensive and often yields
suboptimal results under heterogeneous or congested conditions. This paper
introduces the EvolveSignal, a large language models (LLMs) powered coding
agent to automatically discover new traffic ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>121. RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS   Localization with Sparse Radio Map Estimation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiucheng Wang, Qiming Zhang, Nan Cheng</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.LG, cs.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.01875v2" target="_blank">arXiv:2509.01875v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.01875v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Accurate localization of non-cooperative signal sources in non-line-of-sight
(NLoS) environments remains a critical challenge with a wide range of
applications, including autonomous navigation, industrial automation, and
emergency response. In such settings, traditional positioning techniques
relying on line-of-sight (LoS) or cooperative signaling fail due to severe
multipath propagation and unknown transmit power. This paper proposes a novel
generative inference framework for NLoS localization ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>122. Efficient Odd-One-Out Anomaly Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Silvio Chito, Paolo Rabino, Tatiana Tommasi</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04326v1" target="_blank">arXiv:2509.04326v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04326v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The recently introduced odd-one-out anomaly detection task involves
identifying the odd-looking instances within a multi-object scene. This problem
presents several challenges for modern deep learning models, demanding spatial
reasoning across multiple views and relational reasoning to understand context
and generalize across varying object categories and layouts. We argue that
these challenges must be addressed with efficiency in mind. To this end, we
propose a DINO-based model that reduces the...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at ICIAP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>123. Differential Morphological Profile Neural Networks for Semantic   Segmentation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ David Huangal, J. Alex Hurt</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04268v1" target="_blank">arXiv:2509.04268v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04268v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Semantic segmentation of overhead remote sensing imagery enables applications
in mapping, urban planning, and disaster response. State-of-the-art
segmentation networks are typically developed and tuned on ground-perspective
photographs and do not directly address remote sensing challenges such as
extreme scale variation, foreground-background imbalance, and large image
sizes. We explore the incorporation of the differential morphological profile
(DMP), a multi-scale shape extraction method based...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 14 pages, 7 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>124. Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network   Weight Space Diffusion</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dongliang Cao, Guoxing Sun, Marc Habermann et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.GR, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04145v1" target="_blank">arXiv:2509.04145v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04145v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge fr...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>125. Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A   Comprehensive Review of Methods, Datasets, and Future Directions</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ruonan Lin, Tao Tang, Yongtai Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.07611v2" target="_blank">arXiv:2505.07611v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.07611v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Traffic accident prediction and detection are critical for enhancing road
safety, and vision-based traffic accident anticipation (Vision-TAA) has emerged
as a promising approach in the era of deep learning. This paper reviews 147
recent studies, focusing on the application of supervised, unsupervised, and
hybrid deep learning models for accident prediction, alongside the use of
real-world and synthetic datasets. Current methodologies are categorized into
four key approaches: image and video feat...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>126. SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy   Representation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Han Huang, Han Sun, Ningzhong Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03999v1" target="_blank">arXiv:2509.03999v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03999v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Driven by autonomous driving&#x27;s demands for precise 3D perception, 3D semantic
occupancy prediction has become a pivotal research topic. Unlike
bird&#x27;s-eye-view (BEV) methods, which restrict scene representation to a 2D
plane, occupancy prediction leverages a complete 3D voxel grid to model spatial
structures in all dimensions, thereby capturing semantic variations along the
vertical axis. However, most existing approaches overlook height-axis
information when processing voxel features. And conven...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 14 pages, accepted by PRCV2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>127. Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated   Piano Hand Motion Synthesis</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zihao Liu, Mingwen Ou, Zunnan Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.CV, eess.AS</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.09885v2" target="_blank">arXiv:2504.09885v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.09885v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Automating the synthesis of coordinated bimanual piano performances poses
significant challenges, particularly in capturing the intricate choreography
between the hands while preserving their distinct kinematic signatures. In this
paper, we propose a dual-stream neural framework designed to generate
synchronized hand gestures for piano playing from audio input, addressing the
critical challenge of modeling both hand independence and coordination. Our
framework introduces two key innovations: (i)...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages, 7 figures, Accepted to ACMMM 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>128. DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool   Interleaved Vision-Language Model</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qian Chen, Xianyin Zhang, Lifan Guo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.13238v2" target="_blank">arXiv:2508.13238v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.13238v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advances in large vision-language models (LVLMs) have enabled a new
paradigm of end-to-end document image parsing, excelling in Optical Character
Recognition (OCR) tasks such as text, table, and formula recognition. However,
generative LVLMs, similarly to large language models (LLMs), are prone to
hallucinations--generating words that do not exist in input images.
Furthermore, LVLMs are designed for general purposes and tend to be less
effective on OCR tasks compared to expert models that...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>129. Multimodal Feature Fusion Network with Text Difference Enhancement for   Remote Sensing Change Detection</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yijun Zhou, Yikui Zhai, Zilu Ying et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03961v1" target="_blank">arXiv:2509.03961v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03961v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Although deep learning has advanced remote sensing change detection (RSCD),
most methods rely solely on image modality, limiting feature representation,
change pattern modeling, and generalization especially under illumination and
noise disturbances. To address this, we propose MMChange, a multimodal RSCD
method that combines image and text modalities to enhance accuracy and
robustness. An Image Feature Refinement (IFR) module is introduced to highlight
key regions and suppress environmental noi...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>130. Is an Ultra Large Natural Image-Based Foundation Model Superior to a   Retina-Specific Model for Detecting Ocular and Systemic Diseases?</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.IV, cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.06289v2" target="_blank">arXiv:2502.06289v2</a> | 
                    <a href="http://arxiv.org/pdf/2502.06289v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The advent of foundation models (FMs) is transforming medical domain. In
ophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4
million natural images and 1.6 million retinal images, has demonstrated high
adaptability across clinical applications. Conversely, DINOv2, a
general-purpose vision FM pre-trained on 142 million natural images, has shown
promise in non-medical domains. However, its applicability to clinical tasks
remains underexplored. To address this, we conducte...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by Ophthalmology Science and is currently in press</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>131. EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming   in Debt Recovery</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yunbo Long, Yuhan Liu, Liming Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.21080v4" target="_blank">arXiv:2503.21080v4</a> | 
                    <a href="http://arxiv.org/pdf/2503.21080v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language model-based chatbots have enhanced engagement in financial
negotiations, but their overreliance on passive empathy introduces critical
risks in credit collection. While empathy-driven approaches preserve client
satisfaction in benign cases, they fail catastrophically against dishonest
debtors--individuals who exploit conciliatory tactics to manipulate terms or
evade repayment. Blindly prioritizing &quot;customer experience&quot; in such scenarios
leads to creditor vulnerabilities: revenue l...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>132. Explicit Learning and the LLM in Machine Translation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Malik Marmonier, Rachel Bawden, BenoÃ®t Sagot</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.09454v4" target="_blank">arXiv:2503.09454v4</a> | 
                    <a href="http://arxiv.org/pdf/2503.09454v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This study explores an LLM&#x27;s ability to learn new languages using
explanations found in a grammar book, a process we term &quot;explicit learning.&quot; To
rigorously assess this ability, we design controlled translation experiments
between English and constructed languages generated, through specific
cryptographic means, from Latin or French. Contrary to previous studies, our
results demonstrate that LLMs do possess a measurable capacity for explicit
learning. This ability, however, diminishes as the com...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>133. Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuqi Tang, Kehua Feng, Yunfeng Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.00454v2" target="_blank">arXiv:2508.00454v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.00454v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
&quot;LLM-as-a-judge&quot; paradigm, where an LLM is prompted to serve as an evaluator to
assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages, 2 pages, under review</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>134. MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for   Speech Emotion Recognition in Naturalistic Conditions</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Georgios Chatzichristodoulou, Despoina Kosmopoulou, Antonios Kritikos et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.09556v2" target="_blank">arXiv:2506.09556v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.09556v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">SER is a challenging task due to the subjective nature of human emotions and
their uneven representation under naturalistic conditions. We propose MEDUSA, a
multimodal framework with a four-stage training pipeline, which effectively
handles class imbalance and emotion ambiguity. The first two stages train an
ensemble of classifiers that utilize DeepSER, a novel extension of a deep
cross-modal transformer fusion mechanism from pretrained self-supervised
acoustic and linguistic representations. Ma...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Interspeech 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>135. LibriQuote: A Speech Dataset of Fictional Character Utterances for   Expressive Zero-Shot Speech Synthesis</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Gaspard Michel, Elena V. Epure, Christophe Cerisara</span><br>
                    <span class="meta-item">ğŸ“ eess.AS, cs.CL, cs.SD</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04072v1" target="_blank">arXiv:2509.04072v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04072v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Text-to-speech (TTS) systems have recently achieved more expressive and
natural speech synthesis by scaling to large speech datasets. However, the
proportion of expressive speech in such large-scale corpora is often unclear.
Besides, existing expressive speech corpora are typically smaller in scale and
primarily used for benchmarking TTS systems. In this paper, we introduce the
LibriQuote dataset, an English corpus derived from read audiobooks, designed
for both fine-tuning and benchmarking expr...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>136. Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to   Enhance LLM Safety Guardrail to Potential Attacks</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sheng Liu, Qiang Sheng, Danding Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.20038v3" target="_blank">arXiv:2508.20038v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.20038v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite advances in improving large language model (LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs&#x27; inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this chal...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025 findings</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>137. Mitigating Bias in Text Classification via Prompt-Based Text   Transformation</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Charmaine Barker, Dimitar Kazakov</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2305.06166v3" target="_blank">arXiv:2305.06166v3</a> | 
                    <a href="http://arxiv.org/pdf/2305.06166v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The presence of specific linguistic signals particular to a certain sub-group
can become highly salient to language models during training. In automated
decision-making settings, this may lead to biased outcomes when models rely on
cues that correlate with protected characteristics. We investigate whether
prompting ChatGPT to rewrite text using simplification, neutralisation,
localisation, and formalisation can reduce demographic signals while preserving
meaning. Experimental results show a stat...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: This version corrects an error in the model specification</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>138. FutureGen: A RAG-based Approach to Generate the Future Work of   Scientific Article</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ibrahim Al Azher, Miftahul Jannat Mokarrama, Zhishuai Guo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.16561v3" target="_blank">arXiv:2503.16561v3</a> | 
                    <a href="http://arxiv.org/pdf/2503.16561v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The Future Work section of a scientific article outlines potential research
directions by identifying gaps and limitations of a current study. This section
serves as a valuable resource for early-career researchers seeking unexplored
areas and experienced researchers looking for new projects or collaborations.
In this study, we generate future work suggestions from a scientific article.
To enrich the generation process with broader insights and reduce the chance of
missing important research dir...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages, 6 figures, Accepted for publication at the Workshop on AI
  Principles in Science Communication (Ai4SC&#x27;25), held in conjunction with the
  IEEE eScience Conference 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>139. Short-video Propagation Influence Rating: A New Real-world Dataset and A   New Large Graph Model</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dizhan Xue, Shengsheng Qian, Chuanrui Hu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.CL, cs.LG, cs.MM, cs.SI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.23746v2" target="_blank">arXiv:2503.23746v2</a> | 
                    <a href="http://arxiv.org/pdf/2503.23746v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Short-video platforms have gained immense popularity, captivating the
interest of millions, if not billions, of users globally. Recently, researchers
have highlighted the significance of analyzing the propagation of short-videos,
which typically involves discovering commercial values, public opinions, user
behaviors, etc. This paper proposes a new Short-video Propagation Influence
Rating (SPIR) task and aims to promote SPIR from both the dataset and method
perspectives. First, we propose a new C...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>140. Explaining Length Bias in LLM-Based Preference Evaluations</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhengyu Hu, Linxin Song, Jieyu Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2407.01085v5" target="_blank">arXiv:2407.01085v5</a> | 
                    <a href="http://arxiv.org/pdf/2407.01085v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The use of large language models (LLMs) as judges, particularly in preference
comparisons, has become widespread, but this reveals a notable bias towards
longer responses, undermining the reliability of such evaluations. To better
understand such bias, we propose to decompose the preference evaluation metric,
specifically the win rate, into two key components: desirability and
information mass, where the former is length-independent and related to
trustworthiness such as correctness, toxicity, a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>141. Science Across Languages: Assessing LLM Multilingual Translation of   Scientific Papers</h3>
                <div class="priority-badge priority-high" style="display: inline-block; margin: 0.5rem 0;">
                    High Relevance (Score: 3.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hannah Calzi Kleidermacher, James Zou</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.17882v2" target="_blank">arXiv:2502.17882v2</a> | 
                    <a href="http://arxiv.org/pdf/2502.17882v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Scientific research is inherently global. However, the vast majority of
academic journals are published exclusively in English, creating barriers for
non-native-English-speaking researchers. In this study, we leverage large
language models (LLMs) to translate published scientific articles while
preserving their native JATS XML formatting, thereby developing a practical,
automated approach for implementation by academic journals. Using our approach,
we translate articles across multiple scientifi...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>142. SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic   Avatars</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Atikkhan Faridkhan Nilgar, Kristof Van Laerhoven, Ayub Kinoti</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04356v1" target="_blank">arXiv:2509.04356v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04356v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present SRWToolkit, an open-source Wizard of Oz toolkit designed to
facilitate the rapid prototyping of social robotic avatars powered by local
large language models (LLMs). Our web-based toolkit enables multimodal
interaction through text input, button-activated speech, and wake-word command.
The toolkit offers real-time configuration of avatar appearance, behavior,
language, and voice via an intuitive control panel. In contrast to prior works
that rely on cloud-based LLM services, SRWToolki...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>143. MuMTAffect: A Multimodal Multitask Affective Framework for Personality   and Emotion Recognition from Physiological Signals</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Meisam Jamshidi Seikavandi, Fabricio Batista Narcizo, Ted Vucurevich et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04254v1" target="_blank">arXiv:2509.04254v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04254v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present MuMTAffect, a novel Multimodal Multitask Affective Embedding
Network designed for joint emotion classification and personality prediction
(re-identification) from short physiological signal segments. MuMTAffect
integrates multiple physiological modalities pupil dilation, eye gaze, facial
action units, and galvanic skin response using dedicated, transformer-based
encoders for each modality and a fusion transformer to model cross-modal
interactions. Inspired by the Theory of Constructed...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>144. POET: Supporting Prompting Creativity and Personalization with Automated   Expansion of Text-to-Image Generation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Evans Xu Han, Alice Qian Zhang, Haiyi Zhu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.13392v2" target="_blank">arXiv:2504.13392v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.13392v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">State-of-the-art visual generative AI tools hold immense potential to assist
users in the early ideation stages of creative tasks -- offering the ability to
generate (rather than search for) novel and unprecedented (instead of existing)
images of considerable quality that also adhere to boundless combinations of
user specifications. However, many large-scale text-to-image systems are
designed for broad applicability, yielding conventional output that may limit
creative exploration. They also emp...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>145. OneSearch: A Preliminary Exploration of the Unified End-to-End   Generative Framework for E-commerce Search</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 3.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ben Chen, Xian Guo, Siyuan Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03236v2" target="_blank">arXiv:2509.03236v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03236v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Traditional e-commerce search systems employ multi-stage cascading
architectures (MCA) that progressively filter items through recall,
pre-ranking, and ranking stages. While effective at balancing computational
efficiency with business conversion, these systems suffer from fragmented
computation and optimization objective collisions across stages, which
ultimately limit their performance ceiling. To address these, we propose
\textbf{OneSearch}, the first industrial-deployed end-to-end generative...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>146. Demographic-aware fine-grained classification of pediatric wrist   fractures</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.12964v5" target="_blank">arXiv:2507.12964v5</a> | 
                    <a href="http://arxiv.org/pdf/2507.12964v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Wrist pathologies are frequently observed, particularly among children who
constitute the majority of fracture cases. Computer vision presents a promising
avenue, contingent upon the availability of extensive datasets, a notable
challenge in medical imaging. Therefore, reliance solely on one modality, such
as images, proves inadequate, especially in an era of diverse and plentiful
data types. This study addresses the problem using a multifaceted approach:
framing it as a fine-grained recognition...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>147. SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jimin Xu, Bosheng Qin, Tao Jin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04379v1" target="_blank">arXiv:2509.04379v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04379v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in neural representations, such as Neural Radiance Fields
and 3D Gaussian Splatting, have increased interest in applying style transfer
to 3D scenes. While existing methods can transfer style patterns onto
3D-consistent neural representations, they struggle to effectively extract and
transfer high-level style semantics from the reference style image.
Additionally, the stylized results often lack structural clarity and
separation, making it difficult to distinguish between dif...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>148. Pilot Study on Generative AI and Critical Thinking in Higher Education   Classrooms</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ W. F. Lamberti, S. R. Lawrence, D. White et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.AP, cs.HC, cs.AI, cs.CY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.00167v2" target="_blank">arXiv:2509.00167v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.00167v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Generative AI (GAI) tools have seen rapid adoption in educational settings,
yet their role in fostering critical thinking remains underexplored. While
previous studies have examined GAI as a tutor for specific lessons or as a tool
for completing assignments, few have addressed how students critically evaluate
the accuracy and appropriateness of GAI-generated responses. This pilot study
investigates students&#x27; ability to apply structured critical thinking when
assessing Generative AI outputs in in...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>149. Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery   Systems with Data-Driven Formal Verification</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Rudi Coppola, Hovsep Touloujian, Pierfrancesco Ombrini et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.AI, cs.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04288v1" target="_blank">arXiv:2509.04288v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04288v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of
modern technology. In the last decades, the production and design of such
batteries and their adjacent embedded charging and safety protocols, denoted by
Battery Management Systems (BMS), has taken central stage. A fundamental
challenge to be addressed is the trade-off between the speed of charging and
the ageing behavior, resulting in the loss of capacity in the battery cell. We
rely on a high-fidelity physics-based battery...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>150. Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE   Solvers</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hang Zhou, Yuezhou Ma, Haixu Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.NA, math.NA, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2405.17527v5" target="_blank">arXiv:2405.17527v5</a> | 
                    <a href="http://arxiv.org/pdf/2405.17527v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Deep models have recently emerged as promising tools to solve partial
differential equations (PDEs), known as neural PDE solvers. While neural
solvers trained from either simulation data or physics-informed loss can solve
PDEs reasonably well, they are mainly restricted to a few instances of PDEs,
e.g. a certain equation with a limited set of coefficients. This limits their
generalization to diverse PDEs, preventing them from being practical surrogate
models of numerical solvers. In this paper, ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>151. An Empirical Study of Vulnerabilities in Python Packages and Their   Detection</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Haowei Quan, Junjie Wang, Xinzhe Li et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SE, cs.AI, cs.CR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04260v1" target="_blank">arXiv:2509.04260v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04260v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effective...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>152. A Survey of Graph Retrieval-Augmented Generation for Customized Large   Language Models</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qinggang Zhang, Shengyuan Chen, Yuanchen Bei et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.IR, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2501.13958v2" target="_blank">arXiv:2501.13958v2</a> | 
                    <a href="http://arxiv.org/pdf/2501.13958v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-Augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>153. How many patients could we save with LLM priors?</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shota Arai, David Selby, Andrew Vargo et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.AP, cs.ET, stat.ME, cs.IR, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04250v1" target="_blank">arXiv:2509.04250v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04250v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Imagine a world where clinical trials need far fewer patients to achieve the
same statistical power, thanks to the knowledge encoded in large language
models (LLMs). We present a novel framework for hierarchical Bayesian modeling
of adverse events in multi-center clinical trials, leveraging LLM-informed
prior distributions. Unlike data augmentation approaches that generate
synthetic data points, our methodology directly obtains parametric priors from
the model. Our approach systematically elicit...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 4 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>154. FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via   Flow Variational Inference</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qian Feng, Jianxiang Feng, Zhaopeng Chen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2407.15161v4" target="_blank">arXiv:2407.15161v4</a> | 
                    <a href="http://arxiv.org/pdf/2407.15161v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Synthesizing diverse, uncertainty-aware grasps for multi-fingered hands from
partial observations remains a critical challenge in robot learning. Prior
generative methods struggle to model the intricate grasp distribution of
dexterous hands and often fail to reason about shape uncertainty inherent in
partial point clouds, leading to unreliable or overly conservative grasps. We
propose FFHFlow, a flow-based variational framework that generates diverse,
robust multi-finger grasps while explicitly ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: First two authors contributed equally, whose ordering decided via
  coin-tossing. Accepted for CoRL 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>155. Kolb-Based Experiential Learning for Generalist Agents with Human-Level   Kaggle Data Science Performance</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Antoine Grosnit, Alexandre Maraval, Refinath S N et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.03562v2" target="_blank">arXiv:2411.03562v2</a> | 
                    <a href="http://arxiv.org/pdf/2411.03562v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Human expertise emerges through iterative cycles of interaction, reflection,
and internal model updating, which are central to cognitive theories such as
Kolb&#x27;s experiential learning and Vygotsky&#x27;s zone of proximal development. In
contrast, current AI systems, particularly LLM agents, rely on static
pre-training or rigid workflows, lacking mechanisms for continual adaptation.
Recent studies identified early cognitive traits in LLM agents (reflection,
revision, and self-correction) suggesting fou...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>156. StreetViewAI: Making Street View Accessible Using Context-Aware   Multimodal AI</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jon E. Froehlich, Alexander Fiannaca, Nimer Jaber et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, H.5; I.2, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.08524v3" target="_blank">arXiv:2508.08524v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.08524v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Interactive streetscape mapping tools such as Google Street View (GSV) and
Meta Mapillary enable users to virtually navigate and experience real-world
environments via immersive 360{\deg} imagery but remain fundamentally
inaccessible to blind users. We introduce StreetViewAI, the first-ever
accessible street view tool, which combines context-aware, multimodal AI,
accessible navigation controls, and conversational speech. With StreetViewAI,
blind users can virtually examine destinations, engage i...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to UIST&#x27;25 v2. Fixed a missing word in the PDF v3. Fixed a
  typo in an author&#x27;s name</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>157. LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text   Pairing</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Federico Girella, Davide Talon, Ziyue Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.22627v2" target="_blank">arXiv:2507.22627v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.22627v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Fashion design is a complex creative process that blends visual and textual
expressions. Designers convey ideas through sketches, which define spatial
structure and design elements, and textual descriptions, capturing material,
texture, and stylistic details. In this paper, we present LOcalized Text and
Sketch for fashion image generation (LOTS), an approach for compositional
sketch-text based generation of complete fashion outlooks. LOTS leverages a
global description with paired localized sket...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at ICCV25 (Oral). Project page:
  https://intelligolabs.github.io/lots/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>158. Attention as an Adaptive Filter</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Peter Racioppo</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04154v1" target="_blank">arXiv:2509.04154v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04154v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce Adaptive Filter Attention (AFA), a novel attention mechanism
that incorporates a learnable dynamics model directly into the computation of
attention weights. Rather than comparing queries and keys directly, we model
the input sequence as discrete observations of a linear stochastic differential
equation (SDE). By imposing a linear dynamics model with simultaneously
diagonalizable state matrices and noise covariances, we can make use of a
closed-form solution to the differential Lyap...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>159. Quantifying Calibration Error in Neural Networks Through Evidence-Based   Theory</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos et al.</span><br>
                    <span class="meta-item">ğŸ“ math.LO, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.00265v3" target="_blank">arXiv:2411.00265v3</a> | 
                    <a href="http://arxiv.org/pdf/2411.00265v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Trustworthiness in neural networks is crucial for their deployment in
critical applications, where reliability, confidence, and uncertainty play
pivotal roles in decision-making. Traditional performance metrics such as
accuracy and precision fail to capture these aspects, particularly in cases
where models exhibit overconfidence. To address these limitations, this paper
introduces a novel framework for quantifying the trustworthiness of neural
networks by incorporating subjective logic into the ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: This is the preprint of the paper accepted to Fusion 2025 (28th
  International Conference on Information Fusion, Rio de Janeiro, Brazil, July
  7-10, 2025). The published version is available at
  https://doi.org/10.23919/FUSION65864.2025.11124121</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>160. Hybrid Reinforcement Learning and Search for Flight Trajectory Planning</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Alberto Luise, Michele Lombardi, Florent Teichteil Koenigsbuch</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04100v1" target="_blank">arXiv:2509.04100v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04100v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The appro...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>161. PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal   Documents</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junjie Wang, Yuxiang Zhang, Minghao Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.MM, cs.CL, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2406.13923v2" target="_blank">arXiv:2406.13923v2</a> | 
                    <a href="http://arxiv.org/pdf/2406.13923v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in large multimodal models (LMMs) have leveraged
extensive multimodal datasets to enhance capabilities in complex
knowledge-driven tasks. However, persistent challenges in perceptual and
reasoning errors limit their efficacy, particularly in interpreting intricate
visual data and deducing multimodal relationships. To address these issues, we
introduce PIN (Paired and INterleaved multimodal documents), a novel data
format designed to foster a deeper integration of visual and t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Technical report v1.0</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>162. Conditional Video Generation for High-Efficiency Video Compression</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Fangqiu Yi, Jingyu Xu, Jiawei Shao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.15269v2" target="_blank">arXiv:2507.15269v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.15269v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Perceptual studies demonstrate that conditional diffusion models excel at
reconstructing video content aligned with human visual perception. Building on
this insight, we propose a video compression framework that leverages
conditional diffusion models for perceptually optimized reconstruction.
Specifically, we reframe video compression as a conditional generation task,
where a generative model synthesizes video from sparse, yet informative
signals. Our approach introduces three key modules: (1) ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Critical methodology flaws invalidate key results</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>163. Unveiling the Role of Data Uncertainty in Tabular Deep Learning</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Nikolay Kartashev, Ivan Rubachev, Artem Babenko</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04430v1" target="_blank">arXiv:2509.04430v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04430v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advancements in tabular deep learning have demonstrated exceptional
practical performance, yet the field often lacks a clear understanding of why
these techniques actually succeed. To address this gap, our paper highlights
the importance of the concept of data uncertainty for explaining the
effectiveness of the recent tabular DL methods. In particular, we reveal that
the success of many beneficial design choices in tabular DL, such as numerical
feature embeddings, retrieval-augmented mode...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>164. Rethinking Layer-wise Gaussian Noise Injection: Bridging Implicit   Objectives and Privacy Budget Allocation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qifeng Tan, Shusen Yang, Xuebin Ren et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04232v1" target="_blank">arXiv:2509.04232v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04232v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Layer-wise Gaussian mechanisms (LGM) enhance flexibility in differentially
private deep learning by injecting noise into partitioned gradient vectors.
However, existing methods often rely on heuristic noise allocation strategies,
lacking a rigorous understanding of their theoretical grounding in connecting
noise allocation to formal privacy-utility tradeoffs. In this paper, we present
a unified analytical framework that systematically connects layer-wise noise
injection strategies with their imp...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>165. Set Block Decoding is a Language Model Inference Accelerator</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Itai Gat, Heli Ben-Hamu, Marton Havasi et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04185v1" target="_blank">arXiv:2509.04185v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04185v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Autoregressive next token prediction language models offer powerful
capabilities but face significant challenges in practical deployment due to the
high computational and memory costs of inference, particularly during the
decoding stage. We introduce Set Block Decoding (SBD), a simple and flexible
paradigm that accelerates generation by integrating standard next token
prediction (NTP) and masked token prediction (MATP) within a single
architecture. SBD allows the model to sample multiple, not ne...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>166. Comment on &quot;A Note on Over-Smoothing for Graph Neural Networks&quot;</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Razi Hasson, Reuven Guetta</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04178v1" target="_blank">arXiv:2509.04178v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04178v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We comment on Cai and Wang (2020, arXiv:2006.13318), who analyze
over-smoothing in GNNs via Dirichlet energy. We show that under mild spectral
conditions (including with Leaky-ReLU), the Dirichlet energy of node embeddings
decreases exponentially with depth; we further extend the result to spectral
polynomial filters and provide a short proof for the Leaky-ReLU case.
Experiments on edge deletion and weight amplification illustrate when Dirichlet
energy increases, hinting at practical ways to rel...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Comment on arXiv:2006.13318 (Cai &amp; Wang, 2020). Revisits their
  Dirichlet-energy analysis of over-smoothing and extends it to Leaky-ReLU and
  spectral polynomial filters; includes Proposition 7.1 and a new proof of
  Lemma 3.3 for Leaky-ReLU. 7 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>167. Probabilistic QoS Metric Forecasting in Delay-Tolerant Networks Using   Conditional Diffusion Models on Latent Dynamics</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jianhua Liu, Zheng Liu, Yu Xiang et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.08821v2" target="_blank">arXiv:2504.08821v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.08821v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Active QoS metric prediction, commonly employed in the maintenance and
operation of DTN, could enhance network performance regarding latency,
throughput, energy consumption, and dependability. Naturally formulated as a
multivariate time series forecasting problem, it attracts substantial research
efforts. Traditional mean regression methods for time series forecasting cannot
capture the data complexity adequately, resulting in deteriorated performance
in operational tasks in DTNs such as routing...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>168. One Flight Over the Gap: A Survey from Perspective to Panoramic Vision</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xin Lin, Xian Ge, Dizhe Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04444v1" target="_blank">arXiv:2509.04444v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04444v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct doma...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>169. Durian: Dual Reference-guided Portrait Animation with Attribute Transfer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hyunsoo Cha, Byungjun Kim, Hanbyul Joo</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04434v1" target="_blank">arXiv:2509.04434v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04434v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project Page: https://hyunsoocha.github.io/durian</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>170. Few-step Flow for 3D Generation via Marginal-Data Transport Distillation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zanwei Zhou, Taoran Yi, Jiemin Fang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04406v1" target="_blank">arXiv:2509.04406v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04406v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Margin...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project page: https://github.com/Zanue/MDT-dist</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>171. Completing Spatial Transcriptomics Data for Gene Expression Prediction   Benchmarking</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Daniela Ruiz, Paula CÃ¡rdenas, Leonardo Manrique et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.02980v2" target="_blank">arXiv:2505.02980v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.02980v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Spatial Transcriptomics is a groundbreaking technology that integrates
histology images with spatially resolved gene expression profiles. Among the
various Spatial Transcriptomics techniques available, Visium has emerged as the
most widely adopted. However, its accessibility is limited by high costs, the
need for specialized expertise, and slow clinical integration. Additionally,
gene capture inefficiencies lead to significant dropout, corrupting acquired
data. To address these challenges, the d...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: arXiv admin note: substantial text overlap with arXiv:2407.13027</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>172. Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from   Vector Drawings</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Feiwei Qin, Shichao Lu, Junhao Hou et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.18733v3" target="_blank">arXiv:2508.18733v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.18733v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Computer-Aided Design (CAD) generative modeling is driving significant
innovations across industrial applications. Recent works have shown remarkable
progress in creating solid models from various inputs such as point clouds,
meshes, and text descriptions. However, these methods fundamentally diverge
from traditional industrial workflows that begin with 2D engineering drawings.
The automatic generation of parametric CAD models from these 2D vector drawings
remains underexplored despite being a c...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to ACM MM 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>173. DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mustafa Sakhai, Kaung Sithu, Min Khant Soe Oke et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04117v1" target="_blank">arXiv:2509.04117v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04117v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Event cameras like Dynamic Vision Sensors (DVS) report micro-timed brightness
changes instead of full frames, offering low latency, high dynamic range, and
motion robustness. DVS-PedX (Dynamic Vision Sensor Pedestrian eXploration) is a
neuromorphic dataset designed for pedestrian detection and crossing-intention
analysis in normal and adverse weather conditions across two complementary
sources: (1) synthetic event streams generated in the CARLA simulator for
controlled &quot;approach-cross&quot; scenes un...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages, 8 figures, 3 tables; dataset descriptor paper introducing
  DVS-PedX (synthetic-and-real event-based pedestrian dataset with baselines)
  External URL: https://doi.org/10.5281/zenodo.17030898</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>174. MUNBa: Machine Unlearning via Nash Bargaining</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jing Wu, Mehrtash Harandi</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.15537v4" target="_blank">arXiv:2411.15537v4</a> | 
                    <a href="http://arxiv.org/pdf/2411.15537v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Machine Unlearning (MU) aims to selectively erase harmful behaviors from
models while retaining the overall utility of the model. As a multi-task
learning problem, MU involves balancing objectives related to forgetting
specific concepts/data and preserving general performance. A naive integration
of these forgetting and preserving objectives can lead to gradient conflicts
and dominance, impeding MU algorithms from reaching optimal solutions. To
address the gradient conflict and dominance issue, ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>175. Accurate and lightweight dehazing via multi-receptive-field non-local   network and novel contrastive regularization</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zewei He, Zixuan Chen, Jinlei Li et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2309.16494v3" target="_blank">arXiv:2309.16494v3</a> | 
                    <a href="http://arxiv.org/pdf/2309.16494v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recently, deep learning-based methods have dominated image dehazing domain. A
multi-receptive-field non-local network (MRFNLN) consisting of the multi-stream
feature attention block (MSFAB) and the cross non-local block (CNLB) is
presented in this paper to further enhance the performance. We start with
extracting richer features for dehazing. Specifically, a multi-stream feature
extraction (MSFE) sub-block, which contains three parallel convolutions with
different receptive fields (i.e., $1\time...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: submitted to the IEEE Journal for possible publication</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>176. SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junyu Yan, Feng Chen, Yuyang Xue et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.18826v2" target="_blank">arXiv:2508.18826v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.18826v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent studies have shown that Machine Learning (ML) models can exhibit bias
in real-world scenarios, posing significant challenges in ethically sensitive
domains such as healthcare. Such bias can negatively affect model fairness,
model generalization abilities and further risks amplifying social
discrimination. There is a need to remove biases from trained models. Existing
debiasing approaches often necessitate access to original training data and
need extensive model retraining; they also typi...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2025:015</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>177. BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ahmed Emam, Mohamed Elbassiouny, Julius Miller et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.19762v3" target="_blank">arXiv:2508.19762v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.19762v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
anthropogenic and environmental stressors. Scalable, automated monitoring in
agricultural environments remains an open challenge due to the difficulty of
detecting small, fast-moving, and often camouflaged insects. To address this,
we present BuzzSet v1.0, a large-scale dataset of high-resolution pollinator
images collected under real field c...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>178. Integrating Intermediate Layer Optimization and Projected Gradient   Descent for Solving Inverse Problems with Diffusion Models</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yang Zheng, Wen Li, Zhaoqiang Liu</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.20789v3" target="_blank">arXiv:2505.20789v3</a> | 
                    <a href="http://arxiv.org/pdf/2505.20789v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Inverse problems (IPs) involve reconstructing signals from noisy
observations. Recently, diffusion models (DMs) have emerged as a powerful
framework for solving IPs, achieving remarkable reconstruction performance.
However, existing DM-based methods frequently encounter issues such as heavy
computational demands and suboptimal convergence. In this work, building upon
the idea of the recent work DMPlug, we propose two novel methods, DMILO and
DMILO-PGD, to address these challenges. Our first meth...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: ICML 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>179. Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical   Definitions</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lan Zhang, Marco Valentino, Andre Freitas</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.FL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.12065v3" target="_blank">arXiv:2502.12065v3</a> | 
                    <a href="http://arxiv.org/pdf/2502.12065v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Thanks to their linguistic capabilities, LLMs offer an opportunity to bridge
the gap between informal mathematics and formal languages through
autoformalization. However, it is still unclear how well LLMs generalize to
sophisticated and naturally occurring mathematical statements. To address this
gap, we investigate the task of autoformalizing real-world mathematical
definitions: a critical component of mathematical discourse. Specifically, we
introduce two novel resources for autoformalization,...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025 Camera-Ready Version</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>180. Towards Stable and Personalised Profiles for Lexical Alignment in Spoken   Human-Agent Dialogue</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Keara Schaaij, Roel Boumans, Tibor Bosse et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04104v1" target="_blank">arXiv:2509.04104v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04104v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Lexical alignment, where speakers start to use similar words across
conversation, is known to contribute to successful communication. However, its
implementation in conversational agents remains underexplored, particularly
considering the recent advancements in large language models (LLMs). As a first
step towards enabling lexical alignment in human-agent dialogue, this study
draws on strategies for personalising conversational agents and investigates
the construction of stable, personalised lex...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for TSD 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>181. Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jianhua Liu, Liwen Cao, Yanru Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.12311v4" target="_blank">arXiv:2504.12311v4</a> | 
                    <a href="http://arxiv.org/pdf/2504.12311v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Prompt tuning has emerged as a lightweight strategy for adapting foundation
models to downstream tasks, particularly for resource-constrained systems. As
pre-trained prompts become valuable assets, combining multiple source prompts
offers a promising approach to enhance generalization for new tasks by
leveraging complementary knowledge. However, naive aggregation often overlooks
different source prompts have different contribution potential to the target
task. To address this, we propose HGPromp...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>182. VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based   Role-Playing Agents</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Weihao Wu, Liang Cao, Xinyu Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI, cs.SD</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03940v1" target="_blank">arXiv:2509.03940v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03940v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent significant advancements in Large Language Models (LLMs) have greatly
propelled the development of Role-Playing Conversational Agents (RPCAs). These
systems aim to create immersive user experiences through consistent persona
adoption. However, current RPCA research faces dual limitations. First,
existing work predominantly focuses on the textual modality, entirely
overlooking critical paralinguistic features including intonation, prosody, and
rhythm in speech, which are essential for conv...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>183. Decoding the Poetic Language of Emotion in Korean Modern Poetry:   Insights from a Human-Labeled Dataset and AI Modeling</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Iro Lim, Haein Ji, Byungjun Kim</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CY, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03932v1" target="_blank">arXiv:2509.03932v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03932v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This study introduces KPoEM (Korean Poetry Emotion Mapping) , a novel dataset
for computational emotion analysis in modern Korean poetry. Despite remarkable
progress in text-based emotion classification using large language models,
poetry-particularly Korean poetry-remains underexplored due to its figurative
language and cultural specificity. We built a multi-label emotion dataset of
7,662 entries, including 7,007 line-level entries from 483 poems and 615
work-level entries, annotated with 44 fi...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 30 pages, 13 tables, 2 figures, Digital Humanities and Social
  Sciences Korea Conference, James Joo-Jin Kim Center for Korean Studies,
  University of Pennsylvania, Philadelphia, USA</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>184. False Sense of Security: Why Probing-based Malicious Input Detection   Fails to Generalize</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Cheng Wang, Zeming Wei, Qin Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03888v1" target="_blank">arXiv:2509.03888v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03888v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large Language Models (LLMs) can comply with harmful instructions, raising
serious safety concerns despite their impressive capabilities. Recent work has
leveraged probing-based approaches to study the separability of malicious and
benign inputs in LLMs&#x27; internal representations, and researchers have proposed
using such probing methods for safety detection. We systematically re-examine
this paradigm. Motivated by poor out-of-distribution performance, we
hypothesize that probes learn superficial ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>185. NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio   Deepfake Detection via Attention Aggregation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Huhong Xian, Rui Liu, Berrak Sisman et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03829v1" target="_blank">arXiv:2509.03829v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03829v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Different from traditional sentence-level audio deepfake detection (ADD),
partial audio deepfake detection (PADD) requires frame-level positioning of the
location of fake speech. While some progress has been made in this area,
leveraging semantic information from audio, especially named entities, remains
an underexplored aspect. To this end, we propose NE-PADD, a novel method for
Partial Audio Deepfake Detection (PADD) that leverages named entity knowledge
through two parallel branches: Speech N...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>186. Align-then-Slide: A complete evaluation framework for Ultra-Long   Document-Level Machine Translation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jiaxin Guo, Daimeng Wei, Yuanchang Luo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03809v1" target="_blank">arXiv:2509.03809v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03809v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large language models (LLMs) have ushered in a new era for document-level
machine translation (\textit{doc}-mt), yet their whole-document outputs
challenge existing evaluation methods that assume sentence-by-sentence
alignment. We introduce \textit{\textbf{Align-then-Slide}}, a complete
evaluation framework for ultra-long doc-mt. In the Align stage, we
automatically infer sentence-level source-target correspondences and rebuild
the target to match the source sentence number, resolving omissions ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: under preview</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>187. Evaluating the Robustness of Retrieval-Augmented Generation to   Adversarial Evidence in the Health Domain</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shakiba Amirshahi, Amin Bigdeli, Charles L. A. Clarke et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03787v1" target="_blank">arXiv:2509.03787v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03787v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Retrieval augmented generation (RAG) systems provide a method for factually
grounding the responses of a Large Language Model (LLM) by providing retrieved
evidence, or context, as support. Guided by this context, RAG systems can
reduce hallucinations and expand the ability of LLMs to accurately answer
questions outside the scope of their training data. Unfortunately, this design
introduces a critical vulnerability: LLMs may absorb and reproduce
misinformation present in retrieved evidence. This ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>188. Integrating Pruning with Quantization for Efficient Deep Neural Networks   Compression</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sara Makenali, Babak Rokh, Ali Azarpeyvand</span><br>
                    <span class="meta-item">ğŸ“ cs.NE</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04244v1" target="_blank">arXiv:2509.04244v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04244v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Deep Neural Networks (DNNs) have achieved significant advances in a wide
range of applications. However, their deployment on resource-constrained
devices remains a challenge due to the large number of layers and parameters,
which result in considerable computational and memory demands. To address this
issue, pruning and quantization are two widely used compression techniques,
commonly applied individually in most studies to reduce model size and enhance
processing speed. Nevertheless, combining ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>189. An invertible generative model for forward and inverse problems</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tristan van Leeuwen, Christoph Brune, Marcello Carioni</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG, math.PR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03910v1" target="_blank">arXiv:2509.03910v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03910v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We formulate the inverse problem in a Bayesian framework and aim to train a
generative model that allows us to simulate (i.e., sample from the likelihood)
and do inference (i.e., sample from the posterior). We review the use of
triangular normalizing flows for conditional sampling in this context and show
how to combine two such triangular maps (an upper and a lower one) in to one
invertible mapping that can be used for simulation and inference. We work out
several useful properties of this inve...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>190. Asymptotic convexity of wide and shallow neural networks</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Vivek Borkar, Parthe Pandit</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG, math.PR, 68T07</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.01044v2" target="_blank">arXiv:2507.01044v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.01044v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">For a simple model of shallow and wide neural networks, we show that the
epigraph of its input-output map as a function of the network parameters
approximates epigraph of a. convex function in a precise sense. This leads to a
plausible explanation of their observed good performance.</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 5 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>191. Solving Robotics Tasks with Prior Demonstration via   Exploration-Efficient Deep Reinforcement Learning</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chengyandan Shen, Christoffer Sloth</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04069v1" target="_blank">arXiv:2509.04069v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04069v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper proposes an exploration-efficient Deep Reinforcement Learning with
Reference policy (DRLR) framework for learning robotics tasks that incorporates
demonstrations. The DRLR framework is developed based on an algorithm called
Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve
IBRL by modifying the action selection module. The proposed action selection
module provides a calibrated Q-value, which mitigates the bootstrapping error
that otherwise leads to inefficien...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>192. ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in   Cluttered Scenes</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zeyuan Chen, Qiyang Yan, Yuanpei Chen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.14317v3" target="_blank">arXiv:2506.14317v3</a> | 
                    <a href="http://arxiv.org/pdf/2506.14317v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Dexterous grasping in cluttered scenes presents significant challenges due to
diverse object geometries, occlusions, and potential collisions. Existing
methods primarily focus on single-object grasping or grasp-pose prediction
without interaction, which are insufficient for complex, cluttered scenes.
Recent vision-language-action models offer a potential solution but require
extensive real-world demonstrations, making them costly and difficult to scale.
To address these limitations, we revisit t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at CoRL 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>193. Spiking Neural Network Decoders of Finger Forces from High-Density   Intramuscular Microelectrode Arrays</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Farah Baracat, Agnese Grison, Dario Farina et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, eess.SP</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04088v1" target="_blank">arXiv:2509.04088v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04088v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Restoring naturalistic finger control in assistive technologies requires the
continuous decoding of motor intent with high accuracy, efficiency, and
robustness. Here, we present a spike-based decoding framework that integrates
spiking neural networks (SNNs) with motor unit activity extracted from
high-density intramuscular microelectrode arrays. We demonstrate simultaneous
and proportional decoding of individual finger forces from motor unit spike
trains during isometric contractions at 15% of m...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>194. Temporal Interest-Driven Multimodal Personalized Content Generation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tian Miao</span><br>
                    <span class="meta-item">ğŸ“ cs.IR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04330v1" target="_blank">arXiv:2509.04330v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04330v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With the dynamic evolution of user interests and the increasing multimodal
demands in internet applications, personalized content generation strategies
based on static interest preferences struggle to meet practical application
requirements. The proposed TIMGen (Temporal Interest-driven Multimodal
Generation) model addresses this challenge by modeling the long-term temporal
evolution of users&#x27; interests and capturing dynamic interest representations
with strong temporal dependencies. This model ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>195. PianoBind: A Multimodal Joint Embedding Model for Pop-piano Music</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 2.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hayeon Bang, Eunjin Choi, Seungheon Doh et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.IR, cs.MM</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04215v1" target="_blank">arXiv:2509.04215v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04215v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Solo piano music, despite being a single-instrument medium, possesses
significant expressive capabilities, conveying rich semantic information across
genres, moods, and styles. However, current general-purpose music
representation models, predominantly trained on large-scale datasets, often
struggle to captures subtle semantic distinctions within homogeneous solo piano
music. Furthermore, existing piano-specific representation models are typically
unimodal, failing to capture the inherently mult...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted for publication at the 26th International Society for Music
  Information Retrieval Conference (ISMIR 2025)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>196. ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Adrian Catalin Lutu, Ioana Pintilie, Elena Burceanu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04449v1" target="_blank">arXiv:2509.04449v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04449v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present ChronoGraph, a graph-structured multivariate time series
forecasting dataset built from real-world production microservices. Each node
is a service that emits a multivariate stream of system-level performance
metrics, capturing CPU, memory, and network usage patterns, while directed
edges encode dependencies between services. The primary task is forecasting
future values of these signals at the service level. In addition, ChronoGraph
provides expert-annotated incident windows as anoma...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>197. Understanding Space Is Rocket Science -- Only Top Reasoning Models Can   Solve Spatial Understanding Tasks</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Nils Hoehing, Mayug Maniparambil, Ellen Rushe et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI, cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02175v2" target="_blank">arXiv:2509.02175v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02175v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We propose RocketScience, an open-source contrastive VLM benchmark that tests
for spatial relation understanding. It is comprised of entirely new real-world
image-text pairs covering mostly relative spatial understanding and the order
of objects. The benchmark is designed to be very easy for humans and hard for
the current generation of VLMs, and this is empirically verified. Our results
show a striking lack of spatial relation understanding in open source and
frontier commercial VLMs and a surp...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>198. AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open   Worlds</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qizhou Wang, Hanxun Huang, Guansong Pang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04345v1" target="_blank">arXiv:2509.04345v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04345v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Speech generation systems can produce remarkably realistic vocalisations that
are often indistinguishable from human speech, posing significant authenticity
challenges. Although numerous deepfake detection methods have been developed,
their effectiveness in real-world environments remains unrealiable due to the
domain shift between training and test samples arising from diverse human
speech and fast evolving speech synthesis systems. This is not adequately
addressed by current datasets, which la...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>199. Improving Robustness of AlphaZero Algorithms to Test-Time Environment   Changes</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Isidoro Tamassia, Wendelin BÃ¶hmer</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04317v1" target="_blank">arXiv:2509.04317v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04317v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standa...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>200. Evaluating Quality of Gaming Narratives Co-created with AI</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Arturo Valdivia, Paolo Burelli</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04239v1" target="_blank">arXiv:2509.04239v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04239v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>201. Theory of Mind Using Active Inference: A Framework for Multi-Agent   Cooperation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Riddhi J. Pitliya, Ozan Ã‡atal, Toon Van de Maele et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.MA</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.00401v2" target="_blank">arXiv:2508.00401v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.00401v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Theory of Mind (ToM) -- the ability to understand that others can have
differing knowledge and goals -- enables agents to reason about others&#x27; beliefs
while planning their own actions. We present a novel approach to multi-agent
cooperation by implementing ToM within active inference. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication. In
our framework, ToM-equipped agents ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>202. First Order Model-Based RL through Decoupled Backpropagation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Joseph Amigo, Rooholla Khorrambakht, Elliot Chane-Sane et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.00215v2" target="_blank">arXiv:2509.00215v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.00215v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">There is growing interest in reinforcement learning (RL) methods that
leverage the simulator&#x27;s derivatives to improve learning efficiency. While
early gradient-based approaches have demonstrated superior performance compared
to derivative-free methods, accessing simulator gradients is often impractical
due to their implementation cost or unavailability. Model-based RL (MBRL) can
approximate these gradients via learned dynamics models, but the solver
efficiency suffers from compounding prediction...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: CoRL 2025. Project website: https://machines-in-motion.github.io/DMO/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>203. YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind   Turbine Components</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Serhii Svystun, Pavlo Radiuk, Oleksandr Melnychenko et al.</span><br>
                    <span class="meta-item">ğŸ“ I.2.10; I.4.8; I.5.4; I.2.9, cs.AI, cs.CV, cs.RO, 68T07, 68T45, 68U10, 68T40</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04156v1" target="_blank">arXiv:2509.04156v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04156v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up
new opportunities for monitoring wind power plants, including blades, towers,
and other critical components. However, reliable defect detection requires
high-resolution data and efficient methods to process multispectral imagery. In
this research, we aim to enhance defect detection accuracy through the
development of an ensemble of YOLO-based deep learning models that integrate
both visible and thermal channels. We pro...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The 13th IEEE International Conference on Intelligent Data
  Acquisition and Advanced Computing Systems: Technology and Applications, 4-6
  September, 2025, Gliwice, Poland</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>204. Extending FKG.in: Towards a Food Claim Traceability Network</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Saransh Kumar Gupta, Rizwan Gulzar Mir, Lipika Dey et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.IR, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.16117v2" target="_blank">arXiv:2508.16117v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.16117v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The global food landscape is rife with scientific, cultural, and commercial
claims about what foods are, what they do, what they should not do, or should
not do. These range from rigorously studied health benefits (probiotics improve
gut health) and misrepresentations (soaked almonds make one smarter) to vague
promises (superfoods boost immunity) and culturally rooted beliefs (cold foods
cause coughs). Despite their widespread influence, the infrastructure for
tracing, verifying, and contextuali...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 10 pages, 3 figures, 1 table, 45 references, ACM International
  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>205. Enhancing FKG.in: automating Indian food composition analysis</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.IR, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2412.05248v3" target="_blank">arXiv:2412.05248v3</a> | 
                    <a href="http://arxiv.org/pdf/2412.05248v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG[.]in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG[.]in and iteratively
supplement food composition data from verified knowledge...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages, 5 figures, 30 references, International Conference on
  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>206. Stochastic Parameter Decomposition</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lucius Bushnaq, Dan Braun, Lee Sharkey</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.20790v2" target="_blank">arXiv:2506.20790v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.20790v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A key step in reverse engineering neural networks is to decompose them into
simpler parts that can be studied in relative isolation. Linear parameter
decomposition -- a framework that has been proposed to resolve several issues
with current decomposition methods -- decomposes neural network parameters into
a sum of sparsely used vectors in parameter space. However, the current main
method in this framework, Attribution-based Parameter Decomposition (APD), is
impractical on account of its computa...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>207. Analysis of Bluffing by DQN and CFR in Leduc Hold&#x27;em Poker</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tarik Zaciragic, Aske Plaat, K. Joost Batenburg</span><br>
                    <span class="meta-item">ğŸ“ cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04125v1" target="_blank">arXiv:2509.04125v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04125v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold&#x27;em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play aga...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>208. EHVC: Efficient Hierarchical Reference and Quality Structure for Neural   Video Coding</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junqi Liao, Yaojun Wu, Chaoyi Lin et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.IV, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04118v1" target="_blank">arXiv:2509.04118v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04118v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Neural video codecs (NVCs), leveraging the power of end-to-end learning, have
demonstrated remarkable coding efficiency improvements over traditional video
codecs. Recent research has begun to pay attention to the quality structures in
NVCs, optimizing them by introducing explicit hierarchical designs. However,
less attention has been paid to the reference structure design, which
fundamentally should be aligned with the hierarchical quality structure. In
addition, there is still significant room...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 8 figures, Accepted to ACMMM 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>209. WASP: A Weight-Space Approach to Detecting Learned Spuriousness</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Cristian Daniel PÄƒduraru, Antonio BÄƒrbÄƒlau, Radu Filipescu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2410.18970v4" target="_blank">arXiv:2410.18970v4</a> | 
                    <a href="http://arxiv.org/pdf/2410.18970v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">It is of crucial importance to train machine learning models such that they
clearly understand what defines each class in a given task. Though there is a
sum of works dedicated to identifying the spurious correlations featured by a
dataset that may impact the model&#x27;s understanding of the classes, all current
approaches rely solely on data or error analysis. That is, they cannot point
out spurious correlations learned by the model that are not already pointed out
by the counterexamples featured i...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: under review</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>210. Beyond holography: the entropic quantum gravity foundations of image   processing</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ginestra Bianconi</span><br>
                    <span class="meta-item">ğŸ“ cond-mat.dis-nn, cond-mat.stat-mech, cs.AI, gr-qc, quant-ph</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.14048v2" target="_blank">arXiv:2503.14048v2</a> | 
                    <a href="http://arxiv.org/pdf/2503.14048v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recently, thanks to the development of artificial intelligence (AI) there is
increasing scientific attention in establishing the connections between
theoretical physics and AI. Traditionally, these connections have been focusing
mostly on the relation between string theory and image processing and involve
important theoretical paradigms such as holography. Recently G. Bianconi has
formulated the Gravity from Entropy (GfE) approach to quantum gravity in which
gravity is derived from the geometric...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: (7 pages, 1 figure)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>211. SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for   Histopathology Whole Slide Image Classification</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yu Bai, Zitong Yu, Haowen Tian et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03973v1" target="_blank">arXiv:2509.03973v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03973v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for
performing WSI classification. SAC-MIL consists of a positional encoding module
to encode position information and a SAC block to perform full instance
correlations. The positional encoding module utilizes the instance coordinates
within the slide to encode the spatial relationships instead of the instance
index in the input WSI sequence. The positional encoding module can also handle
the length extrapolation issue wher...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>212. Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual   Try-On from a Single Image -- Technical Preview</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04450v1" target="_blank">arXiv:2509.04450v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04450v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining g...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project Page: https://immortalco.github.io/VirtualFittingRoom/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>213. Understanding sparse autoencoder scaling in the presence of feature   manifolds</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Eric J. Michaud, Liv Gorton, Tom McGrath</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02565v2" target="_blank">arXiv:2509.02565v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02565v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Sparse autoencoders (SAEs) model the activations of a neural network as
linear combinations of sparsely occurring directions of variation (latents).
The ability of SAEs to reconstruct activations follows scaling laws w.r.t. the
number of latents. In this work, we adapt a capacity-allocation model from the
neural scaling literature (Brill, 2024) to understand SAE scaling, and in
particular, to understand how &quot;feature manifolds&quot; (multi-dimensional features)
influence scaling behavior. Consistent w...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 13 pages, 8 figures, short workshop submission</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>214. Moco: A Learnable Meta Optimizer for Combinatorial Optimization</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tim Dernedde, Daniela Thyssens, SÃ¶ren Dittrich et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2402.04915v3" target="_blank">arXiv:2402.04915v3</a> | 
                    <a href="http://arxiv.org/pdf/2402.04915v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Relevant combinatorial optimization problems (COPs) are often NP-hard. While
they have been tackled mainly via handcrafted heuristics in the past, advances
in neural networks have motivated the development of general methods to learn
heuristics from data. Many approaches utilize a neural network to directly
construct a solution, but are limited in further improving based on already
constructed solutions at inference time. Our approach, Moco, defines a
lightweight solution construction procedure,...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 20 pages, 2 figures. A prior version was published in Advances in
  Knowledge Discovery and Data Mining. PAKDD 2025. Lecture Notes in Computer
  Science, vol 15872. Springer, Singapore</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>215. Characteristic Energy Behavior Profiling of Non-Residential Buildings</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Haley Dozier, Althea Henslee</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04322v1" target="_blank">arXiv:2509.04322v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04322v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Due to the threat of changing climate and extreme weather events, the
infrastructure of the United States Army installations is at risk. More than
ever, climate resilience measures are needed to protect facility assets that
support critical missions and help generate readiness. As most of the Army
installations within the continental United States rely on commercial energy
and water sources, resilience to the vulnerabilities within independent energy
resources (electricity grids, natural gas pip...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>216. Generalized and Unified Equivalences between Hardness and Pseudoentropy</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lunjia Hu, Salil Vadhan</span><br>
                    <span class="meta-item">ğŸ“ cs.CC, cs.CR, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.05972v2" target="_blank">arXiv:2507.05972v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.05972v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Pseudoentropy characterizations provide a quantitatively precise
demonstration of the close relationship between computational hardness and
computational randomness. We prove a unified pseudoentropy characterization
that generalizes and strengthens previous results for both uniform and
non-uniform models of computation. Our characterization holds for a general
family of entropy notions that encompasses the common notions of Shannon
entropy and min entropy as special cases. Moreover, we show that...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to TCC 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>217. Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT   Systems</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Pavle Vasiljevic, Milica Matic, Miroslav Popovic</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.DC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.05138v2" target="_blank">arXiv:2506.05138v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.05138v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recently, federated learning frameworks such as Python TestBed for Federated
Learning Algorithms and MicroPython TestBed for Federated Learning Algorithms
have emerged to tackle user privacy concerns and efficiency in embedded
systems. Even more recently, an efficient federated anomaly detection
algorithm, FLiForest, based on Isolation Forests has been developed, offering a
low-resource, unsupervised method well-suited for edge deployment and
continuous learning. In this paper, we present an app...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 6 pages, 4 algorithms, 5 figures, 2 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>218. An Interactive Framework for Finding the Optimal Trade-off in   Differential Privacy</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yaohong Yang, Aki Rehn, Sammie Katt et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04290v1" target="_blank">arXiv:2509.04290v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04290v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Differential privacy (DP) is the standard for privacy-preserving analysis,
and introduces a fundamental trade-off between privacy guarantees and model
performance. Selecting the optimal balance is a critical challenge that can be
framed as a multi-objective optimization (MOO) problem where one first
discovers the set of optimal trade-offs (the Pareto front) and then learns a
decision-maker&#x27;s preference over them. While a rich body of work on interactive
MOO exists, the standard approach -- model...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 20 pages, 12 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>219. Privacy Risks in Time Series Forecasting: User- and Record-Level   Membership Inference</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Nicolas Johansson, Tobias Olsson, Daniel Nilsson et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04169v1" target="_blank">arXiv:2509.04169v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04169v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Membership inference attacks (MIAs) aim to determine whether specific data
were used to train a model. While extensively studied on classification models,
their impact on time series forecasting remains largely unexplored. We address
this gap by introducing two new attacks: (i) an adaptation of multivariate
LiRA, a state-of-the-art MIA originally developed for classification models, to
the time-series forecasting setting, and (ii) a novel end-to-end learning
approach called Deep Time Series (DTS...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>220. Uncertainty-Guided Likelihood Tree Search</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Julia Grosse, Ruotian Wu, Ahmad Rashid et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2407.03951v3" target="_blank">arXiv:2407.03951v3</a> | 
                    <a href="http://arxiv.org/pdf/2407.03951v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Tree search is a fundamental tool for planning, as many sequential
decision-making problems can be framed as searching over tree-structured
spaces. We propose an uncertainty-guided tree search algorithm for settings
where the reward function is a log-likelihood function of the paths. Due to the
combinatorial explosion of the tree size, the set of paths for which one can
obtain rewards is sparse, particularly when the likelihood is obtained through
expensive evaluations, such as by querying a lar...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 10 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>221. Bayesian Additive Regression Trees for functional ANOVA model</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Seokhun Park, Insung Kong, Yongdai Kim</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03317v2" target="_blank">arXiv:2509.03317v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03317v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Bayesian Additive Regression Trees (BART) is a powerful statistical model
that leverages the strengths of Bayesian inference and regression trees. It has
received significant attention for capturing complex non-linear relationships
and interactions among predictors. However, the accuracy of BART often comes at
the cost of interpretability. To address this limitation, we propose ANOVA
Bayesian Additive Regression Trees (ANOVA-BART), a novel extension of BART
based on the functional ANOVA decompos...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>222. Shuffling Heuristic in Variational Inequalities: Establishing New   Convergence Guarantees</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Daniil Medyakov, Gleb Molodtsov, Grigoriy Evseev et al.</span><br>
                    <span class="meta-item">ğŸ“ math.OC, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04133v1" target="_blank">arXiv:2509.04133v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04133v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Variational inequalities have gained significant attention in machine
learning and optimization research. While stochastic methods for solving these
problems typically assume independent data sampling, we investigate an
alternative approach -- the shuffling heuristic. This strategy involves
permuting the dataset before sequential processing, ensuring equal
consideration of all data points. Despite its practical utility, theoretical
guarantees for shuffling in variational inequalities remain unex...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 25 pages, 5 figures, 2 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>223. FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data   Heterogeneity</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ozgu Goksu, Nicolas Pugeault</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04107v1" target="_blank">arXiv:2509.04107v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04107v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Federated Learning (FL) provides decentralised model training, which
effectively tackles problems such as distributed data and privacy preservation.
However, the generalisation of global models frequently faces challenges from
data heterogeneity among clients. This challenge becomes even more pronounced
when datasets are limited in size and class imbalance. To address data
heterogeneity, we propose a novel method, \textit{FedQuad}, that explicitly
optimises smaller intra-class variance and large...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The 3rd IEEE International Conference on Federated Learning
  Technologies and Applications (FLTA25)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>224. Deliberate Planning of 3D Bin Packing on Packing Configuration Trees</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hang Zhao, Juzhan Xu, Kexiong Yu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.04421v4" target="_blank">arXiv:2504.04421v4</a> | 
                    <a href="http://arxiv.org/pdf/2504.04421v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Online 3D Bin Packing Problem (3D-BPP) has widespread applications in
industrial automation. Existing methods usually solve the problem with limited
resolution of spatial discretization, and/or cannot deal with complex practical
constraints well. We propose to enhance the practical applicability of online
3D-BPP via learning on a novel hierarchical representation, packing
configuration tree (PCT). PCT is a full-fledged description of the state and
action space of bin packing which can support pa...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: International Journal of Robotics Research</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>225. Emergence of Quantised Representations Isolated to Anisotropic Functions</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ George Bird</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, I.5.1; F.1.1; I.2.6</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.12070v3" target="_blank">arXiv:2507.12070v3</a> | 
                    <a href="http://arxiv.org/pdf/2507.12070v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents a novel methodology for determining representational
structure, which builds upon the existing Spotlight Resonance method. This new
tool is used to gain insight into how discrete representations can emerge and
organise in autoencoder models, through a controlled ablation study in which
only the activation function is altered. Using this technique, the validity of
whether function-driven symmetries can act as implicit inductive biases on
representations is determined. Represen...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 41 pages, 37 figures, edited some introductory phrasing and
  appendices on hyperoctahedral LeakyReLU</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>226. On Aligning Prediction Models with Clinical Experiential Learning: A   Prostate Cancer Case Study</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jacqueline J. Vallon, William Overman, Wanqiao Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04053v1" target="_blank">arXiv:2509.04053v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04053v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Over the past decade, the use of machine learning (ML) models in healthcare
applications has rapidly increased. Despite high performance, modern ML models
do not always capture patterns the end user requires. For example, a model may
predict a non-monotonically decreasing relationship between cancer stage and
survival, keeping all other features fixed. In this paper, we present a
reproducible framework for investigating this misalignment between model
behavior and clinical experiential learning,...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>227. TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface   Scattering for Perlin Distributed Heterogeneous Media</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ashish Tiwari, Satyam Bhardwaj, Yash Bachwana et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.GR, cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04047v1" target="_blank">arXiv:2509.04047v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04047v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: To appear in Pacific Graphics 2025 (CGF Journal Track), Project page:
  https://yashbachwana.github.io/TensoIS/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>228. What if I ask in \textit{alia lingua}? Measuring Functional Similarity   Across Languages</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Debangan Mishra, Arihant Rastogi, Agyeya Negi et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04032v1" target="_blank">arXiv:2509.04032v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04032v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">How similar are model outputs across languages? In this work, we study this
question using a recently proposed model similarity metric $\kappa_p$ applied
to 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that a
model&#x27;s responses become increasingly consistent across languages as its size
and capability grow. Interestingly, models exhibit greater cross-lingual
consistency within themselves than agreement with other models prompted in the
same language. These results highlight no...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Preprint, 11 Pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>229. Learning neural representations for X-ray ptychography reconstruction   with unknown probes</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tingyou Li, Zixin Xu, Zirui Gao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04402v1" target="_blank">arXiv:2509.04402v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04402v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">X-ray ptychography provides exceptional nanoscale resolution and is widely
applied in materials science, biology, and nanotechnology. However, its full
potential is constrained by the critical challenge of accurately reconstructing
images when the illuminating probe is unknown. Conventional iterative methods
and deep learning approaches are often suboptimal, particularly under the
low-signal conditions inherent to low-dose and high-speed experiments. These
limitations compromise reconstruction f...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>230. Ecological Legacies of Pre-Columbian Settlements Evident in Palm   Clusters of Neotropical Mountain Forests</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sebastian Fajardo, Sina Mohammadi, Jonas Gregorio de Souza et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.06949v2" target="_blank">arXiv:2507.06949v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.06949v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Ancient populations markedly transformed Neotropical forests, yet the spatial
extent of their ecological influence remains underexplored at high resolution.
Here we present a deep learning and remote sensing based approach to estimate
areas of pre-Columbian forest modification based on modern vegetation. We apply
this method to high-resolution satellite imagery from the Sierra Nevada de
Santa Marta, Colombia, as a demonstration of a scalable approach, to evaluate
palm tree distributions in relat...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>231. Stitching the Story: Creating Panoramic Incident Summaries from   Body-Worn Footage</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dor Cohen, Inga Efrosman, Yehudit Aperstein et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04370v1" target="_blank">arXiv:2509.04370v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04370v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">First responders widely adopt body-worn cameras to document incident scenes
and support post-event analysis. However, reviewing lengthy video footage is
impractical in time-critical situations. Effective situational awareness
demands a concise visual summary that can be quickly interpreted. This work
presents a computer vision pipeline that transforms body-camera footage into
informative panoramic images summarizing the incident scene. Our method
leverages monocular Simultaneous Localization and...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 5 pages, 3 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>232. MICACL: Multi-Instance Category-Aware Contrastive Learning for   Long-Tailed Dynamic Facial Expression Recognition</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Feng-Qi Cui, Zhen Lin, Xinlong Rao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04344v1" target="_blank">arXiv:2509.04344v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04344v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Dynamic facial expression recognition (DFER) faces significant challenges due
to long-tailed category distributions and complexity of spatio-temporal feature
modeling. While existing deep learning-based methods have improved DFER
performance, they often fail to address these issues, resulting in severe model
induction bias. To overcome these limitations, we propose a novel
multi-instance learning framework called MICACL, which integrates
spatio-temporal dependency modeling and long-tailed contra...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by IEEE ISPA2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>233. DIO: Refining Mutual Information and Causal Chain to Enhance Machine   Abstract Reasoning Ability</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ruizhuo Song, Beiming Yuan</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.15387v4" target="_blank">arXiv:2508.15387v4</a> | 
                    <a href="http://arxiv.org/pdf/2508.15387v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite the outstanding performance of current deep learning models across
various domains, their fundamental bottleneck in abstract reasoning remains
unresolved. To address this challenge, the academic community has introduced
Raven&#x27;s Progressive Matrices (RPM) problems as an authoritative benchmark for
evaluating the abstract reasoning capabilities of deep learning algorithms,
with a focus on core intelligence dimensions such as abstract reasoning,
pattern recognition, and complex problem-solv...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages, 9 figures, 8 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>234. TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale   Category-Aware Temporal Graph</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yaru Chen, Faegheh Sardari, Peiliang Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.MM</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04086v1" target="_blank">arXiv:2509.04086v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04086v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Audio-Visual Video Parsing (AVVP) task aims to identify event categories and
their occurrence times in a given video with weakly supervised labels. Existing
methods typically fall into two categories: (i) designing enhanced
architectures based on attention mechanism for better temporal modeling, and
(ii) generating richer pseudo-labels to compensate for the absence of
frame-level annotations. However, the first type methods treat noisy
segment-level pseudo labels as reliable supervision and the ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>235. A Re-ranking Method using K-nearest Weighted Fusion for Person   Re-identification</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Quang-Huy Che, Le-Chuong Nguyen, Gia-Nghia Tran et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04050v1" target="_blank">arXiv:2509.04050v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04050v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In person re-identification, re-ranking is a crucial step to enhance the
overall accuracy by refining the initial ranking of retrieved results. Previous
studies have mainly focused on features from single-view images, which can
cause view bias and issues like pose variation, viewpoint changes, and
occlusions. Using multi-view features to present a person can help reduce view
bias. In this work, we present an efficient re-ranking method that generates
multi-view features by aggregating neighbors&#x27;...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published in ICPRAM 2025, ISBN 978-989-758-730-6, ISSN 2184-4313</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>236. Encoder-Only Image Registration</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiang Chen, Renjiu Hu, Jinwei Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.00451v2" target="_blank">arXiv:2509.00451v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.00451v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Learning-based techniques have significantly improved the accuracy and speed
of deformable image registration. However, challenges such as reducing
computational complexity and handling large deformations persist. To address
these challenges, we analyze how convolutional neural networks (ConvNets)
influence registration performance using the Horn-Schunck optical flow
equation. Supported by prior studies and our empirical experiments, we observe
that ConvNets play two key roles in registration: l...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>237. Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference   Optimization and Temporal Motion Modulation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jiahao Cui, Yan Chen, Mingwang Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.23525v2" target="_blank">arXiv:2505.23525v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.23525v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Generating highly dynamic and photorealistic portrait animations driven by
audio and skeletal motion remains challenging due to the need for precise lip
synchronization, natural facial expressions, and high-fidelity body motion
dynamics. We propose a human-preference-aligned diffusion framework that
addresses these challenges through two key innovations. First, we introduce
direct preference optimization tailored for human-centric animation, leveraging
a curated dataset of human preferences to a...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>238. Defending LVLMs Against Vision Attacks through Partial-Perception   Supervision</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Qi Zhou, Tianlin Li, Qing Guo et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.AI, cs.CR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2412.12722v2" target="_blank">arXiv:2412.12722v2</a> | 
                    <a href="http://arxiv.org/pdf/2412.12722v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent studies have raised significant concerns regarding the vulnerability
of Large Vision Language Models (LVLMs) to maliciously injected or perturbed
input images, which can mislead their responses. Existing defense methods show
that such vision attacks are sensitive to image modifications especially
cropping, using majority voting across responses of modified images as
corrected responses. However, these modifications often result in partial
images and distort the semantics, which reduces re...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to ICML 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>239. LMVC: An End-to-End Learned Multiview Video Coding Framework</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xihua Sheng, Yingwen Zhang, Long Xu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03922v1" target="_blank">arXiv:2509.03922v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03922v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Multiview video is a key data source for volumetric video, enabling immersive
3D scene reconstruction but posing significant challenges in storage and
transmission due to its massive data volume. Recently, deep learning-based
end-to-end video coding has achieved great success, yet most focus on
single-view or stereo videos, leaving general multiview scenarios
underexplored. This paper proposes an end-to-end learned multiview video coding
(LMVC) framework that ensures random access and backward c...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>240. MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Gowen Loo, Chang Liu, Qinghong Yin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03891v1" target="_blank">arXiv:2509.03891v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03891v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Smartphones have become indispensable in people&#x27;s daily lives, permeating
nearly every aspect of modern society. With the continuous advancement of large
language models (LLMs), numerous LLM-based mobile agents have emerged. These
agents are capable of accurately parsing diverse user queries and automatically
assisting users in completing complex or repetitive operations. However,
current agents 1) heavily rely on the comprehension ability of LLMs, which can
lead to errors caused by misoperation...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>241. Contextualized Token Discrimination for Speech Search Query Correction</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junyu Lu, Di Jiang, Mengze Hong et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04393v1" target="_blank">arXiv:2509.04393v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04393v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Query spelling correction is an important function of modern search engines
since it effectively helps users express their intentions clearly. With the
growing popularity of speech search driven by Automated Speech Recognition
(ASR) systems, this paper introduces a novel method named Contextualized Token
Discrimination (CTD) to conduct effective speech query correction. In CTD, we
first employ BERT to generate token-level contextualized representations and
then construct a composition layer to e...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>242. DynaSaur: Large Language Agents Beyond Predefined Actions</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dang Nguyen, Viet Dac Lai, Seunghyun Yoon et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.01747v3" target="_blank">arXiv:2411.01747v3</a> | 
                    <a href="http://arxiv.org/pdf/2411.01747v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Existing LLM agent systems typically select actions from a fixed and
predefined set at every step. While this approach is effective in closed,
narrowly scoped environments, it presents two major challenges for real-world,
open-ended scenarios: (1) it significantly restricts the planning and acting
capabilities of LLM agents, and (2) it requires substantial human effort to
enumerate and implement all possible actions, which is impractical in complex
environments with a vast number of potential ac...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Published as a conference paper at COLM 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>243. Can Compact Language Models Search Like Agents? Distillation-Guided   Policy Optimization for Preserving Agentic RAG Capabilities</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Rikuto Kotoge, Mai Nishimura, Jiaxin Ma</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.20324v2" target="_blank">arXiv:2508.20324v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.20324v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>244. Explicit and Implicit Data Augmentation for Social Event Detection</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Congbo Ma, Yuxia Wang, Jia Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.SI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04202v1" target="_blank">arXiv:2509.04202v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04202v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Social event detection involves identifying and categorizing important events
from social media, which relies on labeled data, but annotation is costly and
labor-intensive. To address this problem, we propose Augmentation framework for
Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework,
which combines explicit text-based and implicit feature-space augmentation to
enhance data diversity and model robustness. The explicit augmentation utilizes
large language models to en...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>245. Joint Modeling of Entities and Discourse Relations for Coherence   Assessment</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wei Liu, Michael Strube</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04182v1" target="_blank">arXiv:2509.04182v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04182v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In linguistics, coherence can be achieved by different means, such as by
maintaining reference to the same set of entities across sentences and by
establishing discourse relations between them. However, most existing work on
coherence modeling focuses exclusively on either entity features or discourse
relation features, with little attention given to combining the two. In this
study, we explore two methods for jointly modeling entities and discourse
relations for coherence assessment. Experiment...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>246. SLM-Bench: A Comprehensive Benchmark of Small Language Models on   Environmental Impacts--Extended Version</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Nghiem Thanh Pham, Tung Kieu, Duc-Manh Nguyen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CY, cs.PF</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.15478v2" target="_blank">arXiv:2508.15478v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.15478v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Small Language Models (SLMs) offer computational efficiency and
accessibility, yet a systematic evaluation of their performance and
environmental impact remains lacking. We introduce SLM-Bench, the first
benchmark specifically designed to assess SLMs across multiple dimensions,
including accuracy, computational efficiency, and sustainability metrics.
SLM-Bench evaluates 15 SLMs on 9 NLP tasks using 23 datasets spanning 14
domains. The evaluation is conducted on 4 hardware configurations, providi...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 24 pages. An extended version of &quot;SLM-Bench: A Comprehensive
  Benchmark of Small Language Models on Environmental Impacts&quot; accepted at
  EMNLP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>247. MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dan Saattrup Smart</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04111v1" target="_blank">arXiv:2509.04111v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04111v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which
covers 306 languages. The context data comes from Wikipedia articles, with
questions generated by an LLM and the answers appearing verbatim in the
Wikipedia articles. We conduct a crowdsourced human evaluation of the fluency
of the generated questions across 30 of the languages, providing evidence that
the questions are of good quality. We evaluate 6 different language models,
both decoder and encoder models of varying s...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>248. Exploring Linguistic Features for Turkish Text Readability</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ahmet Yavuz Uluslu, Gerold Schneider</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2306.03774v4" target="_blank">arXiv:2306.03774v4</a> | 
                    <a href="http://arxiv.org/pdf/2306.03774v4" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents the first comprehensive study on automatic readability
assessment of Turkish texts. We combine state-of-the-art neural network models
with linguistic features at lexical, morphological, syntactic and discourse
levels to develop an advanced readability tool. We evaluate the effectiveness
of traditional readability formulas compared to modern automated methods and
identify key linguistic features that determine the readability of Turkish
texts.</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>249. A Comprehensive Survey on Trustworthiness in Reasoning with Large   Language Models</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yanbo Wang, Yongcan Yu, Jian Liang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI, cs.CR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03871v1" target="_blank">arXiv:2509.03871v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03871v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The development of Long-CoT reasoning has advanced LLM performance across
various tasks, including language understanding, complex problem solving, and
code generation. This paradigm enables models to generate intermediate
reasoning steps, thereby improving both accuracy and interpretability. However,
despite these advancements, a comprehensive understanding of how CoT-based
reasoning affects the trustworthiness of language models remains
underdeveloped. In this paper, we survey recent work on r...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 38 pages. This survey considers papers published up to June 30, 2025.
  Work in progress</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>250. Measuring How (Not Just Whether) VLMs Build Common Ground</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Saki Imai, Mert Ä°nan, Anthony Sicilia et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03805v1" target="_blank">arXiv:2509.03805v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03805v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Large vision language models (VLMs) increasingly claim reasoning skills, yet
current benchmarks evaluate them in single-turn or question answering settings.
However, grounding is an interactive process in which people gradually develop
shared understanding through ongoing communication. We introduce a four-metric
suite (grounding efficiency, content alignment, lexical adaptation, and
human-likeness) to systematically evaluate VLM performance in interactive
grounding contexts. We deploy the suite...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>251. HalluEntity: Benchmarking and Understanding Entity-Level Hallucination   Detection</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Min-Hsuan Yeh, Max Kamachee, Seongheon Park et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.11948v3" target="_blank">arXiv:2502.11948v3</a> | 
                    <a href="http://arxiv.org/pdf/2502.11948v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">To mitigate the impact of hallucination nature of LLMs, many studies propose
detecting hallucinated generation through uncertainty estimation. However,
these approaches predominantly operate at the sentence or paragraph level,
failing to pinpoint specific spans or entities responsible for hallucinated
content. This lack of granularity is especially problematic for long-form
outputs that mix accurate and fabricated information. To address this
limitation, we explore entity-level hallucination det...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: TMLR 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>252. SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation   Evaluation</h3>
                <div class="priority-badge priority-medium" style="display: inline-block; margin: 0.5rem 0;">
                    Medium Relevance (Score: 1.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Saki Imai, Mert Ä°nan, Anthony Sicilia et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03791v1" target="_blank">arXiv:2509.03791v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03791v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Evaluating sign language generation is often done through back-translation,
where generated signs are first recognized back to text and then compared to a
reference using text-based metrics. However, this two-step evaluation pipeline
introduces ambiguity: it not only fails to capture the multimodal nature of
sign language-such as facial expressions, spatial grammar, and prosody-but also
makes it hard to pinpoint whether evaluation errors come from sign generation
model or the translation system ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>253. Improved sampling algorithms and PoincarÃ© inequalities for   non-log-concave distributions</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuchen He, Zhehan Lei, Jianan Shao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.DS, cs.LG, math.PR, stat.ML</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.11236v2" target="_blank">arXiv:2507.11236v2</a> | 
                    <a href="http://arxiv.org/pdf/2507.11236v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We study the problem of sampling from a distribution $\mu$ with density
$\propto e^{-V}$ for some potential function $V:\mathbb R^d\to \mathbb R$ with
query access to $V$ and $\nabla V$. We start with the following standard
assumptions:
  (1) The potential function $V$ is $L$-smooth.
  (2) The second moment $\mathbf{E}_{X\sim \mu}[\|X\|^2]\leq M$.
  Recently, He and Zhang (COLT&#x27;25) showed that the query complexity of sampling
from such distributions is at least
$\left(\frac{LM}{d\epsilon}\right)...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>254. Towards understanding Accelerated Stein Variational Gradient Flow --   Analysis of Generalized Bilinear Kernels for Gaussian target distributions</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Viktor Stein, Wuchen Li</span><br>
                    <span class="meta-item">ğŸ“ math.OC, stat.ML, 46N10 (Primary) 46E22 94A15 37Lxx 37A50 (Secondary)</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04008v1" target="_blank">arXiv:2509.04008v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04008v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Stein variational gradient descent (SVGD) is a kernel-based and
non-parametric particle method for sampling from a target distribution, such as
in Bayesian inference and other machine learning tasks. Different from other
particle methods, SVGD does not require estimating the score, which is the
gradient of the log-density. However, in practice, SVGD can be slow compared to
score-estimation-based sampling algorithms. To design a fast and efficient
high-dimensional sampling algorithm with the adva...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 46 pages, 4 figures, 4 algorithms, 4 tables, comments welcome!</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>255. Simulation-based Inference via Langevin Dynamics with Score Matching</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Haoyu Jiang, Yuexi Wang, Yun Yang</span><br>
                    <span class="meta-item">ğŸ“ stat.ME, stat.CO, stat.ML</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03853v1" target="_blank">arXiv:2509.03853v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03853v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Simulation-based inference (SBI) enables Bayesian analysis when the
likelihood is intractable but model simulations are available. Recent advances
in statistics and machine learning, including Approximate Bayesian Computation
and deep generative models, have expanded the applicability of SBI, yet these
methods often face challenges in moderate to high-dimensional parameter spaces.
Motivated by the success of gradient-based Monte Carlo methods in Bayesian
sampling, we propose a novel SBI method t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>256. Estimation of High-Dimensional Markov-Switching VAR Models with an   Approximate EM Algorithm</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiudi Li, Abolfazl Safikhani, Ali Shojaie</span><br>
                    <span class="meta-item">ğŸ“ stat.ME, stat.ML</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2210.07456v3" target="_blank">arXiv:2210.07456v3</a> | 
                    <a href="http://arxiv.org/pdf/2210.07456v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Regime shifts in high-dimensional time series arise naturally in many
applications, from neuroimaging to finance. This problem has received
considerable attention in low-dimensional settings, with both Bayesian and
frequentist methods used extensively for parameter estimation. The EM algorithm
is a particularly popular strategy for parameter estimation in low-dimensional
settings, although the statistical properties of the resulting estimates have
not been well understood. Furthermore, its exten...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>257. HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and   Learning</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhi Su, Bike Zhang, Nima Rahmanian et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.21043v2" target="_blank">arXiv:2508.21043v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.21043v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Humanoid robots have recently achieved impressive progress in locomotion and
whole-body control, yet they remain constrained in tasks that demand rapid
interaction with dynamic environments through manipulation. Table tennis
exemplifies such a challenge: with ball speeds exceeding 5 m/s, players must
perceive, predict, and act within sub-second reaction times, requiring both
agility and precision. To address this, we present a hierarchical framework for
humanoid table tennis that integrates a mo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: add more references</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>258. Classification of Vision-Based Tactile Sensors: A Review</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Haoran Li, Yijiong Lin, Chenghua Lu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02478v2" target="_blank">arXiv:2509.02478v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02478v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Vision-based tactile sensors (VBTS) have gained widespread application in
robotic hands, grippers and prosthetics due to their high spatial resolution,
low manufacturing costs, and ease of customization. While VBTSs have common
design features, such as a camera module, they can differ in a rich diversity
of sensing principles, material compositions, multimodal approaches, and data
interpretation methods. Here, we propose a novel classification of VBTS that
categorizes the technology into two pri...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>259. FPC-VLA: A Vision-Language-Action Framework with a Supervisor for   Failure Prediction and Correction</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yifan Yang, Zhixiang Duan, Tianshi Xie et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04018v1" target="_blank">arXiv:2509.04018v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04018v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Robotic manipulation is a fundamental component of automation. However,
traditional perception-planning pipelines often fall short in open-ended tasks
due to limited flexibility, while the architecture of a single end-to-end
Vision-Language-Action (VLA) offers promising capabilities but lacks crucial
mechanisms for anticipating and recovering from failure. To address these
challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with
a supervisor for failure prediction and corr...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>260. Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall   Climbing Robot</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Branimir Ä†aran, Vladimir MiliÄ‡, Marko Å vaco et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04016v1" target="_blank">arXiv:2509.04016v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04016v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents the design of a pose estimator for a four wheel
independent steer four wheel independent drive (4WIS4WID) wall climbing mobile
robot, based on the fusion of multimodal measurements, including wheel
odometry, visual odometry, and an inertial measurement unit (IMU) data using
Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose
estimator is a critical component of wall climbing mobile robots, as their
operational environment involves carrying precise measure...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: ACCEPTED FOR IEEE EUROPEAN CONFERENCE ON MOBILE ROBOTS 2025. PREPRINT
  VERSION. ACCEPTED JUNE, 2025 AND PRESENTED SEPTEMBER, 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>261. Emancipatory Information Retrieval</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Bhaskar Mitra</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2501.19241v5" target="_blank">arXiv:2501.19241v5</a> | 
                    <a href="http://arxiv.org/pdf/2501.19241v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Our world today is facing a confluence of several mutually reinforcing crises
each of which intersects with concerns of social justice and emancipation. This
paper is a provocation for the role of computer-mediated information access in
our emancipatory struggles. We define emancipatory information retrieval as the
study and development of information access methods that challenge various
forms of human oppression, and situates its activities within broader
collective emancipatory praxis. The te...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>262. Would I regret being different? The influence of social norms on   attitudes toward AI usage</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jaroslaw Kornowicz, Maurice Pape, Kirsten Thommes</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04241v1" target="_blank">arXiv:2509.04241v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04241v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Prior research shows that social norms can reduce algorithm aversion, but
little is known about how such norms become established. Most accounts
emphasize technological and individual determinants, yet AI adoption unfolds
within organizational social contexts shaped by peers and supervisors. We ask
whether the source of the norm-peers or supervisors-shapes AI usage behavior.
This question is practically relevant for organizations seeking to promote
effective AI adoption. We conducted an online v...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 30 pages, 5 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>263. The MolecularWeb Universe: Web-Based, Immersive, Multiuser Molecular   Graphics And Modeling, for Education and Work in Chemistry, Structural   Biology, and Materials Sciences</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Luciano A. Abriata</span><br>
                    <span class="meta-item">ğŸ“ physics.chem-ph, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04056v1" target="_blank">arXiv:2509.04056v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04056v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Molecular visualization software has long supported research and education in
chemical and structural sciences, but consumer devices constrained to 2D inputs
and outputs pose two major challenges: they poorly convey 3D nature, and 3D
manipulation is very difficult. eXtended Reality (XR, including AR and VR)
offers new ways to see and interact with molecules in three dimensions. This
chapter presents the &quot;MolecularWeb&quot; ecosystem (https://molecularweb.org), a set
of web-based tools for immersive v...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 37 pages, 7 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>264. Beyond-Voice: Towards Continuous 3D Hand Pose Tracking on Commercial   Home Assistant Devices</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yin Li, Rohan Reddy, Cheng Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, cs.HC, eess.AS</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2306.17477v3" target="_blank">arXiv:2306.17477v3</a> | 
                    <a href="http://arxiv.org/pdf/2306.17477v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The surging popularity of home assistants and their voice user interface
(VUI) have made them an ideal central control hub for smart home devices.
However, current form factors heavily rely on VUI, which poses accessibility
and usability issues; some latest ones are equipped with additional cameras and
displays, which are costly and raise privacy concerns. These concerns jointly
motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that
allows commodity home assistant devices to t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by IPSN 2024</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>265. Towards an Understanding of Developer Experience-Driven Transparency in   Software Ecosystems</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Rodrigo Oliveira Zacarias, Rodrigo Pereira dos Santos, Patricia Lago</span><br>
                    <span class="meta-item">ğŸ“ cs.SE, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03848v1" target="_blank">arXiv:2509.03848v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03848v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 36 pages Submitted to the ACM Transactions on Software Engineering
  and Methodology. 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>266. Exploring the Integration of Extended Reality and Artificial   Intelligence (AI) for Remote STEM Education and Assessment</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 1.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shadeeb Hossain, Natalie Sommer, Neda Adib</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03812v1" target="_blank">arXiv:2509.03812v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03812v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents a dynamic gamification architecture for an Extended
Reality Artificial Intelligence virtual training environment designed to
enhance STEM education through immersive adaptive, and kinesthetic learning.
The proposed system can be introduced in four phases: Introduction Phase,
Component Development Phase, Fault Introduction and Correction Phase and
Generative AI XR scenarios Phase. Security and privacy are discussed via a
defense-in-depth approach spanning client, middleware, a...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 5 figures, 1 table</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>267. DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hao-Shu Fang, Branden Romero, Yichen Xie et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.HC, cs.AI, cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04441v1" target="_blank">arXiv:2509.04441v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04441v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (vi...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: project page: https://dex-op.github.io</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>268. PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity   Disambiguation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jiajun He, Naoki Sawada, Koichi Miyazaki et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.SD, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04357v1" target="_blank">arXiv:2509.04357v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04357v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Automatic speech recognition (ASR) systems struggle with domain-specific
named entities, especially homophones. Contextual ASR improves recognition but
often fails to capture fine-grained phoneme variations due to limited entity
diversity. Moreover, prior methods treat entities as independent tokens,
leading to incomplete multi-token biasing. To address these issues, we propose
Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation
(PARCO), which integrates phoneme-aware e...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by ASRU 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>269. Decoupled Entity Representation Learning for Pinterest Ads Ranking</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jie Liu, Yinrui Li, Jiankai Sun et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04337v1" target="_blank">arXiv:2509.04337v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04337v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this paper, we introduce a novel framework following an
upstream-downstream paradigm to construct user and item (Pin) embeddings from
diverse data sources, which are essential for Pinterest to deliver personalized
Pins and ads effectively. Our upstream models are trained on extensive data
sources featuring varied signals, utilizing complex architectures to capture
intricate relationships between users and Pins on Pinterest. To ensure
scalability of the upstream models, entity embeddings are l...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>270. Autonomation, Not Automation: Activities and Needs of European   Fact-checkers as a Basis for Designing Human-Centered AI Systems</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Andrea Hrckova, Robert Moro, Ivan Srba et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.AI, cs.CY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2211.12143v3" target="_blank">arXiv:2211.12143v3</a> | 
                    <a href="http://arxiv.org/pdf/2211.12143v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">To mitigate the negative effects of false information more effectively, the
development of Artificial Intelligence (AI) systems to assist fact-checkers is
needed. Nevertheless, the lack of focus on the needs of these stakeholders
results in their limited acceptance and skepticism toward automating the whole
fact-checking process. In this study, we conducted semi-structured in-depth
interviews with Central European fact-checkers. Their activities and problems
were analyzed using iterative content...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 44 pages, 13 figures, 2 annexes. Accepted to ACM Journal on
  Responsible Computing</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>271. The KG-ER Conceptual Schema Language</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Enrico Franconi, BenoÃ®t Groz, Jan Hidders et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.DB, cs.AI, 68P15</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.02548v2" target="_blank">arXiv:2508.02548v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.02548v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We propose KG-ER, a conceptual schema language for knowledge graphs that
describes the structure of knowledge graphs independently of their
representation (relational databases, property graphs, RDF) while helping to
capture the semantics of the information stored in a knowledge graph.</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>272. Image Embedding Sampling Method for Diverse Captioning</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sania Waheed, Na Min An</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.10118v2" target="_blank">arXiv:2502.10118v2</a> | 
                    <a href="http://arxiv.org/pdf/2502.10118v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Image Captioning for state-of-the-art VLMs has significantly improved over
time; however, this comes at the cost of increased computational complexity,
making them less accessible for resource-constrained applications such as
mobile devices and assistive technologies. Alternatively, comparably smaller
VLMs prioritize high-level scene descriptions, overlooking finer details that
contribute to a richer understanding of an image. In this paper, we introduce a
training-free framework that enhances c...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 17 pages, 5 figures, 9 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>273. Learning Active Perception via Self-Evolving Preference Optimization for   GUI Grounding</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wanfu Wang, Qipeng Huang, Guangquan Xue et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04243v1" target="_blank">arXiv:2509.04243v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04243v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Vision Language Models (VLMs) have recently achieved significant progress in
bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model
introduced a zoom-in search strategy that effectively elicits active perception
capabilities in VLMs, improving downstream task performance. However, enabling
VLMs to reason effectively over appropriate image regions remains a core
challenge in GUI grounding, particularly under high-resolution inputs and
complex multi-element visual interacti...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>274. AutoPETIII: The Tracer Frontier. What Frontier?</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zacharia Mesbah, LÃ©o Mottay, Romain Modzelewski et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.IV, cs.AI, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2410.02807v2" target="_blank">arXiv:2410.02807v2</a> | 
                    <a href="http://arxiv.org/pdf/2410.02807v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">For the last three years, the AutoPET competition gathered the medical
imaging community around a hot topic: lesion segmentation on Positron Emitting
Tomography (PET) scans. Each year a different aspect of the problem is
presented; in 2024 the multiplicity of existing and used tracers was at the
core of the challenge. Specifically, this year&#x27;s edition aims to develop a
fully automatic algorithm capable of performing lesion segmentation on a PET/CT
scan, without knowing the tracer, which can eith...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>275. Domain size asymptotics for Markov logic networks</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Vera Koponen</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LO, math.LO, 68T27, 68T30, 68T37, 03C13, I.2; F.4; G.3</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04192v1" target="_blank">arXiv:2509.04192v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04192v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds&#x27;&#x27;, with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this ca...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>276. Towards an Action-Centric Ontology for Cooking Procedures Using Temporal   Graphs</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Aarush Kumbhakern, Saransh Kumar Gupta, Lipika Dey et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04159v1" target="_blank">arXiv:2509.04159v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04159v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL&#x27;s expressiveness and suitability for futur...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 6 pages, 3 figures, 1 table, 11 references, ACM International
  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>277. The human biological advantage over AI</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ William Stewart</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.CY, I.2.0</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04130v1" target="_blank">arXiv:2509.04130v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04130v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor &quot;digital species&quot;, with a rightful...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>278. Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on   Controllers in Reactive Synthesis</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mickael Randour</span><br>
                    <span class="meta-item">ğŸ“ cs.LO, cs.AI, cs.FL, math.PR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04129v1" target="_blank">arXiv:2509.04129v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04129v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In the game-theoretic approach to controller synthesis, we model the
interaction between a system to be controlled and its environment as a game
between these entities, and we seek an appropriate (e.g., winning or optimal)
strategy for the system. This strategy then serves as a formal blueprint for a
real-world controller. A common belief is that simple (e.g., using limited
memory) strategies are better: corresponding controllers are easier to conceive
and understand, and cheaper to produce and ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Invited paper at RP 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>279. Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling   Paradigms for Text-to-Music Generation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Or Tal, Felix Kreuk, Yossi Adi</span><br>
                    <span class="meta-item">ğŸ“ cs.SD, eess.AS, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.08570v3" target="_blank">arXiv:2506.08570v3</a> | 
                    <a href="http://arxiv.org/pdf/2506.08570v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent progress in text-to-music generation has enabled models to synthesize
high-quality musical segments, full compositions, and even respond to
fine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA)
systems differ significantly in many dimensions, such as training datasets,
modeling paradigms, and architectural choices. This diversity complicates
efforts to evaluate models fairly and identify which design choices influence
performance the most. While factors like data ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>280. Neural Video Compression with In-Loop Contextual Filtering and   Out-of-Loop Reconstruction Enhancement</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yaojun Wu, Chaoyi Lin, Yiming Wang et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.IV, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04051v1" target="_blank">arXiv:2509.04051v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04051v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper explores the application of enhancement filtering techniques in
neural video compression. Specifically, we categorize these techniques into
in-loop contextual filtering and out-of-loop reconstruction enhancement based
on whether the enhanced representation affects the subsequent coding loop.
In-loop contextual filtering refines the temporal context by mitigating error
propagation during frame-by-frame encoding. However, its influence on both the
current and subsequent frames poses cha...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 9 pages, 8 figures, Accepted to ACMMM 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>281. Oruga: An Avatar of Representational Systems Theory</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Daniel Raggi, Gem Stapleton, Mateja Jamnik et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LO, 68T30, 68T27, 03B35, I.2.4; I.2.3; F.4.1; F.4.3</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04041v1" target="_blank">arXiv:2509.04041v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04041v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>282. Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum   as Fallback</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kai Sauerwald, Kenneth Skiba, Eduardo FermÃ© et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.AI, cs.LO, 03E99, 91B14, I.2.4</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.03315v2" target="_blank">arXiv:2506.03315v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.03315v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We study how linear orders can be employed to realise choice functions for
which the set of potential choices is restricted, i.e., the possible choice is
not possible among the full powerset of all alternatives. In such restricted
settings, constructing a choice function via a relation on the alternatives is
not always possible. However, we show that one can always construct a choice
function via a linear order on sets of alternatives, even when a fallback value
is encoded as the minimal element...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>283. Structure Transfer: an Inference-Based Calculus for the Transformation   of Representations</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Daniel Raggi, Gem Stapleton, Mateja Jamnik et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.AI, cs.LO, 68T30, 68T27, 03B35, I.2.4; I.2.3; F.4.1; F.4.3</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03249v2" target="_blank">arXiv:2509.03249v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.03249v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Representation choice is of fundamental importance to our ability to
communicate and reason effectively. A major unsolved problem, addressed in this
paper, is how to devise representational-system (RS) agnostic techniques that
drive representation transformation and choice. We present a novel calculus,
called structure transfer, that enables representation transformation across
diverse RSs. Specifically, given a source representation drawn from a source
RS, the rules of structure transfer allow ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>284. Towards Cognitively-Faithful Decision-Making Models to Improve AI   Alignment</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Cyrus Cousins, Vijay Keswani, Vincent Conitzer et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04445v1" target="_blank">arXiv:2509.04445v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04445v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Recent AI work trends towards incorporating human-centric objectives, with
the explicit goal of aligning AI models to personal preferences and societal
values. Using standard preference elicitation methods, researchers and
practitioners build models of human decisions and judgments, which are then
used to align AI behavior with that of humans. However, models commonly used in
such elicitation processes often do not capture the true cognitive processes of
human decision making, such as when peopl...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>285. Echo State Networks as State-Space Models: A Systems Perspective</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Pradeep Singh, Balasubramanian Raman</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, 93C10, 68T07, 93C05, 93E11, 93B30, 93B05, 93B07, 62M10, I.2.6; I.5.1; I.6.5; I.6.4; G.3</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04422v1" target="_blank">arXiv:2509.04422v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04422v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Echo State Networks (ESNs) are typically presented as efficient,
readout-trained recurrent models, yet their dynamics and design are often
guided by heuristics rather than first principles. We recast ESNs explicitly as
state-space models (SSMs), providing a unified systems-theoretic account that
links reservoir computing with classical identification and modern kernelized
SSMs. First, we show that the echo-state property is an instance of
input-to-state stability for a contractive nonlinear SSM ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 27 pages, 1 figure</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>286. Interpretable Clustering with Adaptive Heterogeneous Causal Structure   Learning in Mixed Observational Data</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Wenrui Li, Qinghao Zhang, Xiaowo Wang</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04415v1" target="_blank">arXiv:2509.04415v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04415v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Understanding causal heterogeneity is essential for scientific discovery in
domains such as biology and medicine. However, existing methods lack causal
awareness, with insufficient modeling of heterogeneity, confounding, and
observational constraints, leading to poor interpretability and difficulty
distinguishing true causal heterogeneity from spurious associations. We propose
an unsupervised framework, HCL (Interpretable Causal Mechanism-Aware Clustering
with Adaptive Heterogeneous Causal Struc...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>287. SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety   Certificates</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Babak Esmaeili, Hamidreza Modares</span><br>
                    <span class="meta-item">ğŸ“ cs.MA, cs.SY, math.OC, eess.SY, cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04413v1" target="_blank">arXiv:2509.04413v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04413v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper proposes a fully data-driven motion-planning framework for
homogeneous linear multi-agent systems that operate in shared, obstacle-filled
workspaces without access to explicit system models. Each agent independently
learns its closed-loop behavior from experimental data by solving convex
semidefinite programs that generate locally invariant ellipsoids and
corresponding state-feedback gains. These ellipsoids, centered along grid-based
waypoints, certify the dynamic feasibility of short...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Submitted to IEEE Transactions on Automation Science and Engineering</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>288. Closed-Loop Neural Operator-Based Observer of Traffic Density</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Alice Harting, Karl Henrik Johansson, Matthieu Barreau</span><br>
                    <span class="meta-item">ğŸ“ math.OC, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.04873v2" target="_blank">arXiv:2504.04873v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.04873v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We consider the problem of traffic density estimation with sparse
measurements from stationary roadside sensors. Our approach uses Fourier neural
operators to learn macroscopic traffic flow dynamics from high-fidelity data.
During inference, the operator functions as an open-loop predictor of traffic
evolution. To close the loop, we couple the open-loop operator with a
correction operator that combines the predicted density with sparse
measurements from the sensors. Simulations with the SUMO sof...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>289. When three experiments are better than two: Avoiding intractable   correlated aleatoric uncertainty by leveraging a novel bias--variance   tradeoff</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Paul Scherer, Andreas Kirsch, Jake P. Taylor-King</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04363v1" target="_blank">arXiv:2509.04363v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04363v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Real-world experimental scenarios are characterized by the presence of
heteroskedastic aleatoric uncertainty, and this uncertainty can be correlated
in batched settings. The bias--variance tradeoff can be used to write the
expected mean squared error between a model distribution and a ground-truth
random variable as the sum of an epistemic uncertainty term, the bias squared,
and an aleatoric uncertainty term. We leverage this relationship to propose
novel active learning strategies that directly...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 16 pages, 5 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>290. The Strong, Weak and Benign Goodhart&#x27;s law. An independence-free and   paradigm-agnostic formalisation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Adrien Majka, El-Mahdi El-Mhamdi</span><br>
                    <span class="meta-item">ğŸ“ math.ST, stat.ML, cs.LG, stat.TH</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.23445v2" target="_blank">arXiv:2505.23445v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.23445v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Goodhart&#x27;s law is a famous adage in policy-making that states that ``When a
measure becomes a target, it ceases to be a good measure&#x27;&#x27;. As machine learning
models and the optimisation capacity to train them grow, growing empirical
evidence reinforced the belief in the validity of this law without however
being formalised. Recently, a few attempts were made to formalise Goodhart&#x27;s
law, either by categorising variants of it, or by looking at how optimising a
proxy metric affects the optimisation o...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 32 pages, 1 figure</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>291. Using causal abstractions to accelerate decision-making in complex   bandit problems</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Joel Dyer, Nicholas Bishop, Anisoara Calinescu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04296v1" target="_blank">arXiv:2509.04296v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04296v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Although real-world decision-making problems can often be encoded as causal
multi-armed bandits (CMABs) at different levels of abstraction, a general
methodology exploiting the information and computational advantages of each
abstraction level is missing. In this paper, we propose AT-UCB, an algorithm
which efficiently exploits shared information between CMAB problem instances
defined at different levels of abstraction. More specifically, AT-UCB leverages
causal abstraction (CA) theory to explor...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>292. A Primer on Causal and Statistical Dataset Biases for Fair and Robust   Image Analysis</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Charles Jones, Ben Glocker</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG, cs.CY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04295v1" target="_blank">arXiv:2509.04295v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04295v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Machine learning methods often fail when deployed in the real world. Worse
still, they fail in high-stakes situations and across socially sensitive lines.
These issues have a chilling effect on the adoption of machine learning methods
in settings such as medical diagnosis, where they are arguably best-placed to
provide benefits if safely deployed. In this primer, we introduce the causal
and statistical structures which induce failure in machine learning methods for
image analysis. We highlight t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Excerpt from C. Jones&#x27; PhD thesis. Winner of the G-Research PhD prize
  2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>293. Pulling Back the Curtain on ReLU Networks</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Maciej Satkiewicz</span><br>
                    <span class="meta-item">ğŸ“ I.2.6; I.4.10, cs.NE, cs.CV, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.22832v3" target="_blank">arXiv:2507.22832v3</a> | 
                    <a href="http://arxiv.org/pdf/2507.22832v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Since any ReLU network is piecewise affine, its hidden units can be
characterized by their pullbacks through the active subnetwork, i.e., by their
gradients (up to bias terms). However, gradients of deeper neurons are
notoriously misaligned, which obscures the network&#x27;s internal representations.
We posit that models do align gradients with data, yet this is concealed by the
intrinsic noise of the ReLU hard gating. We validate this intuition by applying
soft gating in the backward pass only, redu...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages, 3-page appendix, 4 figures, preprint; v3 changes: changed
  title, improved abstract, expanded introduction, added section on
  implications of the path stability</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>294. Mitigating Message Imbalance in Fraud Detection with Dual-View Graph   Representation Learning</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yudan Song, Yuecen Wei, Yuhang Lu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.SI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2507.06469v3" target="_blank">arXiv:2507.06469v3</a> | 
                    <a href="http://arxiv.org/pdf/2507.06469v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Graph representation learning has become a mainstream method for fraud
detection due to its strong expressive power, which focuses on enhancing node
representations through improved neighborhood knowledge capture. However, the
focus on local interactions leads to imbalanced transmission of global
topological information and increased risk of node-specific information being
overwhelmed during aggregation due to the imbalance between fraud and benign
nodes. In this paper, we first summarize the im...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>295. Single-seed generation of Brownian paths and integrals for adaptive and   high order SDE solvers</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ AndraÅ¾ JelinÄiÄ, James Foster, Patrick Kidger</span><br>
                    <span class="meta-item">ğŸ“ math.NA, cs.LG, cs.NA, math.PR, stat.CO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2405.06464v5" target="_blank">arXiv:2405.06464v5</a> | 
                    <a href="http://arxiv.org/pdf/2405.06464v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite the success of adaptive time-stepping in ODE simulation, it has so
far seen few applications for Stochastic Differential Equations (SDEs). To
simulate SDEs adaptively, methods such as the Virtual Brownian Tree (VBT) have
been developed, which can generate Brownian motion (BM) non-chronologically.
However, in most applications, knowing only the values of Brownian motion is
not enough to achieve a high order of convergence; for that, we must compute
time-integrals of BM such as $\int_s^t W...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>296. Reservoir kernels and Volterra series</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lukas Gonon, Lyudmila Grigoryeva, Juan-Pablo Ortega</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2212.14641v2" target="_blank">arXiv:2212.14641v2</a> | 
                    <a href="http://arxiv.org/pdf/2212.14641v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A universal kernel is constructed whose sections approximate any causal and
time-invariant filter in the fading memory category with inputs and outputs in
a finite-dimensional Euclidean space. This kernel is built using the reservoir
functional associated with a state-space representation of the Volterra series
expansion available for any analytic fading memory filter, and it is hence
called the Volterra reservoir kernel. Even though the state-space
representation and the corresponding reservoir...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 11 pages, 2 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>297. Revealing the empirical flexibility of gas units through deep clustering</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Chiara Fusar Bassini, Alice Lixuan Xu, Jorge SÃ¡nchez Canales et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CY, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.16943v2" target="_blank">arXiv:2504.16943v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.16943v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The flexibility of a power generation unit determines how quickly and often
it can ramp up or down. In energy models, it depends on assumptions on the
technical characteristics of the unit, such as its installed capacity or
turbine technology. In this paper, we learn the empirical flexibility of gas
units from their electricity generation, revealing how real-world limitations
can lead to substantial differences between units with similar technical
characteristics. Using a novel deep clustering a...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 19 pages, 4 figures, 3 tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>298. Why Can&#x27;t I See My Clusters? A Precision-Recall Approach to   Dimensionality Reduction Validation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Diede P. M. van der Hoorn, Alessio Arleo, Fernando V. Paulovich</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04222v1" target="_blank">arXiv:2509.04222v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04222v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Dimensionality Reduction (DR) is widely used for visualizing high-dimensional
data, often with the goal of revealing expected cluster structure. However,
such a structure may not always appear in the projections. Existing DR quality
metrics assess projection reliability (to some extent) or cluster structure
quality, but do not explain why expected structures are missing. Visual
Analytics solutions can help, but are often time-consuming due to the large
hyperparameter space. This paper addresses ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>299. Batched Stochastic Matching Bandits</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jung-hun Kim, Min-hwan Oh</span><br>
                    <span class="meta-item">ğŸ“ stat.ML, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04194v1" target="_blank">arXiv:2509.04194v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04194v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In this study, we introduce a novel bandit framework for stochastic matching
based on the Multi-nomial Logit (MNL) choice model. In our setting, $N$ agents
on one side are assigned to $K$ arms on the other side, where each arm
stochastically selects an agent from its assigned pool according to an unknown
preference and yields a corresponding reward. The objective is to minimize
regret by maximizing the cumulative revenue from successful matches across all
agents. This task requires solving a com...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>300. Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric   Similarity Learning of Motion Patterns</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Christian Merz, Lukas Schach, Marie Luisa Fiedler et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04174v1" target="_blank">arXiv:2509.04174v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04174v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper introduces an unobtrusive in-situ measurement method to detect
user behavior changes during arbitrary exposures in XR systems. Here, such
behavior changes are typically associated with the Proteus effect or bodily
affordances elicited by different avatars that the users embody in XR. We
present a biometric user model based on deep metric similarity learning, which
uses high-dimensional embeddings as reference vectors to identify behavior
changes of individual users. We evaluate our mo...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>301. Exposing Synthetic Speech: Model Attribution and Detection of   AI-generated Speech via Audio Fingerprints</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ MatÃ­as Pizarro, Mike Laszkiewicz, Shawkat Hesso et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.AS, cs.CR, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.14013v3" target="_blank">arXiv:2411.14013v3</a> | 
                    <a href="http://arxiv.org/pdf/2411.14013v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">As speech generation technologies continue to advance in quality and
accessibility, the risk of malicious use cases, including impersonation,
misinformation, and spoofing, increases rapidly. This work addresses this
threat by introducing a simple, training-free, yet effective approach for
detecting AI-generated speech and attributing it to its source model.
Specifically, we tackle three key tasks: (1) single-model attribution in an
open-world setting, where the goal is to determine whether a giv...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>302. Who Pays for Fairness? Rethinking Recourse under Social Burden</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ainhize Barrainkua, Giovanni De Toni, Jose Antonio Lozano et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.CY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04128v1" target="_blank">arXiv:2509.04128v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04128v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Machine learning based predictions are increasingly used in sensitive
decision-making applications that directly affect our lives. This has led to
extensive research into ensuring the fairness of classifiers. Beyond just fair
classification, emerging legislation now mandates that when a classifier
delivers a negative decision, it must also offer actionable steps an individual
can take to reverse that outcome. This concept is known as algorithmic
recourse. Nevertheless, many researchers have expr...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>303. Synthetic Counterfactual Labels for Efficient Conformal Counterfactual   Inference</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Amirmohammad Farzaneh, Matteo Zecchin, Osvaldo Simeone</span><br>
                    <span class="meta-item">ğŸ“ cs.LG, cs.IT, math.IT</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04112v1" target="_blank">arXiv:2509.04112v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04112v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This work addresses the problem of constructing reliable prediction intervals
for individual counterfactual outcomes. Existing conformal counterfactual
inference (CCI) methods provide marginal coverage guarantees but often produce
overly conservative intervals, particularly under treatment imbalance when
counterfactual samples are scarce. We introduce synthetic data-powered CCI
(SP-CCI), a new framework that augments the calibration set with synthetic
counterfactual labels generated by a pre-tra...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>304. Gromov-Wasserstein and optimal transport: from assignment problems to   probabilistic numeric</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Iman Seyedi, Antonio Candelieri, Enza Messina et al.</span><br>
                    <span class="meta-item">ğŸ“ math.OC, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04089v1" target="_blank">arXiv:2509.04089v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04089v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The assignment problem, a cornerstone of operations research, seeks an
optimal one-to-one mapping between agents and tasks to minimize total cost.
This work traces its evolution from classical formulations and algorithms to
modern optimal transport (OT) theory, positioning the Quadratic Assignment
Problem (QAP) and related structural matching tasks within this framework. We
connect the linear assignment problem to Monge&#x27;s transport problem,
Kantorovich&#x27;s relaxation, and Wasserstein distances, th...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>305. One Small Step with Fingerprints, One Giant Leap for De Novo Molecule   Generation from Mass Spectra</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Neng Kai Nigel Neo, Lim Jing, Ngoui Yong Zhau Preston et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.04180v3" target="_blank">arXiv:2508.04180v3</a> | 
                    <a href="http://arxiv.org/pdf/2508.04180v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">A common approach to the de novo molecular generation problem from mass
spectra involves a two-stage pipeline: (1) encoding mass spectra into molecular
fingerprints, followed by (2) decoding these fingerprints into molecular
structures. In our work, we adopt MIST as the encoder and MolForge as the
decoder, leveraging additional training data to enhance performance. We also
threshold the probabilities of each fingerprint bit to focus on the presence of
substructures. This results in a tenfold imp...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>306. The Telephone Game: Evaluating Semantic Drift in Unified Models</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sabbir Mollah, Rohit Gupta, Sirnam Swetha et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04438v1" target="_blank">arXiv:2509.04438v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04438v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and G...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>307. From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray   Collimators via Hough Transform</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Benjamin El-Zein, Dominik Eckert, Andreas Fieselmann et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, physics.med-ph</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04437v1" target="_blank">arXiv:2509.04437v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04437v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrai...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>308. Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images   with Depth and Normal Supervision</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Tianle Liu, Shuangming Zhao, Wanshou Jiang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.08352v2" target="_blank">arXiv:2502.08352v2</a> | 
                    <a href="http://arxiv.org/pdf/2502.08352v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With advancements in satellite imaging technology, acquiring high-resolution
multi-view satellite imagery has become increasingly accessible, enabling rapid
and location-independent ground model reconstruction. However, traditional
stereo matching methods struggle to capture fine details, and while neural
radiance fields (NeRFs) achieve high-quality reconstructions, their training
time is prohibitively long. Moreover, challenges such as low visibility of
building facades, illumination and style ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>309. FADE: A Dataset for Detecting Falling Objects around Buildings in Video</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zhigang Tu, Zitao Gao, Zhengbo Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2408.05750v2" target="_blank">arXiv:2408.05750v2</a> | 
                    <a href="http://arxiv.org/pdf/2408.05750v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Falling objects from buildings can cause severe injuries to pedestrians due
to the great impact force they exert. Although surveillance cameras are
installed around some buildings, it is challenging for humans to capture such
events in surveillance videos due to the small size and fast motion of falling
objects, as well as the complex background. Therefore, it is necessary to
develop methods to automatically detect falling objects around buildings in
surveillance videos. To facilitate the invest...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted by IEEE Transactions on Information Forensics and Security
  (TIFS), 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>310. Global-to-Local or Local-to-Global? Enhancing Image Retrieval with   Efficient Local Search and Effective Global Re-ranking</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Dror Aiger, Bingyi Cao, Kaifeng Chen et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04351v1" target="_blank">arXiv:2509.04351v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04351v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The dominant paradigm in image retrieval systems today is to search large
databases using global image features, and re-rank those initial results with
local image feature matching techniques. This design, dubbed global-to-local,
stems from the computational cost of local matching approaches, which can only
be afforded for a small number of retrieved images. However, emerging efficient
local feature search approaches have opened up new possibilities, in particular
enabling detailed retrieval at ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>311. GeoArena: An Open Platform for Benchmarking Large Vision-language Models   on WorldWide Image Geolocalization</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Pengyue Jia, Yingyi Zhang, Xiangyu Zhao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04334v1" target="_blank">arXiv:2509.04334v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04334v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Image geolocalization aims to predict the geographic location of images
captured anywhere on Earth, but its global nature presents significant
challenges. Current evaluation methodologies suffer from two major limitations.
First, data leakage: advanced approaches often rely on large vision-language
models (LVLMs) to predict image locations, yet these models are frequently
pretrained on the test datasets, compromising the accuracy of evaluating a
model&#x27;s actual geolocalization capability. Second,...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>312. Noisy Label Refinement with Semantically Reliable Synthetic Images</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yingxuan Li, Jiafeng Mao, Yusuke Matsui</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04298v1" target="_blank">arXiv:2509.04298v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04298v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Semantic noise in image classification datasets, where visually similar
categories are frequently mislabeled, poses a significant challenge to
conventional supervised learning approaches. In this paper, we explore the
potential of using synthetic images generated by advanced text-to-image models
to address this issue. Although these high-quality synthetic images come with
reliable labels, their direct application in training is limited by domain gaps
and diversity constraints. Unlike conventiona...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to ICIP2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>313. PAOLI: Pose-free Articulated Object Learning from Sparse-view Images</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Jianning Deng, Kartic Subr, Hakan Bilen</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04276v1" target="_blank">arXiv:2509.04276v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04276v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We present a novel self-supervised framework for learning articulated object
representations from sparse-view, unposed images. Unlike prior methods that
require dense multi-view observations and ground-truth camera poses, our
approach operates with as few as four views per articulation and no camera
supervision. To address the inherent challenges, we first reconstruct each
articulation independently using recent advances in sparse-view 3D
reconstruction, then learn a deformation field that estab...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>314. Dual-Scale Volume Priors with Wasserstein-Based Consistency for   Semi-Supervised Medical Image Segmentation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Junying Meng, Gangxuan Zhou, Jun Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04273v1" target="_blank">arXiv:2509.04273v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04273v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Despite signi cant progress in semi-supervised medical image segmentation,
most existing segmentation networks overlook e ective methodological guidance
for feature extraction and important prior information from
  datasets. In this paper, we develop a semi-supervised medical image
segmentation framework that e ectively integrates spatial regularization
methods and volume priors. Speci cally, our approach integrates a strong
explicit volume prior at the image scale and Threshold Dynamics spatial...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>315. Revisiting Simple Baselines for In-The-Wild Deepfake Detection</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Orlando Castaneda, Kevin So-Tang, Kshitij Gurung</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04150v1" target="_blank">arXiv:2509.04150v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04150v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The widespread adoption of synthetic media demands accessible deepfake
detectors and realistic benchmarks. While most existing research evaluates
deepfake detectors on highly controlled datasets, we focus on the recently
released &quot;in-the-wild&quot; benchmark, Deepfake-Eval-2024. Initial reporting on
Deepfake-Eval-2024 showed that three finetuned open-source models achieve
accuracies between 61% and 69%, significantly lagging behind the leading
commercial deepfake detector with 82% accuracy. Our work ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>316. Replication Study and Benchmarking of Real-Time Object Detection Models</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Pierre-Luc Asselin, Vincent Coulombe, William Guimont-Martin et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2405.06911v2" target="_blank">arXiv:2405.06911v2</a> | 
                    <a href="http://arxiv.org/pdf/2405.06911v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This work examines the reproducibility and benchmarking of state-of-the-art
real-time object detection models. As object detection models are often used in
real-world contexts, such as robotics, where inference time is paramount,
simply measuring models&#x27; accuracy is not enough to compare them. We thus
compare a large variety of object detection models&#x27; accuracy and inference
speed on multiple graphics cards. In addition to this large benchmarking
attempt, we also reproduce the following models f...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Authors are presented in alphabetical order, each having equal
  contribution to the work</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>317. TriLiteNet: Lightweight Model for Multi-Task Visual Perception</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Quang-Huy Che, Duc-Khai Lam</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04092v1" target="_blank">arXiv:2509.04092v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04092v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Efficient perception models are essential for Advanced Driver Assistance
Systems (ADAS), as these applications require rapid processing and response to
ensure safety and effectiveness in real-world environments. To address the
real-time execution needs of such perception models, this study introduces the
TriLiteNet model. This model can simultaneously manage multiple tasks related
to panoramic driving perception. TriLiteNet is designed to optimize performance
while maintaining low computational ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>318. SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid   Registration</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuxin Yao, Bailin Deng, Junhui Hou et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.GR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2405.20188v2" target="_blank">arXiv:2405.20188v2</a> | 
                    <a href="http://arxiv.org/pdf/2405.20188v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Existing optimization-based methods for non-rigid registration typically
minimize an alignment error metric based on the point-to-point or
point-to-plane distance between corresponding point pairs on the source surface
and target surface. However, these metrics can result in slow convergence or a
loss of detail. In this paper, we propose SPARE, a novel formulation that
utilizes a symmetrized point-to-plane distance for robust non-rigid
registration. The symmetrized point-to-plane distance relies...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>319. Millisecond-Response Tracking and Gazing System for UAVs: A Domestic   Solution Based on &quot;Phytium + Cambricon&quot;</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yuchen Zhu, Longxiang Yin, Kai Zhao</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04043v1" target="_blank">arXiv:2509.04043v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04043v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In the frontier research and application of current video surveillance
technology, traditional camera systems exhibit significant limitations of
response delay exceeding 200 ms in dynamic scenarios due to the insufficient
deep feature extraction capability of automatic recognition algorithms and the
efficiency bottleneck of computing architectures, failing to meet the real-time
requirements in complex scenes. To address this issue, this study proposes a
heterogeneous computing architecture based...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 16 pages,17 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>320. HLG: Comprehensive 3D Room Construction via Hierarchical Layout   Generation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Xiping Wang, Yuxi Wang, Mengqi Zhou et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.17832v2" target="_blank">arXiv:2508.17832v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.17832v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Realistic 3D indoor scene generation is crucial for virtual reality, interior
design, embodied intelligence, and scene understanding. While existing methods
have made progress in coarse-scale furniture arrangement, they struggle to
capture fine-grained object placements, limiting the realism and utility of
generated environments. This gap hinders immersive virtual experiences and
detailed scene comprehension for embodied AI applications. To address these
issues, we propose Hierarchical Layout Ge...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>321. Learning from Majority Label: A Novel Problem in Multi-class   Multiple-Instance Learning</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shiku Kaito, Shinnosuke Matsuo, Daiki Suehiro et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04023v1" target="_blank">arXiv:2509.04023v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04023v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The paper proposes a novel multi-class Multiple-Instance Learning (MIL)
problem called Learning from Majority Label (LML). In LML, the majority class
of instances in a bag is assigned as the bag-level label. The goal of LML is to
train a classification model that estimates the class of each instance using
the majority label. This problem is valuable in a variety of applications,
including pathology image segmentation, political voting prediction, customer
sentiment analysis, and environmental mo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 35 pages, 9 figures, Accepted in Pattern recognition</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>322. Vision-based Manipulation from Single Human Video with Open-World Object   Graphs</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yifeng Zhu, Arisrei Lim, Peter Stone et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.RO, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2405.20321v2" target="_blank">arXiv:2405.20321v2</a> | 
                    <a href="http://arxiv.org/pdf/2405.20321v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This work presents an object-centric approach to learning vision-based
manipulation skills from human videos. We investigate the problem of robot
manipulation via imitation in the open-world setting, where a robot learns to
manipulate novel objects from a single video demonstration. We introduce ORION,
an algorithm that tackles the problem by extracting an object-centric
manipulation plan from a single RGB or RGB-D video and deriving a policy that
conditions on the extracted plan. Our method ena...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Extended version of paper adding results with RGB-only demonstration
  videos uploaded on 09/04/2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>323. Improving Vessel Segmentation with Multi-Task Learning and Auxiliary   Data Available Only During Model Training</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Daniel Sobotka, Alexander Herold, Matthias Perkonigg et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03975v1" target="_blank">arXiv:2509.03975v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03975v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Liver vessel segmentation in magnetic resonance imaging data is important for
the computational analysis of vascular remodelling, associated with a wide
spectrum of diffuse liver diseases. Existing approaches rely on contrast
enhanced imaging data, but the necessary dedicated imaging sequences are not
uniformly acquired. Images without contrast enhancement are acquired more
frequently, but vessel segmentation is challenging, and requires large-scale
annotated data. We propose a multi-task learni...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>324. Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer   Learning in a U-Net Architecture</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Alvaro Aranibar Roque, Helga Sebastian</span><br>
                    <span class="meta-item">ğŸ“ cs.CV, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03950v1" target="_blank">arXiv:2509.03950v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03950v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Pneumothorax, the abnormal accumulation of air in the pleural space, can be
life-threatening if undetected. Chest X-rays are the first-line diagnostic
tool, but small cases may be subtle. We propose an automated deep-learning
pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax
regions. Trained on the SIIM-ACR dataset with data augmentation and a combined
binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and
Dice score of 0.8241 on the independent...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 10 page, 5 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>325. TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained   Tubular Shapes</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Minghui Zhang, Yaoyu Liu, Junyang Wu et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03938v1" target="_blank">arXiv:2509.03938v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03938v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Medical tubular anatomical structures are inherently three-dimensional
conduits with lumens, enclosing walls, and complex branching topologies.
Accurate reconstruction of their geometry and topology is crucial for
applications such as bronchoscopic navigation and cerebral arterial
connectivity assessment. Existing methods often rely on voxel-wise overlap
measures, which fail to capture topological correctness and completeness.
Although topology-aware losses and persistent homology constraints ha...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>326. A Framework for Supervised and Unsupervised Segmentation and   Classification of Materials Microstructure Images</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Kungang Zhang, Wei Chen, Wing K. Liu et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.AP, stat.ML, cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2502.07107v2" target="_blank">arXiv:2502.07107v2</a> | 
                    <a href="http://arxiv.org/pdf/2502.07107v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Microstructure of materials is often characterized through image analysis to
understand processing-structure-properties linkages. We propose a largely
automated framework that integrates unsupervised and supervised learning
methods to classify micrographs according to microstructure phase/class and,
for multiphase microstructures, segments them into different homogeneous
regions. With the advance of manufacturing and imaging techniques, the
ultra-high resolution of imaging that reveals the compl...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>327. Weakly-Supervised Learning of Dense Functional Correspondences</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Stefan Stojanov, Linan Zhao, Yunzhi Zhang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CV</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03893v1" target="_blank">arXiv:2509.03893v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03893v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Establishing dense correspondences across image pairs is essential for tasks
such as shape reconstruction and robot manipulation. In the challenging setting
of matching across different categories, the function of an object, i.e., the
effect that an object can cause on other objects, can guide how correspondences
should be established. This is because object parts that enable specific
functions often share similarities in shape and appearance. We derive the
definition of dense functional corresp...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at ICCV 2025. Project website:
  https://dense-functional-correspondence.github.io/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>328. Can Language Models Handle a Non-Gregorian Calendar?</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Mutsumi Sasaki, Go Kamoda, Ryosuke Takahashi et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04432v1" target="_blank">arXiv:2509.04432v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04432v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>329. That is Unacceptable: the Moral Foundations of Canceling</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Soda Marem Lo, Oscar Araque, Rajesh Sharma et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CY, cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.05720v3" target="_blank">arXiv:2503.05720v3</a> | 
                    <a href="http://arxiv.org/pdf/2503.05720v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Canceling is a morally-driven phenomenon that hinders the development of safe
social media platforms and contributes to ideological polarization. To address
this issue we present the Canceling Attitudes Detection (CADE) dataset, an
annotated corpus of canceling incidents aimed at exploring the factors of
disagreements in evaluating people canceling attitudes on social media.
Specifically, we study the impact of annotators&#x27; morality in their perception
of canceling, showing that morality is an in...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>330. MyProfessors: Mining Turkish Student Reviews</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.50)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ibrahim Faruk Ceylan, Necmettin Bera Calik</span><br>
                    <span class="meta-item">ğŸ“ cs.CL</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2109.02325v5" target="_blank">arXiv:2109.02325v5</a> | 
                    <a href="http://arxiv.org/pdf/2109.02325v5" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce Hocalarim (MyProfessors), the largest student review dataset
available for the Turkish language. It consists of over 5000 professor reviews
left online by students, with different aspects of education rated on a scale
of 1 to 5 stars. We investigate the properties of the dataset and present its
statistics. We examine the impact of students&#x27; institution type on their
ratings and the correlation of students&#x27; bias to give positive or negative
feedback.</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The paper is withdrawn due to the scraping errors in the dataset
  collection process and affected results</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>331. We Have It Covered: A Resampling-based Method for Uplift Model   Comparison</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yang Liu, Chaoyu Yuan</span><br>
                    <span class="meta-item">ğŸ“ stat.ME, stat.ML</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04315v1" target="_blank">arXiv:2509.04315v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04315v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Uplift models play a critical role in modern marketing applications to help
understand the incremental benefits of interventions and identify optimal
targeting strategies. A variety of techniques exist for building uplift models,
and it is essential to understand the model differences in the context of
intended applications. The uplift curve is a widely adopted tool for assessing
uplift model performance on the selection universe when observations are
available for the entire population. However...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>332. Sharp Convergence Rates of Empirical Unbalanced Optimal Transport for   Spatio-Temporal Point Processes</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Marina Struleva, Shayan Hundrieser, Dominic Schuhmacher et al.</span><br>
                    <span class="meta-item">ğŸ“ math.ST, stat.ML, stat.TH, primary 62G05, 62G07, 62R20, secondary: 60D05, 60G60</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04225v1" target="_blank">arXiv:2509.04225v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04225v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We statistically analyze empirical plug-in estimators for unbalanced optimal
transport (UOT) formalisms, focusing on the Kantorovich-Rubinstein distance,
between general intensity measures based on observations from spatio-temporal
point processes. Specifically, we model the observations by two weakly
time-stationary point processes with spatial intensity measures $\mu$ and $\nu$
over the expanding window $(0,t]$ as $t$ increases to infinity, and establish
sharp convergence rates of the empirica...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: The first two authors contributed equally, 76 pages, 7 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>333. FastPart: Over-Parameterized Stochastic Gradient Descent for Sparse   optimisation on Measures</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Yohann De Castro, SÃ©bastien Gadat, ClÃ©ment Marteau</span><br>
                    <span class="meta-item">ğŸ“ math.OC, stat.ML</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2312.05993v2" target="_blank">arXiv:2312.05993v2</a> | 
                    <a href="http://arxiv.org/pdf/2312.05993v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents a novel algorithm that leverages Stochastic Gradient
Descent strategies in conjunction with Random Features to augment the
scalability of Conic Particle Gradient Descent (CPGD) specifically tailored for
solving sparse optimization problems on measures. By formulating the CPGD steps
within a variational framework, we provide rigorous mathematical proofs
demonstrating the following key findings: $\mathrm{(i)}$ The total variation
norms of the solution measures along the descent...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 45 pages, 4 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>334. Prob-GParareal: A Probabilistic Numerical Parallel-in-Time Solver for   Differential Equations</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Guglielmo Gattiglio, Lyudmila Grigoryeva, Massimiliano Tamborrino</span><br>
                    <span class="meta-item">ğŸ“ stat.CO, cs.DC, cs.NA, math.NA, stat.ML, 65M55, 65M22, 65L05, 50G15, 65Y05</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03945v1" target="_blank">arXiv:2509.03945v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03945v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">We introduce Prob-GParareal, a probabilistic extension of the GParareal
algorithm designed to provide uncertainty quantification for the
Parallel-in-Time (PinT) solution of (ordinary and partial) differential
equations (ODEs, PDEs). The method employs Gaussian processes (GPs) to model
the Parareal correction function, as GParareal does, further enabling the
propagation of numerical uncertainty across time and yielding probabilistic
forecasts of system&#x27;s evolution. Furthermore, Prob-GParareal acc...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>335. EMMA: Scaling Mobile Manipulation via Egocentric Human Data</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Lawrence Y. Zhu, Pranav Kuppili, Ryan Punamiya et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04443v1" target="_blank">arXiv:2509.04443v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04443v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines t...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>336. Taming High-Dimensional Dynamics: Learning Optimal Projections onto   Spectral Submanifolds</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hugo Buurmeijer, Luis A. Pabon, John Irvin Alora et al.</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.RO, cs.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.03157v2" target="_blank">arXiv:2504.03157v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.03157v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">High-dimensional nonlinear systems pose considerable challenges for modeling
and control across many domains, from fluid mechanics to advanced robotics.
Such systems are typically approximated with reduced-order models, which often
rely on orthogonal projections, a simplification that may lead to large
prediction errors. In this work, we derive optimality of fiber-aligned
projections onto spectral submanifolds, preserving the nonlinear geometric
structure and minimizing long-term prediction erro...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>337. Leveraging Equivariances and Symmetries in the Control Barrier Function   Synthesis</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Adrian Wiltz, Dimos V. Dimarogonas</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.RO, cs.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04399v1" target="_blank">arXiv:2509.04399v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04399v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The synthesis of Control Barrier Functions (CBFs) often involves demanding
computations or a meticulous construction. However, structural properties of
the system dynamics and constraints have the potential to mitigate these
challenges. In this paper, we explore how equivariances in the dynamics,
loosely speaking a form of symmetry, can be leveraged in the CBF synthesis.
Although CBFs are generally not inherently symmetric, we show how equivariances
in the dynamics and symmetries in the constrai...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 15 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>338. Robotic Manipulation via Imitation Learning: Taxonomy, Evolution,   Benchmark, and Challenges</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zezeng Li, Alexandre Chapin, Enda Xiang et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2508.17449v2" target="_blank">arXiv:2508.17449v2</a> | 
                    <a href="http://arxiv.org/pdf/2508.17449v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Robotic Manipulation (RM) is central to the advancement of autonomous robots,
enabling them to interact with and manipulate objects in real-world
environments. This survey focuses on RM methodologies that leverage imitation
learning, a powerful technique that allows robots to learn complex manipulation
skills by mimicking human demonstrations. We identify and analyze the most
influential studies in this domain, selected based on community impact and
intrinsic quality. For each paper, we provide ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>339. Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the   Roles of Information Transparency, User Control, and Proactivity</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Atikkhan Faridkhan Nilgar, Manuel Dietrich, Kristof Van Laerhoven</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04358v1" target="_blank">arXiv:2509.04358v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04358v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Social robots are increasingly recognized as valuable supporters in the field
of well-being coaching. They can function as independent coaches or provide
support alongside human coaches, and healthcare professionals. In coaching
interactions, these robots often handle sensitive information shared by users,
making privacy a relevant issue. Despite this, little is known about the
factors that shape users&#x27; privacy perceptions. This research aims to examine
three key factors systematically: (1) the ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>340. Compatibility of Multiple Control Barrier Functions for Constrained   Nonlinear Systems</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Max H. Cohen, Eugene Lavretsky, Aaron D. Ames</span><br>
                    <span class="meta-item">ğŸ“ eess.SY, cs.RO, cs.SY, math.OC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04220v1" target="_blank">arXiv:2509.04220v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04220v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Control barrier functions (CBFs) are a powerful tool for the constrained
control of nonlinear systems; however, the majority of results in the
literature focus on systems subject to a single CBF constraint, making it
challenging to synthesize provably safe controllers that handle multiple state
constraints. This paper presents a framework for constrained control of
nonlinear systems subject to box constraints on the systems&#x27; vector-valued
outputs using multiple CBFs. Our results illustrate that ...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: To appear at IEEE CDC 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>341. Lightweight Kinematic and Static Modeling of Cable-Driven Continuum   Robots via Actuation-Space Energy Formulation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ke Wu, Yuhao Wang, Kevin Henry et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04119v1" target="_blank">arXiv:2509.04119v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04119v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Continuum robots, inspired by octopus arms and elephant trunks, combine
dexterity with intrinsic compliance, making them well suited for unstructured
and confined environments. Yet their continuously deformable morphology poses
challenges for motion planning and control, calling for accurate but
lightweight models. We propose the Lightweight Actuation Space Energy Modeling
(LASEM) framework for cable driven continuum robots, which formulates actuation
potential energy directly in actuation space...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Journal</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>342. Cloud-Assisted Remote Control for Aerial Robots: From Theory to   Proof-of-Concept Implementation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Achilleas Santi Seisa, Viswa Narayanan Sankaranarayanan, Gerasimos Damigos et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.DC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04095v1" target="_blank">arXiv:2509.04095v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04095v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework con...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 6 pages, 7 figures, CCGridW 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>343. Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Fatih Dursun, Bruno Vilhena Adorno, Simon Watson et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04094v1" target="_blank">arXiv:2509.04094v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04094v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Object reconstruction and inspection tasks play a crucial role in various
robotics applications. Identifying paths that reveal the most unknown areas of
the object becomes paramount in this context, as it directly affects
efficiency, and this problem is known as the view path planning problem.
Current methods often use sampling-based path planning techniques, evaluating
potential views along the path to enhance reconstruction performance. However,
these methods are computationally expensive as t...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 14 pages, 13 figures, 3 tables. Under Review for the IEEE
  Transactions on Robotics (T-RO)</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>344. Segmented Trajectory Optimization for Autonomous Parking in Unstructured   Environments</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Hang Yu, Renjie Li</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2504.05041v2" target="_blank">arXiv:2504.05041v2</a> | 
                    <a href="http://arxiv.org/pdf/2504.05041v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents a Segmented Trajectory Optimization (STO) method for
autonomous parking, which refines an initial trajectory into a dynamically
feasible and collision-free one using an iterative SQP-based approach. STO
maintains the maneuver strategy of the high-level global planner while allowing
curvature discontinuities at switching points to improve maneuver efficiency.
To ensure safety, a convex corridor is constructed via GJK-accelerated ellipse
shrinking and expansion, serving as safe...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 8 pages, 6 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>345. Integrated Wheel Sensor Communication using ESP32 -- A Contribution   towards a Digital Twin of the Road System</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ventseslav Yordanov, Simon SchÃ¤fer, Alexander Mann et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04061v1" target="_blank">arXiv:2509.04061v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04061v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">While current onboard state estimation methods are adequate for most driving
and safety-related applications, they do not provide insights into the
interaction between tires and road surfaces. This paper explores a novel
communication concept for efficiently transmitting integrated wheel sensor data
from an ESP32 microcontroller. Our proposed approach utilizes a
publish-subscribe system, surpassing comparable solutions in the literature
regarding data transmission volume. We tested this approach...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 6 pages, 2 figures, this work was submitted to and accepted by IEEE
  International Conference on Intelligent Transportation Systems (ITSC) 2025</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>346. A Digital Twin for Robotic Post Mortem Tissue Sampling using Virtual   Reality</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Maximilian Neidhardt, Ludwig Bosse, Vidas Raudonis et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.02760v2" target="_blank">arXiv:2509.02760v2</a> | 
                    <a href="http://arxiv.org/pdf/2509.02760v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Studying tissue samples obtained during autopsies is the gold standard when
diagnosing the cause of death and for understanding disease pathophysiology.
Recently, the interest in post mortem minimally invasive biopsies has grown
which is a less destructive approach in comparison to an open autopsy and
reduces the risk of infection. While manual biopsies under ultrasound guidance
are more widely performed, robotic post mortem biopsies have been recently
proposed. This approach can further reduce ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>347. Reactive In-Air Clothing Manipulation with Confidence-Aware Dense   Correspondence and Visuotactile Affordance</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Neha Sunil, Megha Tippur, Arnau Saumell et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.AI, cs.LG</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03889v1" target="_blank">arXiv:2509.03889v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03889v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributio...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Accepted at CoRL 2025. Project website:
  https://mhtippur.github.io/inairclothmanipulation/</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>348. Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Haichao Zhang, Haonan Yu, Le Zhao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03859v1" target="_blank">arXiv:2509.03859v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03859v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Quadruped-based mobile manipulation presents significant challenges in
robotics due to the diversity of required skills, the extended task horizon,
and partial observability. After presenting a multi-stage pick-and-place task
as a succinct yet sufficiently rich setup that captures key desiderata for
quadruped-based mobile manipulation, we propose an approach that can train a
visuo-motor policy entirely in simulation, and achieve nearly 80\% success in
the real world. The policy efficiently perfo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: Project: https://horizonrobotics.github.io/gail/SLIM</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>349. GMT: General Motion Tracking for Humanoid Whole-Body Control</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Zixuan Chen, Mazeyu Ji, Xuxin Cheng et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2506.14770v2" target="_blank">arXiv:2506.14770v2</a> | 
                    <a href="http://arxiv.org/pdf/2506.14770v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The ability to track general whole-body motions in the real world is a useful
way to build general-purpose humanoid robots. However, achieving this can be
challenging due to the temporal and kinematic diversity of the motions, the
policy&#x27;s capability, and the difficulty of coordination of the upper and lower
bodies. To address these issues, we propose GMT, a general and scalable
motion-tracking framework that trains a single unified policy to enable
humanoid robots to track diverse motions in th...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>350. Robust Offline Imitation Learning Through State-level Trajectory   Stitching</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Shuze Wang, Yunpeng Mei, Hongjie Cao et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.AI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2503.22524v2" target="_blank">arXiv:2503.22524v2</a> | 
                    <a href="http://arxiv.org/pdf/2503.22524v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Imitation learning (IL) has proven effective for enabling robots to acquire
visuomotor skills through expert demonstrations. However, traditional IL
methods are limited by their reliance on high-quality, often scarce, expert
data, and suffer from covariate shift. To address these challenges, recent
advances in offline IL have incorporated suboptimal, unlabeled datasets into
the training. In this paper, we propose a novel approach to enhance policy
learning from mixed-quality offline datasets by ...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>351. Real-Time Buoyancy Estimation for AUV Simulations Using Convex   Hull-Based Submerged Volume Calculation</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ad-Deen Mahbub, Md Ragib Shaharear</span><br>
                    <span class="meta-item">ğŸ“ cs.RO, cs.SY, eess.SY</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03804v1" target="_blank">arXiv:2509.03804v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03804v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Accurate real-time buoyancy modeling is essential for high-fidelity
Autonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a
native buoyancy system, requiring external solutions for precise underwater
physics. This paper presents a novel convex hull-based approach to dynamically
compute the submerged volume of an AUV in real time. By extracting mesh
geometry from the simulation environment and calculating the hull portion
intersecting the water level along the z-axis, our me...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 7 pages, 10 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>352. Fuzzy to Clear: Elucidating the Threat Hunter Cognitive Process and   Cognitive Support Needs</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Alessandra Maciel Paz Milani, Arty Starr, Samantha Hill et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.CR, cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2408.04348v3" target="_blank">arXiv:2408.04348v3</a> | 
                    <a href="http://arxiv.org/pdf/2408.04348v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">With security threats increasing in frequency and severity, it is critical
that we consider the important role of threat hunters. These highly-trained
security professionals learn to see, identify, and intercept security threats.
Many recent works and existing tools in cybersecurity are focused on automating
the threat hunting process, often overlooking the critical human element. Our
study shifts this paradigm by emphasizing a human-centered approach to
understanding the lived experiences of th...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 22 Pages; 5 Figures; 8 Tables</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>353. Human causal perception in a cube-stacking task</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Nikolai Bahr, Christoph Zetzsche</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2505.05923v2" target="_blank">arXiv:2505.05923v2</a> | 
                    <a href="http://arxiv.org/pdf/2505.05923v2" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">In intuitive physics the process of stacking cubes has become a paradigmatic,
canonical task. Even though it gets employed in various shades and
complexities, the very fundamental setting with two cubes has not been
thoroughly investigated. Furthermore, the majority of settings feature only a
reduced, one dimensional (1D) decision space. In this paper an experiment is
conducted in which participants judge the stability of two cubes stacked on top
of each other. It is performed in the full 3D set...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 7 pages, 6 figures</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>354. &quot;Low Frequency Tweeters Have More to Say!&quot; A New Approach to Identify   Importance of Tweets</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Gautam Khannaa, Yeliz Yesilada, Sukru Eraslan et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.HC, cs.SI</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03931v1" target="_blank">arXiv:2509.03931v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03931v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">Twitter is one of the most popular social media platforms.With a large number
of tweets, the activity feed of users becomes noisy, challenging to read, and
most importantly tweets often get lost. We present a new approach to
personalise the ranking of the tweets toward solving the problem of information
overload which is achieved by analysing the relationship between the importance
of tweets to the frequency at which the author tweets. The hypothesis tested is
that &quot;low-frequency tweeters have m...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: 12 pages</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>355. Map as a By-product: Collective Landmark Mapping from IMU Data and   User-provided Texts in Situated Tasks</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Ryo Yonetani, Kotaro Hara</span><br>
                    <span class="meta-item">ğŸ“ cs.HC</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.03792v1" target="_blank">arXiv:2509.03792v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.03792v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">This paper presents Collective Landmark Mapper, a novel map-as-a-by-product
system for generating semantic landmark maps of indoor environments. Consider
users engaged in situated tasks that require them to navigate these
environments and regularly take notes on their smartphones. Collective Landmark
Mapper exploits the smartphone&#x27;s IMU data and the user&#x27;s free text input during
these tasks to identify a set of landmarks encountered by the user. The
identified landmarks are then aggregated acros...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: (c) 2025 Copyright held by the owner/author(s). Publication rights
  licensed to ACM. This is the author&#x27;s version of the work. It is posted here
  for your personal use. Not for redistribution. The definitive Version of
  Record was published in Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
  9, 3, Article 146 (September 2025), https://doi.org/10.1145/3749455</p>
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>356. Safeguarding Patient Trust in the Age of AI: Tackling Health   Misinformation with Explainable AI</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Sueun Hong, Shuojie Fu, Ovidiu Serban et al.</span><br>
                    <span class="meta-item">ğŸ“ cs.IR</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2509.04052v1" target="_blank">arXiv:2509.04052v1</a> | 
                    <a href="http://arxiv.org/pdf/2509.04052v1" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">AI-generated health misinformation poses unprecedented threats to patient
safety and healthcare system trust globally. This white paper presents an
explainable AI framework developed through the EPSRC INDICATE project to combat
medical misinformation while enhancing evidence-based healthcare delivery. Our
systematic review of 17 studies reveals the urgent need for transparent AI
systems in healthcare. The proposed solution demonstrates 95% recall in
clinical evidence retrieval and integrates nov...</p>
                
            </div>

            <div class="paper-entry" style="margin-bottom: 2rem; padding: 1.5rem; background: #fafafa; border-radius: 8px; border: 1px solid #e5e5e5;">
                <h3>357. dsld: A Socially Relevant Tool for Teaching Statistics</h3>
                <div class="priority-badge priority-low" style="display: inline-block; margin: 0.5rem 0;">
                    Low Relevance (Score: 0.00)
                </div>
                <div class="paper-meta" style="margin: 1rem 0;">
                    <span class="meta-item">ğŸ‘¥ Aditya Mittal, Taha Abdullah, Arjun Ashok et al.</span><br>
                    <span class="meta-item">ğŸ“ stat.ME, cs.IR, cs.LG, stat.AP</span><br>
                    <span class="meta-item">ğŸ”— <a href="http://arxiv.org/abs/2411.04228v3" target="_blank">arXiv:2411.04228v3</a> | 
                    <a href="http://arxiv.org/pdf/2411.04228v3" target="_blank">PDF</a></span>
                </div>
                <p style="color: #666; line-height: 1.6;">The growing influence of data science in statistics education requires tools
that make key concepts accessible through real-world applications. We introduce
&quot;Data Science Looks At Discrimination&quot; (dsld), an R package that provides a
comprehensive set of analytical and graphical methods for examining issues of
discrimination involving attributes such as race, gender, and age. By
positioning fairness analysis as a teaching tool, the package enables
instructors to demonstrate confounder effects, mo...</p>
                <p style="font-size: 0.9em; color: #888; font-style: italic;">Note: preprint</p>
            </div>

        </div>
        
        <footer class="card text-center" style="margin-top: 2rem;">
            <p class="text-muted mb-0">Generated on 2025-09-05 17:58:42</p>
        </footer>
    </div>
</body>
</html>