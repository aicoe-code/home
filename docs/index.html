<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AICOE Research Library</title>
    <link rel="stylesheet" href="assets/styles.css">
</head>
<body>
    <div class="header">
        <h1>AICOE Research Library</h1>
        <p>AI Papers - Daily Collection and Analysis</p>
    </div>
    
    <div class="stats">
        <div class="stat-card">
            <div class="stat-number">332</div>
            <div>Total Papers</div>
        </div>
        <div class="stat-card">
            <div class="stat-number">77</div>
            <div>High Relevance</div>
        </div>
        <div class="stat-card">
            <div class="stat-number">75</div>
            <div>Categories</div>
        </div>
        <div class="stat-card">
            <div class="stat-number">Sep 05</div>
            <div>Last Updated</div>
        </div>
    </div>
    
    <h2>Recent Papers (Top 50 by Relevance)</h2>
    
    
        <div class="paper-card">
            <h3 class="paper-title">PAK-UCB Contextual Bandit: An Online Learning Approach to Prompt-Aware   Selection of Generative Models and LLMs</h3>
            <div class="paper-meta">
                Xiaoyan Hu, Ho-fung Leung, Farzan Farnia | 
                2024-10-17 | 
                <span class="category-tag relevance-high">High (11.0)</span>
            </div>
            <div><span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Selecting a sample generation scheme from multiple prompt-based generative
models, including large language models (LLMs) and prompt-guided image and
video generation models, is typically addressed by choosing the model that
maximizes an averaged evaluation score. However, this score-based selection...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2410.13287v6" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2410.13287v6" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of   Vision-Language Model</h3>
            <div class="paper-meta">
                Phuoc-Nguyen Bui, Khanh-Binh Nguyen, Hyunseung Choo | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (11.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learn...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03895v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03895v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">SMooGPT: Stylized Motion Generation using Large Language Models</h3>
            <div class="paper-meta">
                Lei Zhong, Yi Yang, Changjian Li | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (10.0)</span>
            </div>
            <div><span class="category-tag">cs.GR</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey&#x27;&#x27;. Exist...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04058v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04058v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Foundations and Models in Modern Computer Vision: Key Building Blocks in   Landmark Architectures</h3>
            <div class="paper-meta">
                Radu-Andrei Bourceanu, Neil De La Fuente, Jan Grimm, et al. | 
                2025-07-31 | 
                <span class="category-tag relevance-high">High (10.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">This report analyzes the evolution of key design patterns in computer vision
by examining six influential papers. The analysis begins with foundational
architectures for image recognition. We review ResNet, which introduced
residual connections to overcome the vanishing gradient problem and enable
e...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2507.23357v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2507.23357v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Plan Verification for LLM-Based Embodied Task Completion Agents</h3>
            <div class="paper-meta">
                Ananth Hariharan, Vardhan Dongre, Dilek Hakkani-T칲r, et al. | 
                2025-09-02 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span></div>
            <p class="paper-summary">Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequenc...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.02761v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.02761v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">DMN-Guided Prompting: A Framework for Controlling LLM Behavior</h3>
            <div class="paper-meta">
                Shaghayegh Abedi, Amin Jalali | 
                2025-05-16 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span></div>
            <p class="paper-summary">Large Language Models (LLMs) have shown considerable potential in automating
decision logic within knowledge-intensive processes. However, their
effectiveness largely depends on the strategy and quality of prompting. Since
decision logic is typically embedded in prompts, it becomes challenging for e...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2505.11701v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2505.11701v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Detecting Regional Spurious Correlations in Vision Transformers via   Token Discarding</h3>
            <div class="paper-meta">
                Solha Kang, Esla Timothy Anzaku, Wesley De Neve, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues ...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04009v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04009v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">A Generative Foundation Model for Chest Radiography</h3>
            <div class="paper-meta">
                Yuanfeng Ji, Dan Lin, Xiyue Wang, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen&#x27;, a generative vision-language foundation model that
int...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03903v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03903v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Arabic Chatbot Technologies in Education: An Overview</h3>
            <div class="paper-meta">
                Hicham Bourhil, Yacine El Younoussi | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04066v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04066v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">CANDY: Benchmarking LLMs&#x27; Limitations and Assistive Potential in Chinese   Misinformation Fact-Checking</h3>
            <div class="paper-meta">
                Ruiling Guo, Xinwei Yang, Chen Huang, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (9.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span> <span class="category-tag">cs.AI</span></div>
            <p class="paper-summary">The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03957v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03957v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">MiniCPM4: Ultra-Efficient LLMs on End Devices</h3>
            <div class="paper-meta">
                 MiniCPM Team, Chaojun Xiao, Yuxuan Li, et al. | 
                2025-06-09 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">This paper introduces MiniCPM4, a highly efficient large language model (LLM)
designed explicitly for end-side devices. We achieve this efficiency through
systematic innovation in four key dimensions: model architecture, training
data, training algorithms, and inference systems. Specifically, in ter...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2506.07900v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2506.07900v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Rapid Word Learning Through Meta In-Context Learning</h3>
            <div class="paper-meta">
                Wentao Wang, Guangyuan Jiang, Tal Linzen, et al. | 
                2025-02-20 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Humans can quickly learn a new word from a few illustrative examples, and
then systematically and flexibly use it in novel contexts. Yet the abilities of
current language models for few-shot word learning, and methods for improving
these abilities, are underexplored. In this study, we introduce a no...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2502.14791v4" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2502.14791v4" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Style Transfer to Calvin and Hobbes comics using Stable Diffusion</h3>
            <div class="paper-meta">
                Asvin Kumar Venkataramanan, Sloke Shrestha, Sundar Sripada Venugopalaswamy Sriraman | 
                2023-12-07 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">This project report summarizes our journey to perform stable diffusion
fine-tuning on a dataset containing Calvin and Hobbes comics. The purpose is to
convert any given input image into the comic style of Calvin and Hobbes,
essentially performing style transfer. We train stable-diffusion-v1.5 using ...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2312.03993v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2312.03993v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">DaMoC: Efficiently Selecting the Optimal Large Language Model for   Fine-tuning Domain Tasks Based on Data and Model Compression</h3>
            <div class="paper-meta">
                Wei Huang, Huang Wei, Yinggui Wang | 
                2025-09-01 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the opti...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.01221v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.01221v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Promptception: How Sensitive Are Large Multimodal Models to Prompts?</h3>
            <div class="paper-meta">
                Mohamed Insaf Ismithdeen, Muhammad Uzair Khattak, Salman Khan | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.CV</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts a...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03986v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03986v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning</h3>
            <div class="paper-meta">
                Huanyu Liu, Jia Li, Chang Yu, et al. | 
                2025-08-11 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
e...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2508.07809v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2508.07809v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Sailing Towards Zero-Shot State Estimation using Foundation Models   Combined with a UKF</h3>
            <div class="paper-meta">
                Tobin Holtmann, David Stenger, Andres Posada-Moreno, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">eess.SY</span> <span class="category-tag">cs.LG</span> <span class="category-tag">cs.SY</span></div>
            <p class="paper-summary">State estimation in control and systems engineering traditionally requires
extensive manual system identification or data-collection effort. However,
transformer-based foundation models in other domains have reduced data
requirements by leveraging pre-trained generalist models. Ultimately,
developin...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04213v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04213v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">COBRA: Multimodal Sensing Deep Learning Framework for Remote Chronic   Obesity Management via Wrist-Worn Activity Monitoring</h3>
            <div class="paper-meta">
                Zhengyang Shen, Bo Gao, Mayue Shi | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CE</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Chronic obesity management requires continuous monitoring of energy balance
behaviors, yet traditional self-reported methods suffer from significant
underreporting and recall bias, and difficulty in integration with modern
digital health systems. This study presents COBRA (Chronic Obesity Behavioral...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04210v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04210v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">TRUST-VL: An Explainable News Assistant for General Multimodal   Misinformation Detection</h3>
            <div class="paper-meta">
                Zehong Yan, Peng Qi, Wynne Hsu, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span> <span class="category-tag">cs.MM</span></div>
            <p class="paper-summary">Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04448v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04448v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Res-MoCoDiff: Residual-guided diffusion models for motion artifact   correction in brain MRI</h3>
            <div class="paper-meta">
                Mojtaba Safari, Shansong Wang, Qiang Li, et al. | 
                2025-05-06 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span> <span class="category-tag">physics.med-ph</span></div>
            <p class="paper-summary">Objective. Motion artifacts in brain MRI, mainly from rigid head motion,
degrade image quality and hinder downstream applications. Conventional methods
to mitigate these artifacts, including repeated acquisitions or motion
tracking, impose workflow burdens. This study introduces Res-MoCoDiff, an
eff...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2505.03498v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2505.03498v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Aesthetic Image Captioning with Saliency Enhanced MLLMs</h3>
            <div class="paper-meta">
                Yilin Tao, Jiashui Huang, Huaze Xu, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
ima...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04378v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04378v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Imitating Radiological Scrolling: A Global-Local Attention Model for 3D   Chest CT Volumes Multi-Label Anomaly Classification</h3>
            <div class="paper-meta">
                Theo Di Piazza, Carole Lazarus, Olivier Nempont, et al. | 
                2025-03-26 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">The rapid increase in the number of Computed Tomography (CT) scan
examinations has created an urgent need for automated tools, such as organ
segmentation, anomaly classification, and report generation, to assist
radiologists with their growing workload. Multi-label classification of
Three-Dimensiona...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2503.20652v5" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2503.20652v5" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering</h3>
            <div class="paper-meta">
                Ayan Banerjee, Josep Llad칩s, Umapada Pal, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04123v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04123v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD   Detection</h3>
            <div class="paper-meta">
                Zhu Wenjie, Zhang Yabin, Xin Jin, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
signif...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03951v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03951v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Spotlight Attention: Towards Efficient LLM Generation via Non-linear   Hashing-based KV Cache Retrieval</h3>
            <div class="paper-meta">
                Wenhao Li, Yuxin Zhang, Gen Luo, et al. | 
                2025-08-27 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2508.19740v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2508.19740v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by   Self-Play Fine-Tuning</h3>
            <div class="paper-meta">
                Yuhao Zhang, Shaoming Duan, Jinhang Su, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (8.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span> <span class="category-tag">cs.AI</span></div>
            <p class="paper-summary">Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new informa...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03937v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03937v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">ACING: Actor-Critic for Instruction Learning in Black-Box LLMs</h3>
            <div class="paper-meta">
                Salma Kharrat, Fares Fourati, Marco Canini | 
                2024-11-19 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.SY</span> <span class="category-tag">eess.SY</span> <span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">The effectiveness of Large Language Models (LLMs) in solving tasks depends
significantly on the quality of their instructions, which often require
substantial human effort to craft. This underscores the need for automated
instruction optimization. However, optimizing instructions is particularly
cha...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2411.12736v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2411.12736v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in   Resume Screening</h3>
            <div class="paper-meta">
                Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.HC</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.CY</span> <span class="category-tag">K.4.2</span></div>
            <p class="paper-summary">In this study, we conduct a resume-screening experiment (N=528) where people
collaborate with simulated AI models exhibiting race-based preferences (bias)
to evaluate candidates for 16 high and low status occupations. Simulated AI
bias approximates factual and counterfactual estimates of racial bias...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04404v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04404v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">From Editor to Dense Geometry Estimator</h3>
            <div class="paper-meta">
                JiYuan Wang, Chunyu Lin, Lei Sun, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-t...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04338v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04338v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn   Negotiation</h3>
            <div class="paper-meta">
                Yunbo Long, Liming Xu, Lukas Beckenbauer, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span></div>
            <p class="paper-summary">Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04310v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04310v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Transferable Mask Transformer: Cross-domain Semantic Segmentation with   Region-adaptive Transferability Estimation</h3>
            <div class="paper-meta">
                Jianhua Liu, Zhengyu Li, Yanru Wu, et al. | 
                2025-04-08 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Recent advances in Vision Transformers (ViTs) have set new benchmarks in
semantic segmentation. However, when adapting pretrained ViTs to new target
domains, significant performance degradation often occurs due to distribution
shifts, resulting in suboptimal global attention. Since self-attention
me...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2504.05774v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2504.05774v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">CoT-Space: A Theoretical Framework for Internal Slow-Thinking via   Reinforcement Learning</h3>
            <div class="paper-meta">
                Zeyu Gan, Hao Yi, Yong Liu | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought p...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04027v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04027v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware   Embeddings</h3>
            <div class="paper-meta">
                Or Shachar, Uri Katz, Yoav Goldberg, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.IR</span></div>
            <p class="paper-summary">We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named
Entity Retrieval, a variant of Named Entity Recognition (NER), where the types
of interest are not provided in advance, and a user-defined type description is
used to retrieve documents mentioning entities of that type. Inste...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04011v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04011v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Transition Models: Rethinking the Generative Learning Objective</h3>
            <div class="paper-meta">
                Zidong Wang, Yiyuan Zhang, Xiaoyu Yue, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">A fundamental dilemma in generative modeling persists: iterative diffusion
models achieve outstanding fidelity, but at a significant computational cost,
while efficient few-step alternatives are constrained by a hard quality
ceiling. This conflict between generation steps and output quality arises f...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04394v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04394v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Connections between reinforcement learning with feedback,test-time   scaling, and diffusion guidance: An anthology</h3>
            <div class="paper-meta">
                Yuchen Jiao, Yuxin Chen, Gen Li | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">stat.TH</span> <span class="category-tag">cs.GL</span> <span class="category-tag">math.ST</span> <span class="category-tag">stat.ML</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">In this note, we reflect on several fundamental connections among widely used
post-training techniques. We clarify some intimate connections and equivalences
between reinforcement learning with human feedback, reinforcement learning with
internal feedback, and test-time scaling (particularly soft be...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04372v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04372v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">RL&#x27;s Razor: Why Online Reinforcement Learning Forgets Less</h3>
            <div class="paper-meta">
                Idan Shenfeld, Jyothish Pari, Pulkit Agrawal | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Comparison of fine-tuning models with reinforcement learning (RL) and
supervised fine-tuning (SFT) reveals that, despite similar performance at a new
task, RL preserves prior knowledge and capabilities significantly better. We
find that the degree of forgetting is determined by the distributional sh...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04259v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04259v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Synthetic Survival Data Generation for Heart Failure Prognosis Using   Deep Generative Models</h3>
            <div class="paper-meta">
                Chanon Puttanawarut, Natcha Fongsrisin, Porntep Amornritvanich, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">Background: Heart failure (HF) research is constrained by limited access to
large, shareable datasets due to privacy regulations and institutional
barriers. Synthetic data generation offers a promising solution to overcome
these challenges while preserving patient confidentiality. Methods: We
genera...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04245v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04245v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Plot&#x27;n Polish: Zero-shot Story Visualization and Disentangled Editing   with Text-to-Image Diffusion Models</h3>
            <div class="paper-meta">
                Kiymet Akdemir, Jing Shi, Kushal Kafle, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
e...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04446v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04446v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Self-adaptive Dataset Construction for Real-World Multimodal Safety   Scenarios</h3>
            <div class="paper-meta">
                Jingen Qu, Lijun Li, Bo Zhang, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span> <span class="category-tag">cs.CV</span> <span class="category-tag">cs.CR</span></div>
            <p class="paper-summary">Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a uni...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04403v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04403v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval   for Text-Based Person Anomaly Search</h3>
            <div class="paper-meta">
                Hao Ju, Hu Zhang, Zhedong Zheng | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
ali...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04376v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04376v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent   Detection</h3>
            <div class="paper-meta">
                Chen Hu, Shan Luo, Letizia Gionfrida | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span> <span class="category-tag">cs.RO</span></div>
            <p class="paper-summary">Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
as...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04324v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04324v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Enhanced Generative Data Augmentation for Semantic Segmentation via   Stronger Guidance</h3>
            <div class="paper-meta">
                Quang-Huy Che, Duc-Tri Le, Bich-Nga Pham, et al. | 
                2024-09-09 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">Data augmentation is crucial for pixel-wise annotation tasks like semantic
segmentation, where labeling requires significant effort and intensive labor.
Traditional methods, involving simple transformations such as rotations and
flips, create new images but often lack diversity along key semantic di...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2409.06002v5" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2409.06002v5" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation</h3>
            <div class="paper-meta">
                Xiaofu Chen, Israfel Salazar, Yova Kementchedjhieva | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span> <span class="category-tag">cs.CV</span></div>
            <p class="paper-summary">As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03897v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03897v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?</h3>
            <div class="paper-meta">
                Guibin Zhang, Junhao Wang, Junjie Chen, et al. | 
                2025-09-03 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span> <span class="category-tag">cs.MA</span></div>
            <p class="paper-summary">Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the spe...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03312v2" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03312v2" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Measuring Bias or Measuring the Task: Understanding the Brittle Nature   of LLM Gender Biases</h3>
            <div class="paper-meta">
                Bufan Gao, Elisa Kreiss | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully construc...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04373v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04373v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Synthesizing Sheet Music Problems for Evaluation and Reinforcement   Learning</h3>
            <div class="paper-meta">
                Zhilin Wang, Zhe Yang, Yun Luo, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
prop...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04059v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04059v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Exploring NLP Benchmarks in an Extremely Low-Resource Setting</h3>
            <div class="paper-meta">
                Ulin Nuha, Adam Jatowt | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remain...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03962v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03962v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth</h3>
            <div class="paper-meta">
                Yang Wang, Chenghao Xiao, Chia-Yi Hsiao, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (7.0)</span>
            </div>
            <div><span class="category-tag">cs.CL</span></div>
            <p class="paper-summary">We introduce Drivelology, a unique linguistic phenomenon characterised as
&quot;nonsense with depth&quot;, utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit ...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.03867v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.03867v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">Delta Activations: A Representation for Finetuned Large Language Models</h3>
            <div class="paper-meta">
                Zhiqiu Xu, Amish Sethi, Mayur Naik, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (6.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.LG</span> <span class="category-tag">cs.IR</span></div>
            <p class="paper-summary">The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured re...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04442v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04442v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
        <div class="paper-card">
            <h3 class="paper-title">ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory</h3>
            <div class="paper-meta">
                Matthew Ho, Chen Si, Zhaoxiang Feng, et al. | 
                2025-09-04 | 
                <span class="category-tag relevance-high">High (6.0)</span>
            </div>
            <div><span class="category-tag">cs.AI</span> <span class="category-tag">cs.CL</span> <span class="category-tag">cs.LG</span></div>
            <p class="paper-summary">While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, an...</p>
            <div class="paper-links">
                <a href="http://arxiv.org/abs/2509.04439v1" target="_blank">游늯 arXiv</a>
                <a href="http://arxiv.org/pdf/2509.04439v1" target="_blank">游닌 PDF</a>
            </div>
        </div>
    
    <footer style="margin-top: 3rem; padding-top: 2rem; border-top: 1px solid #ddd; text-align: center; color: #666;">
        <p>Generated on 2025-09-05 at 19:33 | AICOE Research Library</p>
    </footer>
</body>
</html>